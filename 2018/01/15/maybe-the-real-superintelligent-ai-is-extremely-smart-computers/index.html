<!DOCTYPE html>
<html lang="en-US">
	<head>
		<meta charset="UTF-8" />
		<title>Maybe The Real Superintelligent AI Is Extremely Smart Computers | Slate Star Codex</title>
		<meta name=viewport content="width=device-width, min-width=572, initial-scale=1">
		<script type="text/javascript" src="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/viewport-min-width.js"></script>
		<link rel="profile" href="https://gmpg.org/xfn/11" />
		<link rel="stylesheet" type="text/css" media="all" href="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/style.css" />
		<link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Josefin+Sans' rel='stylesheet' type='text/css'>
		<link rel='stylesheet' id='font-awesome-css'  href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css' type='text/css' media='all' />

		<link rel="pingback" href="https://slatestarcodex.com/xmlrpc.php" />
		<link rel='dns-prefetch' href='//platform-api.sharethis.com' />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; Feed" href="https://slatestarcodex.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; Comments Feed" href="https://slatestarcodex.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; Maybe The Real Superintelligent AI Is Extremely Smart Computers Comments Feed" href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/feed/" />
<link rel='stylesheet' id='wmsimplecaptcha_style_front-css'  href='https://slatestarcodex.com/wp-content/plugins/wm-simple-captcha/assets/css/wmsimplecaptcha_style.css?ver=5.4.1' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-css'  href='https://c0.wp.com/c/5.4.1/wp-includes/css/dist/block-library/style.min.css' type='text/css' media='all' />
<style id='wp-block-library-inline-css' type='text/css'>
.has-text-align-justify{text-align:justify;}
</style>
<link rel='stylesheet' id='easy_table_style-css'  href='https://slatestarcodex.com/wp-content/plugins/easy-table/themes/default/style.css?ver=1.8' type='text/css' media='all' />
<link rel='stylesheet' id='jetpack_css-css'  href='https://c0.wp.com/p/jetpack/8.5/css/jetpack.css' type='text/css' media='all' />
<script>if (document.location.protocol != "https:") {document.location = document.URL.replace(/^http:/i, "https:");}</script><script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/jquery/jquery.js'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/jquery/jquery-migrate.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var ajax_object = {"ajax_url":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/wm-simple-captcha/assets/js/wmsimplecaptcha_scripts.js?ver=5.4.1'></script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/wp-hide-post/public/js/wp-hide-post-public.js?ver=2.0.10'></script>
<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#product=ga&#038;property=5c350a7dad0b1400119dbb2c'></script>
<link rel='https://api.w.org/' href='https://slatestarcodex.com/wp-json/' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://slatestarcodex.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://slatestarcodex.com/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='OT93: Giant Threadwood' href='https://slatestarcodex.com/2018/01/14/ot93-giant-threadwood/' />
<link rel='next' title='Bundles Of Joy' href='https://slatestarcodex.com/2018/01/16/bundles-of-joy/' />
<link rel="canonical" href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/" />
<link rel='shortlink' href='https://slatestarcodex.com/?p=4773' />
<link rel="alternate" type="application/json+oembed" href="https://slatestarcodex.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fslatestarcodex.com%2F2018%2F01%2F15%2Fmaybe-the-real-superintelligent-ai-is-extremely-smart-computers%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://slatestarcodex.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fslatestarcodex.com%2F2018%2F01%2F15%2Fmaybe-the-real-superintelligent-ai-is-extremely-smart-computers%2F&#038;format=xml" />

<link rel='dns-prefetch' href='//c0.wp.com'/>
<style type='text/css'>img#wpstats{display:none}</style>			<style type="text/css">
				.pmcc-comments-report-link {
					font: 10px sans-serif;
					display:block;
					float:right;
					clear: left;
					margin-top: 10px;
				}
				.pmcc-comments-report-link a {
					color: #9C3E3E;
					padding: 2px 5px;
					margin: 2px 0 0 5px;
					border: 1px solid #ddd;
				}
				
				.pmcc-comments-report-link strong {
				    color: white;
				    background: #c0392b;
				    padding-top: 2px;
				    border-radius: 7px;
				    display: block;
				    width: 15px;
				    height: 15px;
				    text-align: center;
				    margin-right: 10px;
				}
			</style>
			
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article" />
<meta property="og:title" content="Maybe The Real Superintelligent AI Is Extremely Smart Computers" />
<meta property="og:url" content="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/" />
<meta property="og:description" content="I. By Ted Chiang, on Buzzfeed: The Real Danger To Civilization Isn&#8217;t AI: It&#8217;s Runaway Capitalism. Chiang&#8217;s science fiction is great and I highly recommend it. This article, not soâ€¦" />
<meta property="article:published_time" content="2018-01-16T02:12:35+00:00" />
<meta property="article:modified_time" content="2018-01-16T03:35:20+00:00" />
<meta property="og:site_name" content="Slate Star Codex" />
<meta property="og:image" content="https://slatestarcodex.com/wp-content/themes/two_column_pujugama/images/codex_spotlight.png" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:text:title" content="Maybe The Real Superintelligent AI Is Extremely Smart Computers" />
<meta name="twitter:card" content="summary" />
<meta property="og:image:width" content="200" />
<meta property="og:image:height" content="200" />
<meta name="twitter:site" content="@slatestarcodex" />

<!-- End Jetpack Open Graph Tags -->
		<style type="text/css" id="wp-custom-css">
			.hentry {
	margin-bottom: 46px
}

#pjgm-content .pjgm-posttitle {
	margin-bottom: 18px;
}
.pjgm-postcontent {
	padding-top:36px; 
}

/* 2019/07/04
   added by Andrew Swift
   mail@andrewswift.com */

@media all and
(max-device-width: 480px)
{ blockquote {
   -webkit-text-size-adjust:
    140% !important; }}		</style>
				<script src="https://polyfill.io/v2/polyfill.min.js?features=IntersectionObserver"></script>
	</head>

	<body data-rsssl=1 class="post-template-default single single-post postid-4773 single-format-standard s1-collapse s2-collapse">
		<div id="pjgm-wrap">
			<div id="pjgm-header">
				<div id="pjgm-menubar">
					<a href="https://slatestarcodex.com/" class="pjgm-home" title="Slate Star Codex" rel="home">Home</a>
					<div class="menu"><ul>
<li class="page_item page-item-2"><a href="https://slatestarcodex.com/about/">About / Top Posts</a></li>
<li class="page_item page-item-5559"><a href="https://psychiat-list.slatestarcodex.com/">Psychiat-List</a></li>
<li class="page_item page-item-2091"><a href="https://slatestarcodex.com/archives/">Archives</a></li>
<li class="page_item page-item-4475"><a href="https://www.lesswrong.com/community?filters=SSC">Meetups</a></li>
<li class="page_item page-item-3837"><a href="https://slatestarcodex.com/mistakes/">Mistakes</a></li>
<li class="page_item page-item-1745"><a href="https://slatestarcodex.com/comments/">Comments</a></li>
<li class="page_item page-item-3942"><a href="https://slatestarcodex.com/advertise/">Advertise</a></li>
<li class="page_item page-item-3989"><a href="/tag/open/?latest">Open Thread</a></li>
</ul></div>
					<a href="https://slatestarcodex.com/comments/feed/" class="pjgm-feed">Comments Feed</a>
					<a href="https://slatestarcodex.com/feed/" class="pjgm-feed">RSS Feed</a>
				</div><!-- #pjgm-menubar -->

				<div id="pjgm-bigtitle">
										<div id="pjgm-title">
						<img src="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/images/codex.png" alt="codex" class="codex" />
						<span>
							<a href="https://slatestarcodex.com/" title="Slate Star Codex" rel="home">Slate Star Codex</a>
						</span>
						</div>
						<div id="pjgm-description">SELF-RECOMMENDING!</div>
			</div><!-- #pjgm-bigtitle -->
		</div><!-- #pjgm-header -->

		<div id="pjgm-main">
<div id="left-sidebar" class="widget-area" role="complementary">
	<a class="sidebar-toggle" title="Expand Sidebar"><i class="fa fa-angle-double-left"></i><i class="fa fa-angle-double-right"></i></a>
	<ul class="xoxo">
				<li id="recent-posts-2" class="widget-container widget_recent_entries">		<h3 class="widget-title">Recent Posts</h3>		<ul>
											<li>
					<a href="https://slatestarcodex.com/2020/05/27/open-thread-154-75/">Open Thread 154.75</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/26/my-immortal-as-alchemical-allegory/">&#8220;My Immortal&#8221; As Alchemical Allegory</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/24/open-thread-154-5/">Open Thread 154.5</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/20/links-5-20/">Links 5/20</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/20/open-thread-154-25/">Open Thread 154.25</a>
									</li>
					</ul>
		</li><li id="text-5" class="widget-container widget_text"><h3 class="widget-title">Upcoming Meetups</h3>			<div class="textwidget"><p>Cancelled due to pandemic, sorry.</p>
</div>
		</li><li id="text-3" class="widget-container widget_text"><h3 class="widget-title">Blogroll</h3>			<div class="textwidget"></div>
		</li><li id="linkcat-100" class="widget-container widget_links"><h3 class="widget-title">Embalmed Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://blog.jaibot.com/">ANOIEAEIB</a></li>
<li><a href="http://commonsenseatheism.com/">Common Sense Atheism</a></li>
<li><a href="http://lesswrong.com">Less Wrong</a></li>
<li><a href="http://thelastpsychiatrist.com/">The Last Psychiatrist</a></li>

	</ul>
</li>
<li id="linkcat-95" class="widget-container widget_links"><h3 class="widget-title">Fabulous Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://alicorn.elcenia.com/board/index.php">Alicornutopia</a></li>
<li><a href="http://unsongbook.com">Unsong</a></li>
<li><a href="https://parahumans.wordpress.com/">Worm</a></li>

	</ul>
</li>
<li id="linkcat-98" class="widget-container widget_links"><h3 class="widget-title">Innumerable Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://www.gwern.net/">Gwern</a></li>
<li><a href="https://golem.ph.utexas.edu/category/">n-Category Cafe</a></li>
<li><a href="http://putanumonit.com/">Put A Number On It</a></li>
<li><a href="https://randomcriticalanalysis.wordpress.com">Random Critical Analysis</a></li>
<li><a href="http://www.scottaaronson.com/blog/">Shtetl-Optimized</a></li>
<li><a href="http://andrewgelman.com/">Statistical Modeling</a></li>
<li><a href="http://unenumerated.blogspot.com/">Unenumerated</a></li>

	</ul>
</li>
<li id="linkcat-94" class="widget-container widget_links"><h3 class="widget-title">Mermaids</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://intelligence.org/blog/">MIRI</a></li>
<li><a href="http://freethoughtblogs.com/brutereason/">Miri</a></li>
<li><a href="http://nothingismere.com/">Nothing Is Mere</a></li>
<li><a href="https://themerelyreal.wordpress.com/">The Merely Real</a></li>

	</ul>
</li>
<li id="linkcat-96" class="widget-container widget_links"><h3 class="widget-title">Stray Dogs</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://anonymousmugwump.blogspot.co.uk">Anonymous Mugwump</a></li>
<li><a href="http://followthesquirrel.blogspot.com/">Follow The Squirrel</a></li>
<li><a href="http://marginalrevolution.com/">Marginal Revolution</a></li>
<li><a href="https://nintil.com/">Nintil</a></li>
<li><a href="https://pseudoerasmus.com/">Pseudoerasmus</a></li>
<li><a href="http://www.themoneyillusion.com/">The Money Illusion</a></li>

	</ul>
</li>
<li id="linkcat-101" class="widget-container widget_links"><h3 class="widget-title">Suckling Pigs</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://fredrikdeboer.com/">Fredrik deBoer</a></li>
<li><a href="http://unqualifiedrestaurants.tumblr.com/">Unqualified Restaurant Reservations</a></li>
<li><a href="http://wholehealthsource.blogspot.com/">Whole Health Source</a></li>

	</ul>
</li>
<li id="linkcat-91" class="widget-container widget_links"><h3 class="widget-title">Those Drawn With A Very Fine Camel Hair Brush</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://existentialcomics.com/">Existential Comics</a></li>
<li><a href="http://www.smbc-comics.com/">Saturday Morning Breakfast Cereal</a></li>

	</ul>
</li>
<li id="linkcat-89" class="widget-container widget_links"><h3 class="widget-title">Those That Are Included In This Classification</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://www.reddit.com/r/slatestarcodex/">r/slatestarcodex</a></li>
<li><a href="https://discord.gg/kAVSf9U" rel="nofollow">SSC Discord Server</a></li>
<li><a href="http://sscpodcast.libsyn.com/rss">SSC Podcast</a></li>

	</ul>
</li>
<li id="linkcat-93" class="widget-container widget_links"><h3 class="widget-title">Those That Are Trained</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://80000hours.org/blog/">80000 Hours Blog</a></li>
<li><a href="http://aiimpacts.org/">AI Impacts</a></li>
<li><a href="http://www.effective-altruism.com/">Effective Altruism Forum</a></li>
<li><a href="http://blog.givewell.org/">GiveWell Blog</a></li>
<li><a href="http://www.jefftk.com/index">Jeff Kaufman</a></li>
<li><a href="http://lukemuehlhauser.com/">Luke Muehlhauser</a></li>
<li><a href="http://theunitofcaring.tumblr.com/">The Unit of Caring</a></li>
<li><a href="https://thewholesky.wordpress.com/">The Whole Sky</a></li>

	</ul>
</li>
<li id="linkcat-102" class="widget-container widget_links"><h3 class="widget-title">Those That At A Distance Resemble Flies</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://agentyduck.blogspot.com/">Agenty Duck</a></li>
<li><a href="https://www.beeminder.com/">Beeminder</a></li>
<li><a href="http://mindingourway.com/">Nate Soares</a></li>

	</ul>
</li>
<li id="linkcat-99" class="widget-container widget_links"><h3 class="widget-title">Those That Belong To The Emperor</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://samzdat.com">Sam[]zdat</a></li>
<li><a href="http://www.xenosystems.net/">Xenosystems</a></li>

	</ul>
</li>
<li id="linkcat-97" class="widget-container widget_links"><h3 class="widget-title">Those That Have Just Broken The Flower Vase</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://esr.ibiblio.org/">Armed and Dangerous</a></li>
<li><a href="https://www.econlib.org/author/bcaplan/">Bryan Caplan</a></li>
<li><a href="http://daviddfriedman.blogspot.com/">David Friedman</a></li>
<li><a href="https://thezvi.wordpress.com/">Don&#039;t Worry About The Vase</a></li>
<li><a href="http://www.overcomingbias.com/">Overcoming Bias</a></li>
<li><a href="http://www.popehat.com/">Popehat</a></li>
<li><a href="http://sci-hub.tw/">Sci-Hub</a></li>

	</ul>
</li>
<li id="linkcat-90" class="widget-container widget_links"><h3 class="widget-title">Those That Tremble As Though They Are Mad</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://1boringoldman.com/">1 Boring Old Man</a></li>
<li><a href="http://acesounderglass.com/">Aceso Under Glass</a></li>
<li><a href="http://cognitionandevolution.blogspot.com/">Cognition and Evolution</a></li>
<li><a href="https://crazymeds.net/pmwiki/pmwiki.php">Crazy Meds</a></li>
<li><a href="https://www.erikandersontherapy.com/blog/">Erik Anderson Therapy</a></li>
<li><a href="http://gruntledandhinged.wordpress.com/">Gruntled and Hinged</a></li>
<li><a href="http://real-psychiatry.blogspot.com/">Real Psychiatry</a></li>
<li><a href="http://psychiatrist-blog.blogspot.com/">Shrink Rap</a></li>

	</ul>
</li>
<li id="linkcat-92" class="widget-container widget_links"><h3 class="widget-title">Various Others</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://zackmdavis.net/blog/">An Algorithmic Lucidity</a></li>
<li><a href="https://medium.com/@sumdepony">De Pony Sun</a></li>
<li><a href="https://www.gnxp.com/">Gene Expression</a></li>
<li><a href="http://infoproc.blogspot.com/">Information Processing</a></li>
<li><a href="http://www.meltingasphalt.com/">Melting Asphalt</a></li>
<li><a href="https://meteuphoric.wordpress.com/">Meteuphoric</a></li>
<li><a href="https://srconstantin.wordpress.com/">Otium</a></li>
<li><a href="http://www.ribbonfarm.com/">Ribbonfarm</a></li>
<li><a href="http://rationalconspiracy.com/">The Rationalist Conspiracy</a></li>
<li><a href="https://sideways-view.com/">The Sideways View</a></li>
<li><a href="http://thingofthings.wordpress.com/">Thing of Things</a></li>
<li><a href="https://westhunt.wordpress.com/">West Hunter</a></li>

	</ul>
</li>
<li id="archives-2" class="widget-container widget_archive"><h3 class="widget-title">Archives</h3>		<ul>
				<li><a href='https://slatestarcodex.com/2020/05/'>May 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/04/'>April 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/03/'>March 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/02/'>February 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/01/'>January 2020</a></li>
	<li><a href='https://slatestarcodex.com/2019/12/'>December 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/11/'>November 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/10/'>October 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/09/'>September 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/08/'>August 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/07/'>July 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/06/'>June 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/05/'>May 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/04/'>April 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/03/'>March 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/02/'>February 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/01/'>January 2019</a></li>
	<li><a href='https://slatestarcodex.com/2018/12/'>December 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/11/'>November 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/10/'>October 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/09/'>September 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/08/'>August 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/07/'>July 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/06/'>June 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/05/'>May 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/04/'>April 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/03/'>March 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/02/'>February 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/01/'>January 2018</a></li>
	<li><a href='https://slatestarcodex.com/2017/12/'>December 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/11/'>November 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/10/'>October 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/09/'>September 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/08/'>August 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/07/'>July 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/06/'>June 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/05/'>May 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/04/'>April 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/03/'>March 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/02/'>February 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/01/'>January 2017</a></li>
	<li><a href='https://slatestarcodex.com/2016/12/'>December 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/11/'>November 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/10/'>October 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/09/'>September 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/08/'>August 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/07/'>July 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/06/'>June 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/05/'>May 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/04/'>April 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/03/'>March 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/02/'>February 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/01/'>January 2016</a></li>
	<li><a href='https://slatestarcodex.com/2015/12/'>December 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/11/'>November 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/10/'>October 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/09/'>September 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/08/'>August 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/07/'>July 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/06/'>June 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/05/'>May 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/04/'>April 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/03/'>March 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/02/'>February 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/01/'>January 2015</a></li>
	<li><a href='https://slatestarcodex.com/2014/12/'>December 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/11/'>November 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/10/'>October 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/09/'>September 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/08/'>August 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/07/'>July 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/06/'>June 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/05/'>May 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/04/'>April 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/03/'>March 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/02/'>February 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/01/'>January 2014</a></li>
	<li><a href='https://slatestarcodex.com/2013/12/'>December 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/11/'>November 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/10/'>October 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/09/'>September 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/08/'>August 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/07/'>July 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/06/'>June 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/05/'>May 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/04/'>April 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/03/'>March 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/02/'>February 2013</a></li>
		</ul>
			</li><li id="nav_menu-3" class="widget-container widget_nav_menu"><div class="menu-full-archives-link-for-widget-area-container"><ul id="menu-full-archives-link-for-widget-area" class="menu"><li id="menu-item-2103" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2103"><a href="https://slatestarcodex.com/archives/">Full Archives</a></li>
</ul></div></li>	</ul>
</div>

		<div id="pjgm-box">
			<div id="pjgm-content">


				<div id="post-4773" class="post-4773 post type-post status-publish format-standard hentry category-uncategorized tag-ai tag-transhumanism">
					<h1 class="pjgm-posttitle">Maybe The Real Superintelligent AI Is Extremely Smart Computers</h1>

					<div class="pjgm-postmeta">
						<span class="meta-prep meta-prep-author">Posted on</span> <a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/" title="6:12 pm" rel="bookmark"><span class="entry-date">January 15, 2018</span></a> <span class="meta-sep">by</span> <span class="author vcard"><a class="url fn n" href="https://slatestarcodex.com/author/admin/" title="View all posts by Scott Alexander">Scott Alexander</a></span>					</div><!-- .pjgm-postmeta -->

					<div class="pjgm-postcontent">
						<p><b>I.</b></p>
<p>By Ted Chiang, on Buzzfeed: <A HREF="https://www.buzzfeed.com/tedchiang/the-real-danger-to-civilization-isnt-ai-its-runaway">The Real Danger To Civilization Isn&#8217;t AI: It&#8217;s Runaway Capitalism</A>. Chiang&#8217;s <A HREF="https://www.amazon.com/Stories-Your-Life-Others-Chiang/dp/1101972122/ref=as_li_ss_tl?ie=UTF8&#038;qid=1516068964&#038;sr=8-1&#038;keywords=ted+chiang&#038;linkCode=ll1&#038;tag=slatestarcode-20&#038;linkId=8b12d3c016fa97db7d7aca97464944dc">science fiction</A> is great and I highly recommend it. This article, not so much.</p>
<p>The gist seems to be: hypothetical superintelligent AIs sound a lot like modern capitalism. Both optimize relentlessly for their chosen goal (paperclips, money), while ignoring the whole <A HREF="https://arbital.com/p/complexity_of_value/">complexity of human value</A>.</p>
<p>It&#8217;s a <A HREF="https://slatestarcodex.com/2017/11/21/contra-robinson-on-public-food/">good point</A>, and I would have gone on to explain the more general idea of an optimization process. Evolution optimizes relentlessly for reproductive fitness, capitalism optimizes relentlessly for money, politics optimizes relentlessly for electability.  Humans are sort of an optimization process, but such a weird edge case that &#8220;non-human optimizers&#8221; is a natural category to people more used to the human variety. Both future superintelligences and modern corporations are types of non-human optimizers, so they&#8217;ll naturally be similar in ways &#8211; though not so many ways that taking the comparison too far won&#8217;t <A HREF="https://slatestarcodex.com/2015/12/27/things-that-are-not-superintelligences/">carry you off a cliff</A>. And one of those ways will be that even though they both know humans have complex values, they won&#8217;t care. Facebook &#8220;knows&#8221; that people enjoy meaningful offline relationships; after all, it&#8217;s made entirely of human subunits who know that. It&#8217;s just not incentivized to do anything with that knowledge. Future superintelligences will likely be in a similar position &#8211; see section 4.1 <A HREF="https://slatestarcodex.com/superintelligence-faq/">here</A>.</p>
<p>But Chiang argues the analogy proves that AI fears are absurd. This is a really weird thing to do with an analogy. Science has always been a fertile source of metaphors. The Pentagon budget is a <i>black hole</i>. The rise of ISIS will start a <i>chain reaction</i>. Social responsibility is in our corporate <i>DNA</i>. But until now, nobody has tried to use scientific metaphor as evidence in scientific debates. For a long time astronomers were unsure whether black holes really existed. But nobody thought the argument that &#8220;the REAL black hole is the Pentagon budget!&#8221; deserved to be invited to the discussion.</p>
<p>Actually this is worse than that, because the analogy is based on real similarities of mechanism. &#8220;People say in the future we might have fusion power plants. But look at all these ways fusion power plants resemble stars! Obviously stars are the <i>real</i> fusion power plants. And so by this, we can know that the future will never contain fusion power.&#8221; <i>Huh?</i></p>
<p><b>II.</b></p>
<p>Still, Chiang pursues this angle relentlessly. Though he doesn&#8217;t use the word, he bases his argument around the psychological concept of projection, where people trying to avoid thinking about their own attributes unconsciously attribute them to others:</p>
<blockquote><p>Billionaires like Bill Gates and Elon Musk assume that a superintelligent AI will stop at nothing to achieve its goals because thatâ€™s the attitude they adopted&#8230;Itâ€™s no surprise that Silicon Valley capitalists donâ€™t want to think about capitalism ending. Whatâ€™s unexpected is that the way they envision the world ending is through a form of unchecked capitalism, disguised as a superintelligent AI. They have unconsciously created a devil in their own image, a boogeyman whose excesses are precisely their own.</p>
<p>Which brings us back to the importance of insight. Sometimes insight arises spontaneously, but many times it doesnâ€™t. People often get carried away in pursuit of some goal, and they may not realize it until itâ€™s pointed out to them, either by their friends and family or by their therapists. Listening to wake-up calls of this sort is considered a sign of mental health.</p></blockquote>
<p>In my own psychiatric practice, I am always <i>very</i> reluctant to assume a patient is projecting unless I know them very well. I&#8217;ve written more about the dangers of defense mechanism narratives  <A HREF="https://slatestarcodex.com/2016/02/24/two-attitudes-in-psychiatry/">here</A>, but the short version is that amateur therapists inevitably end up using them to trivialize or psychologize a patient&#8217;s real concerns. I can&#8217;t tell you how many morons hear a patient say &#8220;I think my husband hates our kids&#8221;, give some kind of galaxy-brain level interpretation like &#8220;Maybe what&#8217;s really going on is <i>you</i> unconsciously hate your kids, but it&#8217;s more comfortable for you to imagine this of your husband&#8221;, and then get <i>absolutely shocked</i> when the husband turns out to be abusing the kids.</p>
<p>Accusing an entire region of California of projection is a novel psychoanalytic manuever, and I&#8217;m not sure Chiang and Buzzfeed give it the caution it deserves. The problem isn&#8217;t that they don&#8217;t have a plausible-sounding argument. The problem is that this sort of hunting-for-resemblances is a known bug in the human brain. You can do it to anything, and it will <i>always</i> generate a plausible-sounding argument.</p>
<p>Don&#8217;t believe me? What about black holes? Scientists say they exist, but I think these scientists are just creating &#8220;a devil in their own image, a boogeyman whose excesses are precisely their own.&#8221; Think about it. Superstar physicists like Einstein help university STEM departments suck up all the resources that should go to the humanities and arts. So of <i>course</i> when Einstein tries to imagine outer space, he thinks of super-stars that suck up all the resources from surrounding areas!</p>
<p>And chain reactions! You know what was a chain reaction? Enrico Fermi discovered some stuff about atoms. Then Leo Szilard wrote a letter to President Roosevelt saying it might have military applications. Then Roosevelt set up a project to develop military applications. One thing led to another, and a couple of Japanese cities got vaporized and the rest of the world teetered on the brink of total annhilation. Of <i>course</i> nuclear physicists became obsessed with the idea of chain reactions: they were living in one. They expected that subatomic particles would behave the same way they did &#8211; start out working on innocent little atomic collisions, have everything snowball out of control, and end up culpable for a nuclear explosion.</p>
<p>Watson and Crick worked together pretty closely on the discovery of DNA. So they started imagining organic molecules doing the same thing they did &#8211; two of them, intertwining. Just as they published papers which became the inspiration for an entire body of knowledge, so DNA was full of letters that caused the existence of an entire body. Epigenetics is relevant but generally ignored for the sake of keeping things simple, so it represents Rosalind Franklin.</p>
<p>I could go on all day like this. In fact, I have: this was the central narrative of my novel <A HREF="http://unsongbook.com/">Unsong</A>, where the world runs on &#8220;the kabbalistic method&#8221; and correspondences between unlike domains are the royal road to knowledge. You know who <i>else</i> wrote <A HREF="https://www.goodreads.com/book/show/20958575-seventy-two-letters">a story</A> about a world that ran on kabbalah? <i>Ted Chiang</i>. This is not a coincidence because nothing is ever a coincidence.</p>
<p><b>III.</b></p>
<p>But Chiang&#8217;s comparison isn&#8217;t even good kabbalah. The correspondences don&#8217;t really correspond; the match-ups don&#8217;t really match.</p>
<p>He bases his metaphor on the idea that worries about AI risk comes from Silicon Valley. They don&#8217;t. The tech community got interested later. The original version of the theory comes from Nick Bostrom, a professor at Oxford, and Eliezer Yudkowsky, who at the time I think was living in Chicago. It was pushed to public notice by <A HREF="https://slatestarcodex.com/2015/05/22/ai-researchers-on-ai-risk/">leading AI scientists</A> <A HREF="https://slatestarcodex.com/2017/06/08/ssc-journal-club-ai-timelines/">all around the world</A>. And before it was endorsed by Silicon Valley tycoons, it was endorsed by philosophers like David Chalmers and scientists like Stephen Hawking.</p>
<p>(Hawking, by the way, discovered that information could escape black holes despite a bunch of science saying they should be completely inert. This seems <i>suspiciously</i> similar to how he himself is completely paralyzed, but manages to convey information to the outside world via an artificial speaking device. More projection?)</p>
<p>Forcing the argument to rely on &#8220;well, also lots of people in Silicon Valley think this too&#8221; makes it hopelessly weak.</p>
<p>Consider: lots of Hollywood celebrities <A HREF="http://www.dw.com/en/hollywood-to-the-rescue-can-pop-culture-fight-climate-change/a-40847372">speak</A> <A HREF="https://www.climaterealityproject.org/blog/nine-celebrities-changing-conversation-climate-action">out</A> <A HREF="http://www.slate.com/blogs/future_tense/2016/08/09/leonardo_dicaprio_speech_is_the_most_influential_ever_on_climate_change.html">about</A> <A HREF="https://dailyplanet.climate-kic.org/7-a-list-celebrities-who-use-star-power-for-climate-action/">global</A> <A HREF="http://variety.com/2017/biz/news/celebrities-react-to-paris-accord-withdraw-1202450934/">warming</A>. And we&#8217;re gradually finding out that some pretty awful things go on in Hollywood. Does that mean &#8220;The Real Problem Isn&#8217;t Global Warming, It&#8217;s Hollywood Harassment&#8221;? Does that license some author to write (while scientists facepalm worldwide) that because <i>he</i> doesn&#8217;t feel like carbon dioxide should be able to warm the climate, any claims to the contrary must be Hollywood celebrities projecting their own moral inadequacies? (possible angle: celebrities&#8217; utterances emit carbon dioxide, and create a <i>stifling climate</i> for women in the entertainment industry)</p>
<p>If this sounds like a straw man to you, I challenge you to come up with any way it differs from what Chiang is doing with AI risk. You take a scientific controversy over whether there&#8217;s a major global risk. You ignore the science and focus instead on a subregion of California that seems unusually concerned with it. You point out some bad behavior of that subregion of California. You kabbalistically connect it to the risk in question. Then you conclude that people worried about the risk are just peddling science fiction.</p>
<p>(wait, of <i>course</i> Chiang interprets this as people peddling science fiction. He&#8217;s a science fiction writer! More projection!)</p>
<p>If the Hollywood example sounds more blatant or less plausible than the AI example, I maintain it&#8217;s only because we&#8217;re already convinced global warming is real and dangerous. That gives it the same kind of legitimacy as <A HREF="https://slatestarcodex.com/2018/01/11/self-serving-bias/">self-service gas stations</A>, and grants it extra resistance against sophistry. That&#8217;s all. That&#8217;s the whole difference.</p>
<p>This isn&#8217;t how risk assessment works. This isn&#8217;t how good truth-seeking works. Whether or not you believe in AI risk, you should be disappointed that this is how we deal with issues that could be catastrophic to get wrong.</p>
											</div><!-- .pjgm-postcontent -->


					<div class="pjgm-postutility">
						This entry was posted in <a href="https://slatestarcodex.com/category/uncategorized/" rel="category tag">Uncategorized</a> and tagged <a href="https://slatestarcodex.com/tag/ai/" rel="tag">ai</a>, <a href="https://slatestarcodex.com/tag/transhumanism/" rel="tag">transhumanism</a>. Bookmark the <a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/" title="Permalink to Maybe The Real Superintelligent AI Is Extremely Smart Computers" rel="bookmark">permalink</a>.											</div><!-- .pjgm-postutility -->
				</div><!-- #post-## -->

				<div id="pjgm-navbelow" class="pjgm-navigation">
					<div class="pjgm-navpre"><a href="https://slatestarcodex.com/2018/01/14/ot93-giant-threadwood/" rel="prev"><span class="pjgm-metanav">&larr;</span> OT93: Giant Threadwood</a></div>
					<div class="pjgm-navnex"><a href="https://slatestarcodex.com/2018/01/16/bundles-of-joy/" rel="next">Bundles Of Joy <span class="pjgm-metanav">&rarr;</span></a></div>
				</div><!-- #pjgm-navbelow -->

				




	<div id="comments">
			<h3 id="comments-title">363 Responses to <em>Maybe The Real Superintelligent AI Is Extremely Smart Computers</em></h3>

			<div id="comment-order-reverse-button"><a href="?reverseComments=#comments">Reverse order</a></div>


			<ol class="commentlist">
					<li class="comment byuser comment-author-sniffnoy even thread-even depth-1" id="li-comment-588967">
		<div id="comment-588967" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588967">
			January 15, 2018 at 6:23 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>As best I can tell you haven&#8217;t bothered to actually answer Chiang on the object level, but fortunately those arguments are generally well-known here. ðŸ˜› (Instrumental convergence, the AI knows that what its doing is not what you meant for it to do but it doesn&#8217;t care about that any more than you care that you&#8217;re not maximizing your inclusive fitness, etc&#8230;)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-admin bypostauthor odd alt depth-2" id="li-comment-588968">
		<div id="comment-588968" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588968">
			January 15, 2018 at 6:24 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If Chiang gets around to making an object level argument, I&#8217;ll answer it.</p>
<p>(but also, <a rel="nofollow"href="https://slatestarcodex.com/superintelligence-faq/" rel="nofollow ugc">https://slatestarcodex.com/superintelligence-faq/</a> , especially section 4.1)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sniffnoy even depth-3" id="li-comment-588977">
		<div id="comment-588977" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588977">
			January 15, 2018 at 6:50 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I mean I know you know such things!  But like I expect someone is going to read Ted Chiang&#8217;s piece and then read this and say &#8220;but Scott never gave us any reason to think an AI would do as feared rather than possibly not doing that as Chiang suggests&#8221; and therefore write this off, so I thought I should mention it at least briefly in a comment. ðŸ˜›  But your link is obviously a better explication of such things than me briefly name-checking/summarizing them. ðŸ™‚</p>
<p>(Also I removed &#8220;complexity of value&#8221; from my comment since I just realized you totally did mention that&#8230;)</p>
<p>Edit: I guess I was basically trying to make some version of <a rel="nofollow"href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588975">Wrong Species&#8217;s comment below</a>.  To say, hey, to you who read this but didn&#8217;t notice an object level argument, don&#8217;t worry, those arguments exist, and in fact they&#8217;re sufficiently well-known (go read Superintelligence! Or the Sequences! Or Scott&#8217;s linked FAQ!) that Chiang&#8217;s piece is, like, <i>notably</i> bad for how it seems totally unaware of them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-not-a-random-name odd alt depth-4" id="li-comment-589053">
		<div id="comment-589053" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/dbd90c9bc4bbb84f17d1865bd36d9f20?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/dbd90c9bc4bbb84f17d1865bd36d9f20?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Not A Random Name</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589053">
			January 15, 2018 at 10:10 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Hounded down my password just to log in and say this:</p>
<p>Thank you.</p>
<p>Scott&#8217;s post was not more convincing than him just outright saying &#8220;I think Chiang&#8217;s reasoning is bad and so is his conclusion, trust me on that or do your research&#8221;.<br />
I&#8217;m not invested enough to do my research and the arguments against Chiang&#8217;s reasoning sound like knocking down straw men (i.e. &#8220;His argument is so bad, it might as well be the &#8216;fusion plants can&#8217;t exist because of stars&#8217; argument&#8221;). Also shooting down Chiang&#8217;s argument doesn&#8217;t mean he&#8217;s wrong, just means that if he&#8217;s right it&#8217;s not for this reason.<br />
Generally speaking I trust Scott to be worlds more informed than me on superintelligent AI but it&#8217;s a lot easier to do so with a link to the actual object level arguments.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-pontifex even depth-5" id="li-comment-589078">
		<div id="comment-589078" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8dce59c266da81c1ab952d6e0796b5b6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8dce59c266da81c1ab952d6e0796b5b6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">pontifex</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589078">
			January 15, 2018 at 11:48 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s not clear to me why you think Scott is attacking a strawman.  It seems pretty clear that Chiang is in fact saying that capitalism is the real threat, and AI is just a distraction.  The argument is pretty much as presented, as far as I can see.</p>
<p>Maybe the real superintelligent AI is a <a href="https://www.economist.com/news/briefing/21711902-worrying-implications-its-social-credit-project-china-invents-digital-totalitarian" rel="nofollow">one-party dictatorship which is building a digital totalitarian state?</a>  But that doesn&#8217;t tie into any standard progressive narrative, so forget it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-not-a-random-name odd alt depth-5" id="li-comment-589107">
		<div id="comment-589107" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/dbd90c9bc4bbb84f17d1865bd36d9f20?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/dbd90c9bc4bbb84f17d1865bd36d9f20?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Not A Random Name</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589107">
			January 16, 2018 at 2:49 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Scott&#8217;s post triggers my straw man heuristic, which is all I really claim.</p>
<p>Basically it&#8217;s the pattern of reframe, then tear down. Giving an example of an argument that&#8217;s really silly and then claiming that it&#8217;s an analogue to your opponents actual view. This post does it in part 1, part 2 and part 3.</p>
<p>It&#8217;s a red flag for me. I acknowledge that it&#8217;s just a heuristic, but it&#8217;s so easy to do this to things that are actually correct that I can&#8217;t trust arguments based on this structure. Unless I&#8217;m willing to do the research and check whether or not the silly example that was given is actually a fair comparison to the argument the other person was trying to make.<br />
In this case I&#8217;m not sufficiently interested to do that. So I just have to take it on trust or file it under &#8220;things Scott believes which may or may not be true&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-carvenvisage even depth-5" id="li-comment-591317">
		<div id="comment-591317" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">carvenvisage</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591317">
			January 21, 2018 at 2:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Scottâ€™s post was not more convincing than him just outright saying â€œI think Chiangâ€™s reasoning is bad and so is his conclusion, trust me on that or do your researchâ€.
</p></blockquote>
<p>If you think you should have to do research after a post like this, you&#8217;re just missing what it&#8217;s trying to do. It&#8217;s not a controlled experiment with white coats and P values, it&#8217;s an attempt to logically dissect the structure of another argument and show it to be invalid. The only research you could need to judge it is reading Mr Chiang&#8217;s post.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sniffnoy odd alt depth-3" id="li-comment-589027">
		<div id="comment-589027" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589027">
			January 15, 2018 at 8:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>BTW, I&#8217;d say Chiang&#8217;s object-level argument is here:</p>
<blockquote><p>The idea of superintelligence is such a poorly defined notion that one could envision it taking almost any form with equal justification: a benevolent genie that solves all the worldâ€™s problems, or a mathematician that spends all its time proving theorems so abstract that humans canâ€™t even understand them.</p></blockquote>
<p>He&#8217;s saying, there&#8217;s just no reason to expect the idea of AI as dangerous optimizer to be correct.  Of course, there is, but he apparently didn&#8217;t bother to read any of the existing material on this before writing this&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-petealexharris even depth-4" id="li-comment-589102">
		<div id="comment-589102" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e196ef4d3f868ef963c62514a38a4698?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e196ef4d3f868ef963c62514a38a4698?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">petealexharris</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589102">
			January 16, 2018 at 2:22 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>His argument defeats itself. If superintelligence is equally likely to take any of a billion forms, it&#8217;s really only a lack of imagination that would lead someone to think most of them are probably safe for us to coexist with.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mrbubu odd alt depth-4" id="li-comment-589108">
		<div id="comment-589108" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e2b4ce45725cac7e3f83f7b35f6c367?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e2b4ce45725cac7e3f83f7b35f6c367?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MrBubu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589108">
			January 16, 2018 at 2:53 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If all I cared about was proving theorems, and if I were powerful enough to do so, I would remodel the atoms in your body into a part of my brain, so I could prove better theorems.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-peter even depth-4" id="li-comment-589125">
		<div id="comment-589125" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e5a814fcd5e95b4c03e3435731734803?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e5a814fcd5e95b4c03e3435731734803?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Peter</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589125">
			January 16, 2018 at 4:58 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The thing about a harmless theorem-proving AI that really does just sit in a lab somewhere and publish inconsequential proofs in obscure journals is that that doesn&#8217;t prevent there being some other AI elsewhere that takes over the world (and quite possibly dismantles the first AI). </p>
<p>Of course, a slightly less harmless theorem-proving AI whose only fundamental motivation is to sit in a lab and publish but with a free hand to make sure it can do so by any means necessary may well be instrumentally interested in preventing other AIs from coming into being. I wouldn&#8217;t want to bet my life or human civilization on those means being ones we would approve of.</p>
<p>I mean, petealexharris talks about whether &#8220;most of them are probably safe for us to coexist with&#8221;, well, for an early 11th century Chinese person, most steppe nomads were probably safe to coexist with, but if there was one who wasn&#8217;t safe to coexist with, well&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-komponisto odd alt depth-2" id="li-comment-589098">
		<div id="comment-589098" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e1b88f8846c7c8aacf6086534ee0b9a1?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e1b88f8846c7c8aacf6086534ee0b9a1?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">komponisto</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589098">
			January 16, 2018 at 2:16 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>His (Chiang&#8217;s) argument is really about capitalism, not AI. It takes the form: &#8220;Capitalism is dangerous for the kinds of reasons tech billionaires think AI is dangerous.&#8221;</p>
<p>Whether you call that &#8220;object-level&#8221; or not, it certainly isn&#8217;t an argument against AI being dangerous &#8212; unless you assume that capitalism isn&#8217;t dangerous, which is the exact opposite of his point&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-danielsodash even depth-3" id="li-comment-589112">
		<div id="comment-589112" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/68e45e0eba4426216d42557264752dc7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/68e45e0eba4426216d42557264752dc7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">danielsodash</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589112">
			January 16, 2018 at 3:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>+1</p>
<p>Chiang is writing about the dangers of capitalism, and using Elon Musk et al&#8217;s fear&#8217;s of a AI as lens to look at that. His article takes a neutral &#8212; you could say complacent &#8212; view on AI. I think Scott&#8217;s rebuttal misses the point.</p>
<p>IMHO: Let&#8217;s all be friends and worry about both. Capitalism running away with AI (even today&#8217;s relatively dumb AI) is an elopement that&#8217;s both possible and worrying.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-3" id="li-comment-589229">
		<div id="comment-589229" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589229">
			January 16, 2018 at 9:07 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>His (Chiangâ€™s) argument is really about capitalism, not AI. It takes the form: â€œCapitalism is dangerous for the kinds of reasons tech billionaires think AI is dangerous.â€</p></blockquote>
<p>Exactly this.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-yodelyak even depth-3" id="li-comment-589460">
		<div id="comment-589460" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">yodelyak</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589460">
			January 16, 2018 at 3:00 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@komponisto: Exactly. But I&#8217;ll take it one further, and say that Chiang&#8217;s concerns about capitalism are part of the problem of AI risk&#8211;maybe the main problem&#8211;and that I think Chiang is connecting them for good reason.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-yodelyak odd alt depth-3" id="li-comment-589464">
		<div id="comment-589464" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">yodelyak</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589464">
			January 16, 2018 at 3:04 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The problem that &#8220;foom&#8221; is possible is made threatening <i><b>both</b></i> because values are hard to code and values creep is hard to guarantee against (meaning even a well-intended AI may go paper-clip all the same) <i><b>and</b></i> because the most likely candidates for building a foom-capable AI are amoral corporations aiming at money first, second, and very nearly only. Solutions include delaying foom to buy more time, slowing foom to erect a balance of power among &#8220;foomed&#8221; AIs, finding ways to guarantee against values creep once foom happens, and lots of other things that I don&#8217;t really understand, and likely I&#8217;ve botched this list. <i>But solutions also include finding ways to make our existing entire society less like unrestrained crony-capitalism, which is to say, more values-driven,<br />
 so the first software to go &#8220;foom&#8221; isn&#8217;t expressly programmed to worship Mammon</i>. </p>
<p>If Chiang were writing to a panel of specialists on AI, his article might be worth attacking for being uninformed. But he&#8217;s gotten himself published in <i>Buzzfeed</i> urging support for a less amoral, less capitalist society. It is probably too much to hope that The Onion will soon make the joke, &#8220;area asshole, overwhelmed by complexity of stopping robot apocalypse, decides he&#8217;ll start by being decent human being, for a change.&#8221; </p>
<p>But if the Onion does run that headline, could we all please not denounce The Onion as insufficiently informed about AI risk?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-cerebral-paul-z even thread-odd thread-alt depth-1" id="li-comment-588970">
		<div id="comment-588970" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2410bd6fb7878c44d132259be73c2c2d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2410bd6fb7878c44d132259be73c2c2d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Paul Zrimsek</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588970">
			January 15, 2018 at 6:37 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Someone on the latest OT posted a link to Charles Stross deploying the same half-baked simile. Is there an SF-writer version of JournoList?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-onemerlin odd alt depth-2" id="li-comment-588978">
		<div id="comment-588978" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9d6124dc2ff53558e819e4962b43d9f1?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9d6124dc2ff53558e819e4962b43d9f1?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">oneMerlin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588978">
			January 15, 2018 at 6:50 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I was about to post that same link; let me do it here for reference:<br />
<a rel="nofollow"href="http://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html" rel="nofollow ugc">http://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html</a></p>
<p>Charlie makes the same basic analogy but from the description above he takes it in a different direction.  He does not attempt to use the analogy to argue that AI fears are absurd, nor to accuse others of projection.  Instead, he uses it as a historical analogy to attempt to project the most likely path of computer-based AI, using corporations, which he calls &#8220;slow AI&#8221;, as a template to draw on.  </p>
<p>You are certainly free to disagree with his conclusions.  But I do feel that the corporation as a model for AI motivation is a better model than human cognition.  Human cognition is wired into a number of limbic systems that produce strong underlying emotional responses to the environment that neither corporate nor computer AI will experience.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-humeanbeingblog even depth-3" id="li-comment-589033">
		<div id="comment-589033" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e0dd0f8b0802e38707bde520f7b21cf4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e0dd0f8b0802e38707bde520f7b21cf4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">humeanbeingblog</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589033">
			January 15, 2018 at 9:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I liked the Stross piece quite a bit. I only half-agree with it, but it provides a pretty useful perspective on the harmful effects of the kind of algorithmic-driven capitalism that has been steadily consuming the world over the last decade.</p>
<p>I saw a tweet the other day that sums up the idea nicely (@GabrielRossman):<br />
If you want a vision of the future, imagine an AI optimizing for how often the rat in a Skinner box will depress the lever, forever.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nornagest odd alt depth-2" id="li-comment-588985">
		<div id="comment-588985" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588985">
			January 15, 2018 at 7:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Charlie&#8217;s been playing with this idea for a while.  <i>Accelerando</i>, one of his first books, comes at it the other direction by featuring unfriendly AI (&#8220;Vile Offspring&#8221;) descended from trading systems, who act like superintelligent corporate raiders and who by the end of the book have (<a href="http://www.rot13.com/" rel="nofollow">ROT13</a>) qevira uhznavgl bhg bs gur vaare fbyne flfgrz ol orvat gbb tbbq ng rpbabzvpf.</p>
<p>It seemed insightful to me at first, and then I actually sat down and thought about it for a few minutes and realized how much motivated reasoning you need before you can single out corporations.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho even depth-3" id="li-comment-589275">
		<div id="comment-589275" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589275">
			January 16, 2018 at 10:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>It seemed insightful to me at first, and then I actually sat down and thought about it for a few minutes and realized how much motivated reasoning you need before you can single out corporations.</p></blockquote>
<p>This is my general problem with &#8220;capitalism is bad!&#8221; rants. Yes, value misalignment results in perverse incentives and therefore (unintended?) negative outcomes. And then willful blindness that this is a problem with any economic system, and almost certainly worse with the systems that are a little freer with the use of state force. See <a rel="nofollow"href="https://slatestarcodex.com/2017/11/21/contra-robinson-on-public-food/">Contra Robinson on Public Food</a>.</p>
<p>Until then I will absolutely agree with Chiang that capitalism is the Worst Economic System in the World. He just needs to add &#8220;except for all the others.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-andrew-cady odd alt depth-4" id="li-comment-589757">
		<div id="comment-589757" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589757">
			January 17, 2018 at 8:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>If school vouchers worked as well as food vouchers, they would succeed in their mission of improving choice without sacrificing quality.</p></blockquote>
<p>I&#8217;m shocked that Scott would make such a poor analogy.  Schools are obviously(!?) nothing like food.  I get to make more choices between foods in a single semiweekly shopping trip than I could expect to make between schools in a single child&#8217;s entire k-12 education.  I can shop <i>at multiple stores in the same week</i> and choose individual foods <i>within each store</i>.</p>
<p>A proper analogy to changing schools is changing employers or changing nations.  (Changing schools lies in between these in seriousness.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-alexwelk even depth-5" id="li-comment-589809">
		<div id="comment-589809" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d1da6bd24869e7deb0c2252cae6de2cd?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d1da6bd24869e7deb0c2252cae6de2cd?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://anarchydice.com' rel='external nofollow ugc' class='url'>AnarchyDice</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589809">
			January 17, 2018 at 9:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But schools don&#8217;t have to be like changing employers or nations, and are only that difficult because they&#8217;ve been made into a whole package. Education shopping could mean you &#8220;buy&#8221; your physics I course from Teachers Inc, your arts introduction from Le Artbrush, and perhaps hire other 3rd parties that do the child-minding in between classes or that house the open network of courses. I mean, we have tons of departments, mixed schedules, and free choices for college students between different professors, why couldn&#8217;t parents select a mix for their kids from an available course-load? Add in recorded lectures with guided activities on site or at home and you can get just about any educational program you could think of.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady odd alt depth-5" id="li-comment-590062">
		<div id="comment-590062" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590062">
			January 17, 2018 at 4:59 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@AnarchyDice, (1) You&#8217;re not buying teachers; you&#8217;re buying your children a peer group.  (2) College students don&#8217;t get to choose professors or classes from different institutions, either.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-herbert-herberson even depth-2" id="li-comment-589437">
		<div id="comment-589437" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4615480883349ded5d8a941a777ff22c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4615480883349ded5d8a941a777ff22c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">herbert herberson</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589437">
			January 16, 2018 at 2:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;ve seen a lot of lefties poo-poo AI threat as obviously ridiculous, but I&#8217;ve never seen very few really grapple with the obvious fact that Stross pointed out: that forms of human organization that lefties believe to be the most malign are both similar to the AIs rationalists fear and by far the primary source of their development.</p>
<p>Especially since the idea of corporate AI causes the edges to get fuzzy.  Maybe the worst fears will never pan out, and we don&#8217;t actually need to worry about something turning the planet into paperclips.  But we already have substantial AI participation in the markets, in the organization of corporations, etc&#8230;  are any of the critics really able to say with a straight face that my fears of what kinds of machine intelligences will be effectively running the likes of Goldman Sachs and Walmart in 20 years are overblown?  Even if they don&#8217;t try to turn us into computronium, we&#8217;re talking about entities that already wield a ton of power in an amoral way becoming far smarter and far more disconnected from human decision-making, based on nothing more or less than linear (don&#8217;t even need to get into the exponential stuff!) progression of current trends</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-yodelyak odd alt depth-3" id="li-comment-589469">
		<div id="comment-589469" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8f5290995a4c236e025ce0f51ff2efaa?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">yodelyak</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589469">
			January 16, 2018 at 3:41 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>My map of history includes a technological arms race for ways of organizing people, and of specific technologies, which race at some points resembles nothing so much as a race to the bottom. Specific important examples (not all of races to the bottom) include 5th century monasteries in Ireland, or the use of &#8220;boot camps&#8221; to instill martial effectiveness in a fighting corps, or the East India Trading company, or the stock market, or Google&#8217;s rule that no one should be more than 200 feet away from food&#8221;&#8230; </p>
<p>These technologies are as important in the course of history as things like gunpowder and stirrups. Having them wielded by an AI with alien values (or pure-profit-values) is a frightening prospect.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-russellsteapot42 even depth-3" id="li-comment-589476">
		<div id="comment-589476" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/421b58401ed2d4fb33bc04dcea5368e2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/421b58401ed2d4fb33bc04dcea5368e2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">russellsteapot42</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589476">
			January 16, 2018 at 3:59 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Most dismissals of AI risk like this seem very tribalistic to me. Basically &#8220;Those weirdos in the other tribe think that the real risk is Poseidon&#8217;s wrath, but we right thinking people know that Huitzilopoctli is the real god to be feared.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest odd alt depth-4" id="li-comment-589477">
		<div id="comment-589477" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589477">
			January 16, 2018 at 4:00 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Huitzilopoctli is indisputably scarier.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-historyfile even depth-5" id="li-comment-589590">
		<div id="comment-589590" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Le Maistre Chat</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589590">
			January 16, 2018 at 11:16 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>He&#8217;s so scary that knowing his name is just Nahua for &#8220;Blue Hummingbird on the Left&#8221; doesn&#8217;t make him less scary.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species odd alt depth-4" id="li-comment-589479">
		<div id="comment-589479" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589479">
			January 16, 2018 at 4:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I find it bizarre that Elon Musk has become a progressive boogie man. This is the guy that is trying to promote solar power and electric cars and yet because he focuses more on AI danger, he&#8217;s suddenly the paradigm of evil super-villains.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-russellsteapot42 even depth-5" id="li-comment-590025">
		<div id="comment-590025" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/421b58401ed2d4fb33bc04dcea5368e2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/421b58401ed2d4fb33bc04dcea5368e2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">russellsteapot42</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590025">
			January 17, 2018 at 3:17 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s because he&#8217;s a clearly extremely competent individual who came to prominence by doing capitalism well. He&#8217;s basically the main character in an objectivist novel, only without going on about looters and parasites and so on.</p>
<p>The fact that he can succeed under capitalism and turn out to be exactly the sort of person we should want in charge of important things is an embarrasment to anti-capitalism, so anti-capitalists feel a need to tar him with flaws, both real and imagined.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m odd alt depth-5" id="li-comment-590058">
		<div id="comment-590058" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590058">
			January 17, 2018 at 4:44 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Heâ€™s basically the main character in an objectivist novel, only without going on about looters and parasites and so on.</p></blockquote>
<p>Well the Ayn Rand heroes didn&#8217;t rant about that stuff <i>in public</i> either.  Who knows what Elon says behind closed doors at the I-swear-I-didnt-know-this-was-about-sex parties&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez even depth-3" id="li-comment-589959">
		<div id="comment-589959" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589959">
			January 17, 2018 at 2:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is such a good point. AI (regular AI) assisted corporations stand to wield so much power in the v near future. And yet you don&#8217;t see MIRI trying to research on how to avoid this, or to steer it for good.</p>
<p>I guess that given it is an actual problem that exists, there isn&#8217;t any easy low hanging fruit which is grabeable.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-4" id="li-comment-589980">
		<div id="comment-589980" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589980">
			January 17, 2018 at 2:25 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You don&#8217;t see it?</p>
<p>While it wasn&#8217;t the <i>top</i> hit on Google/Bing/etc., I really didn&#8217;t have to do too much digging to find <a href="https://www.itic.org/resources/AI-Policy-Principles-FullReport2.pdf" rel="nofollow">this nice list of platitudes,</a> which says things like:</p>
<blockquote><p>While AI systems are creating new ways to generate economic value, if the value favors only certain incumbent entities, there is a risk of exacerbating existing wage, income, and wealth gaps. We support diversification and broadening of access to the resources necessary for AI development and use, such as computing resources, education, and training, including opportunities to participate in the development of these technologies</p></blockquote>
<p>While the sincerity of these statements and their adoption within the AI research community may remain open to debate, I think this is at least sufficient evidence that there exist influential groups which acknowledge the issues you&#8217;re alluding to, and which have formulated a coherent problem statement and a general plan for how to deal with it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jpnunez even depth-5" id="li-comment-590111">
		<div id="comment-590111" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590111">
			January 17, 2018 at 8:09 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t doubt it, but I feel this article is more about the rationalist fear of strong AI, as exemplarized by the fable of the paperclip maximizer than the actual research being currently done on AI.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-5" id="li-comment-590402">
		<div id="comment-590402" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590402">
			January 18, 2018 at 10:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The policy report is written by ITIC, a <a href="https://www.itic.org/about/member-companies" rel="nofollow">coalition</a> which counts Amazon, Google, Facebook, Microsoft, Intuit, Oracle, Toyota, Twitter, Visa, and many many other evil profit-maximizing, AI-researching, user-data-monetizing corporations among its members. Several of these were specifically called out in Chiang&#8217;s article.</p>
<p>So, we can&#8217;t claim AI researchers aren&#8217;t aware of the problem. Demonstrably, the largest AI-researching companies in the world are aware of the problem.</p>
<p>We can&#8217;t claim AI researchers aren&#8217;t acknowledging the problem. The paper I linked is a statement that AI researchers are aware of present-day ethical implications to their research, and promise they&#8217;ll do their best to proceed carefully.</p>
<p>We <i>can</i> claim they&#8217;re not doing enough, or are being disingenuous, or are sincere but still lack the social awareness to deal with this side of the problem effectively, but these are all different goalposts entirelyâ€¦</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even thread-even depth-1" id="li-comment-588973">
		<div id="comment-588973" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588973">
			January 15, 2018 at 6:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Here&#8217;s a reasonable version of the argument.</p>
<p>Capitalism is excellent at optimizing for maximizing profits and grinds away at other values*. For AI to be run away and dangerous it would have to do exactly that &#8211; maximize profits to gain resources to use to gain more resources, etc. IOW &#8211; AI already basically exists. It&#8217;s called the Coca Cola Corp.</p>
<p>*It observably doesn&#8217;t do either of those but we&#8217;ll leave that aside</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-wrong-species odd alt depth-2" id="li-comment-588983">
		<div id="comment-588983" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588983">
			January 15, 2018 at 6:55 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You can literally cut and paste thousands of different answers in for capitalism and retain the same argument. You canâ€™t just take one shared characteristic of capitalism and AI and claim that they are the same because of it. That would be like saying bicycles and rockets are the same because they are inventions designed by humans to go places.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-3" id="li-comment-588987">
		<div id="comment-588987" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588987">
			January 15, 2018 at 7:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s about the mechanism.</p>
<p>For an AI to be a danger it has to control resources &#8211; at the very minimum it has to pay for its AWS account to keep itself running. To do this it needs to make money &#8211; or transcend money in some other way that gets people to provide it with resources &#8211; which is exactly like making money*. Composite organizations with significantly more intelligence than any living human already exist that do exactly that. I, Pencil is a great demonstration of that &#8211; no person knows how to make a pencil but there are pencil making companies in the world.</p>
<p>What do you think causes the AI danger? That it&#8217;ll be smarter than individual people? Already done. That it&#8217;ll set up to gain resources? Already done.</p>
<p>* It could go the parasite route too and make up effective appeals for people to just give it money &#8211; maybe it&#8217;ll claim that it can make mosquito nets to save more and more people from malaria then somehow make those people reproduce younger and younger yet they&#8217;ll never act to effectively reduce their own malaria risk so they fully depend on contributions funneled through the AI &#8211; whatever &#8211; there are human organizations that go that route too.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-wrong-species odd alt depth-4" id="li-comment-588994">
		<div id="comment-588994" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588994">
			January 15, 2018 at 7:38 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>So if AI is just a corporation do you think that we could get Amazon employees to beat AlphaGo Zero in Go? The fear isnâ€™t that an AI will be smarter than an individual. Itâ€™s that it will be such a high degree smarter than people that we wonâ€™t know what itâ€™s doing until weâ€™re all about to die.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-588998">
		<div id="comment-588998" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588998">
			January 15, 2018 at 7:43 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If you had a corporation as large as Alphabet dedicated to winning at go they could do so &#8211; by building an AI to do it.</p>
<p>Of course no one at Alphabet knows how to build an AI &#8211; see the I, Pencil argument &#8211; yet the AI gets built because Alphabet is smarter than any person at Alphabet.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species odd alt depth-5" id="li-comment-588999">
		<div id="comment-588999" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588999">
			January 15, 2018 at 7:48 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thatâ€™s my point. You canâ€™t get a bunch of people together and have them beat an AI. Only an AI can beat an AI. Thatâ€™s because theyâ€™re working on a different level than us. Now imagine that but for everything. Ants can do some pretty interesting things when they work together but they canâ€™t build a rocket. Thatâ€™s the difference between corporations and super intelligent AI.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589003">
		<div id="comment-589003" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589003">
			January 15, 2018 at 7:55 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>No person can build a rocket either yet SpaceX manages the feat.</p>
<p>Almost everything &#8211; no matter how simple &#8211; is beyond human understanding and yet corporations understand how to do these things that no person can do.</p>
<p>What&#8217;s different about an AI?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-rickhull odd alt depth-5" id="li-comment-589039">
		<div id="comment-589039" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Rick Hull</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589039">
			January 15, 2018 at 9:35 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Dudeman, <i>society</i> is the real AI.  No, wait, it&#8217;s <i>civilization</i>.    Or maybe it&#8217;s <i>nature</i>.  All you are showing is an optimization process, emergent order, and capabilities beyond a single individual homo sapiens.  We&#8217;ve known that such things are powerful for a long time.  They don&#8217;t tell us much unique or interesting about actual AI.  What&#8217;s the version of the singularity for corporations-as-AI?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species even depth-5" id="li-comment-589040">
		<div id="comment-589040" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589040">
			January 15, 2018 at 9:36 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>AI is capable of things that corporations without AI can not do. Google canâ€™t tile the galaxy with paper clips. A super intelligence could. And even things corporations can do, the Super AI does it better and faster. I donâ€™t understand why you donâ€™t understand this. Itâ€™s not just that theyâ€™re better than us. Itâ€™s that theyâ€™re better than us on a ridiculous scale. I donâ€™t know how else to explain it. You are basically looking at humans and chimpanzees and seeing that theyâ€™re 99% similar, confused why anyone would think humans would be better at anything.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-5" id="li-comment-589073">
		<div id="comment-589073" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589073">
			January 15, 2018 at 11:23 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>AI is capable of things that corporations without AI can not do. Google canâ€™t tile the galaxy with paper clips. A super intelligence could.</p></blockquote>
<p>Google is exactly as capable of tiling the galaxy with paperclips as an AI is.</p>
<p>In order to tile the galaxy with paperclips the AI has to pay for it in the sense of consuming energy and matter. If it&#8217;s pulling it from the human economy then it has the same exact level of capability as google &#8211; it can spend as much as it produces in some other endeavor.</p>
<p>An AI that operates outside the human economy will have trouble existing on Earth because Earth happens to be entirely owned.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-feepingcreature even depth-5" id="li-comment-589104">
		<div id="comment-589104" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e5d333bd73746afe1410b39555a3e4f5?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e5d333bd73746afe1410b39555a3e4f5?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">FeepingCreature</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589104">
			January 16, 2018 at 2:29 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think that the argument that you&#8217;re looking for is &#8220;AI screens off corporation.&#8221;</p>
<p>When told that a corporation is running an AI, vs. that a person is running an AI, vs. that a corporation is not running an AI, the conceptual heavy lifting of predicting the outcome is done by &#8220;AI&#8221;, not &#8220;corporation&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vv_vv odd alt depth-5" id="li-comment-589155">
		<div id="comment-589155" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/370347024c2c77316064a69490d6d76d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/370347024c2c77316064a69490d6d76d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">vV_Vv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589155">
			January 16, 2018 at 6:35 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think the steelman argument is that bad AIs are an extension of capitalism, both in the sense that they are likely to be created by corporations and in the sense that their ruthless runaway optimization is going to be a more extreme version of the ruthless runaway optimization that capitalism does.</p>
<p>I don&#8217;t find it a completely compelling argument: bad AIs could be created by other means, for instance by an arms race between rival governments running secret Manhattan-style projects, and runaway capitalism could cause lots of problems even without building AIs.</p>
<p>However, as far as publicly known, current AI development is lead by the largest <strike>paperclip</strike>click-maximizing corporations, therefore the concern that capitalism and AI (even narrow AIs, not necessarily god-like superintelligences) interact badly is real.</p>
<p>To further steelman the argument, it could be argued that worrying about a far risk such as god-like superintelligences tiling the galaxy with paperclips while ignoring the near risks of modern capitalism is an inefficient allocation of concerns. It&#8217;s like worrying about asteroid impacts while living in an unstable building in a seismic area.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species even depth-5" id="li-comment-589195">
		<div id="comment-589195" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589195">
			January 16, 2018 at 7:46 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@reasoned argumentation</p>
<p>I think I figured out whatâ€™s going on here. You decided to define â€œAIâ€ in some weird, idiosyncratic way and some people push back on your argument because they use the normal definition. For some reason you think you can win by using your weird definition. I donâ€™t know what you think youâ€™re accomplishing but it doesnâ€™t do anything. A group of people who work together to make money is not literally the same thing as a machine. And no, just because the corporation might use the machine to make profit doesnâ€™t make it synonymous with the machine itself in the same way that a farmer is not also a pig. Do you think farmers are also pigs, cows and chickens?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-5" id="li-comment-589239">
		<div id="comment-589239" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589239">
			January 16, 2018 at 9:25 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I think I figured out whatâ€™s going on here. You decided to define â€œAIâ€ in some weird, idiosyncratic way and some people push back on your argument because they use the normal definition</p></blockquote>
<p>Has absolutely nothing to do with defining AI in a weird way &#8211; it has to do with the mechanism for how an AI would interact with people.</p>
<p>At the start all an AI could do is order humans to take action and it only has two options for getting them to follow those orders:</p>
<p>1) Pay them to follow those orders<br />
1a) Persuade them to part with money then get others to obey through (1)<br />
2) Use the threat of overwhelming physical force to compel obedience</p>
<p>That&#8217;s it. Method (1) requires doing exactly what a corporation does and those are already under selective pressure to produce outputs that people are willing to part with money for. Method (1a) is what charities already do.</p>
<p>Method (2) is called setting up a competing government &#8211; which tends to get you shot.</p>
<p>Maybe an AI will really want to tile the universe with paperclips but to do that it also has to come to control enough of the human economy to afford that. The human economy happens to already be run by organizations that are under selective pressure to be really good at obtaining the resources they use &#8211; corporations.</p>
<p>If it goes by route 2 immediately then its up against governments who have already have organizations set up to fend off exactly this type of challenger.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-tarpitz even depth-5" id="li-comment-589336">
		<div id="comment-589336" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ba16907d63bc1aaa64902e77f1470bde?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ba16907d63bc1aaa64902e77f1470bde?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tarpitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589336">
			January 16, 2018 at 11:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>At the start all an AI could do is order humans to take action and it only has two options for getting them to follow those orders:</p>
<p>1) Pay them to follow those orders<br />
1a) Persuade them to part with money then get others to obey through (1)<br />
2) Use the threat of overwhelming physical force to compel obedience</p></blockquote>
<p>Surely it could also <i>persuade</i> people to take actions it wanted, by convincing them that it would be in their interest in some way not necessarily involving financial payment, or that the action the AI desired was in fact the right thing to do? Pay and fear of violence are hardly the only motivators for human behaviour.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-5" id="li-comment-589369">
		<div id="comment-589369" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589369">
			January 16, 2018 at 12:10 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Tarpitz &#8211; </p>
<p>I made persuasion into 1a because that&#8217;s how human con artists operate. A con artist wants a new house &#8211; he doesn&#8217;t send out a Nigerian scam email to con someone into building him a house &#8211; he cons the mark out of money and uses the money on the market to buy a house.</p>
<p>There&#8217;s no reason to think that the AI would be particularly persuasive to people that have the skills that the AI requires for its plan so it will almost certainly use the known existing method.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-john-schilling even depth-5" id="li-comment-589412">
		<div id="comment-589412" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">John Schilling</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589412">
			January 16, 2018 at 1:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But there is a wide range of services that would be useful for an AI plotting world domination but, for the most part, cannot be purchased for money alone.  Murder and treason in particular &#8211; literal mercenary assassins are rare in first-world countries, mostly inept, and outnumbered by policemen and informants trying to sucker you into hiring a non-assassin.  You need some sort of moral legitimacy or in-group loyalty to be reasonably confident of success in that realm, no matter how much money you have.  And treason for hire is generally limited to a scattered group of prospects, probably none of which have the particular secret or influence you are looking for &#8211; you get much better results when you add ideology, compromise, and ego to your toolkit.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m odd alt depth-5" id="li-comment-589416">
		<div id="comment-589416" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589416">
			January 16, 2018 at 1:13 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;m unconvinced that a <i>really good persuader</i> would need to rely on a bunch of assassinations to achieve their desired ends.</p>
<p>If anyone can think of a way to get what they want <i>without</i> relying on a lot of murder, it&#8217;s a superintelligent AI.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady even depth-5" id="li-comment-589444">
		<div id="comment-589444" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589444">
			January 16, 2018 at 2:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>All that an AI needs to take over the Earth economy is hypnodrones.  The humans will obey because nanomachine artificial pheremones enter their brains and directly cause them to obey</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species odd alt depth-5" id="li-comment-589470">
		<div id="comment-589470" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589470">
			January 16, 2018 at 3:44 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@reasoned argumentation</p>
<p>I don&#8217;t have a problem with saying that an AI would want to use capitalism for its own gains. I just want to know that you understand that machines are different from an organization of people that come together for a specific purpose and that just because they interact with each other, doesn&#8217;t mean that they are the same.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-4" id="li-comment-589055">
		<div id="comment-589055" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589055">
			January 15, 2018 at 10:21 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I, Pencil is a great demonstration of that â€“ no person knows how to make a pencil but there are pencil making companies in the world.</p></blockquote>
<p>The point of &#8220;I, Pencil&#8221; is that neither individuals nor pencil making companies know how to make a pencil. The super organism isn&#8217;t the company, it&#8217;s the market, the network of actors, individual and corporate, interacting via exchange and prices.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-5" id="li-comment-589070">
		<div id="comment-589070" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589070">
			January 15, 2018 at 11:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The point I was trying to make by referencing I, Pencil is that complex systems that have the important features of AI &#8211; namely superior knowledge and intelligence already exist. On a smaller scale than whole markets corporations know how to do things that no person working there knows how to do.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mostlycrediblehulk even depth-2" id="li-comment-589050">
		<div id="comment-589050" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/759510b5f46461e0e5ed54ed632cdf7c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/759510b5f46461e0e5ed54ed632cdf7c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MostlyCredibleHulk</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589050">
			January 15, 2018 at 10:05 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Communism is also excellent at optimizing for a goal &#8211; in fact, if you need a regime that would subjugate the whole society to achieve a single goal (and you don&#8217;t care how much it would cost in resources or human suffering), a totalitarian regime would probably be your tool of choice, and communist ones have the best support on university campuses, so why not choose one of them? Thus, according to the same logic, a) communism (or it&#8217;s poor aspiring cousin, socialism) is the Real Problem and b) AI, capitalism and communism (and every other totalitarian regime) are the same. Also, AI of CPSU existed, but was defeated and extinguished by AI of Coca Cola Corp, which is now locked in battle with AI of Chinese Communist Party.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ksvanhorn odd alt depth-3" id="li-comment-589180">
		<div id="comment-589180" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://bayesium.com' rel='external nofollow ugc' class='url'>ksvanhorn</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589180">
			January 16, 2018 at 7:26 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Communism is excellent at optimizing for a goal if your goal is production of corpses.</p>
<p><a rel="nofollow"href="https://www.hawaii.edu/powerkills/NOTE1.HTM" rel="nofollow ugc">https://www.hawaii.edu/powerkills/NOTE1.HTM</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mtraven even depth-3" id="li-comment-589192">
		<div id="comment-589192" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">mtraven</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589192">
			January 16, 2018 at 7:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Totalitarian Communism and unregulated capitalism are both systems for entraining humans towards non-human goals. Totalitarianism uses the simple &#8220;do this or get killed&#8221; technique. Capitalism is more subtle, people get more freedom to choose their subgoals, but everyone tends to get channeled into pursuing money. </p>
<p>These systems resemble paper-clip-tilers in their disregard for environmental externalities. If both pure systems existed, I expect the capitalist one would end up doing more damage because it makes better use of the human intelligences that comprise it. However, in the actual recent world, communism collapsed (after doing a great deal of damage) and capitalism managed to regulate itself to avoid the worst consequences, although the final tabulation won&#8217;t be in until we see how bad climate change gets.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman odd alt depth-4" id="li-comment-589245">
		<div id="comment-589245" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589245">
			January 16, 2018 at 9:35 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Totalitarian Communism and unregulated capitalism are both systems for entraining humans towards non-human goals.</p></blockquote>
<p>That&#8217;s like complaining that your home heating system is designed for the non-human goal of keeping the number on the dial at seventy degrees. </p>
<p>Unregulated capitalism gets humans to act for the human goals signaled by the prices people are willing to pay for things they buy, the amount people charge for the labor they sell, the amount people are willing to accept in exchange for postponing consumption in order to invest instead, and the like. It does its maximization by getting firms and individuals to respond to those signals. Just as your thermostat gets temperature to your desired level by responding to the signals it gets from its thermometer.</p>
<p>If the objective of the heating system was to control the number on the dial, it could do that without bothering to heat the house. If the objective of firms was to maximize money they would all lobby the government to print lots and lots more of it. Just think of all the money that German firms made during the Weimar hyperinflation.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589274">
		<div id="comment-589274" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589274">
			January 16, 2018 at 10:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p> If the objective of firms was to maximize money they would all lobby the government to print lots and lots more of it. </p></blockquote>
<p>They do do that though. All of the players in the entire financial sector only still exists because of precisely that &#8211; all of them would have been wiped out in 2008. Instead only the institution stupid enough to pay off the Republican party got wiped out &#8211; giving bribe jobs to Jeb! and John Kasich as if that would protect them &#8211; ha!</p>
<blockquote><p> If the objective of firms was to maximize money they would all lobby the government to print lots and lots more of it. Just think of all the money that German firms made during the Weimar hyperinflation.</p></blockquote>
<p>Yes, this does point out a technical point that people have been glossing over &#8211; corporations don&#8217;t optimize for the number in their bank accounts &#8211; they optimize for wealth held or power to purchase resources &#8211; neither of which are served by having big numbers in a bank account that can&#8217;t be used to purchase goods and services. In normal circumstances though the two things are the same.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mtraven odd alt depth-5" id="li-comment-589720">
		<div id="comment-589720" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">mtraven</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589720">
			January 17, 2018 at 7:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This whiggish view of capitalism, that market goals always represents actual human goals, seems very common around here. But it&#8217;s wrong, and kind of basic.</p>
<p>It is true that market values are grounded (for now) on human values, but because capitalism is a complex and ingenious system, it evolves systems-level goals of its own that have little do with actual human flourishing.</p>
<p>Off the top of my head:</p>
<p>&#8211; A huge amount of human labor is devoted to keeping people away from resources rather than wealth creation (so called &#8220;<a href="http://samoa.santafe.edu/media/workingpapers/05-07-030.pdf" rel="nofollow">guard labor</a>&#8220;). </p>
<p>&#8211; The entire advertising industry and the addictive side of the entertainment industry is serving its own goals</p>
<p>&#8211; A huge amount of financial sector activity contributes nothing to human flourishing (I&#8217;m thinking specifically of HFT, with vast resources devoted to shaving nanoseconds off of transaction times to gain an advantage over other traders)</p>
<p>Note that I am not arguing against capitalism &#8212; maybe there is no better way to organize human activity. I am trying to make a specific point, which is that capitalism as a system spawns a whole bunch of goals which are devoted more to its own maintenance than to the servicing of base human goals such as food, shelter, meaning, and whatever it takes for happiness and a good life.</p>
<p>Because capitalism runs on people (for now), these system-goals have to be converted into human goals, through the medium of money. Take the Brinks security company, as the most obvious example of guard labor (actual guards). The owners and management and employees of that company are working not for any human base goal, they are working for the security and stability of the monetary system. And the monetary system rewards them for their efforts, and presumably the people who pay them consider it worthwhile. But it contributes nothing directly to human betterment.</p>
<p>System goals and human goals exist in a dense and tense ecosystem. In stable prosperous times, there is a rough equilibrium and the goals of both humans and the system are aligned enough that everything works. But because of technical advances and differences in economic class interests, these stable times don&#8217;t last. And when capital figures out that it can do without labor, you get unemployment or immiseration.</p>
<p>The kind of AI we are talking about here (not the only kind possible) is essentially capitalism without capitalists. It&#8217;s the guilt-induced nightmare of capitalism where the tools that used against labor end up turning against their creators.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez even depth-5" id="li-comment-589976">
		<div id="comment-589976" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589976">
			January 17, 2018 at 2:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is WILDLY optimistic. Grossly optimistic. Disgustingly naive.</p>
<p>Unregulated capitalism has shamelessly captured people from their home and shipped them as slaves to the other side of the world, for centuries, until someone came by and actually tried to regulate it.</p>
<p>There&#8217;s no reason to believe it cannot do so again if the economic incentives are right. Hell, right now there are still slaves out there.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman odd alt depth-5" id="li-comment-589996">
		<div id="comment-589996" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589996">
			January 17, 2018 at 2:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Take the Brinks security company, as the most obvious example of guard labor (actual guards). The owners and management and employees of that company are working not for any human base goal, they are working for the security and stability of the monetary system.</p></blockquote>
<p>It has nothing to do with the stability of the monetary system&#8211;for that you would want to look at people working to prevent counterfeiting. </p>
<p>What Brinks is doing is preventing stealing. This has a close connection to human goals. In order to get people fed it has to be in the interest of grocery stores, farmers, food processors, etc. to play their role in the process. If they cannot rely on the money they get for their efforts not being stolen, they are less able and willing to do so.</p>
<p>To put it more generally, what Brinks is supporting isn&#8217;t the monetary system, it&#8217;s the security of property rights. And the security of property rights is a key part of the system that makes it in the interest of people to do things that serve the goals of other people.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mugasofer even depth-2" id="li-comment-589090">
		<div id="comment-589090" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589090">
			January 16, 2018 at 1:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If corporations were actually superintelligent &#8211; that is, better than any individual human at literally everything &#8211; then it would be impossible for individual humans to oppose them successfully. Leaving aside the fact that people do sometimes oppose corporations successfully, this would obviously make Chiang&#8217;s article an exercise in futility.</p>
<p>Unless, of course, corporations are <i>not</i> superintelligent, and thus superintelligent AI would in fact be <i>much more dangerous</i>.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-tbrownaw odd alt depth-3" id="li-comment-589140">
		<div id="comment-589140" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ee92b8b34fce0812cb32f401d121f6cc?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ee92b8b34fce0812cb32f401d121f6cc?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">tbrownaw</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589140">
			January 16, 2018 at 5:58 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I would think this same logic would declare it impossible for a dog or a flu virus to successfully oppose any humans.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even depth-3" id="li-comment-589242">
		<div id="comment-589242" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589242">
			January 16, 2018 at 9:32 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>If corporations were actually superintelligent â€“ that is, better than any individual human at literally everything â€“ then it would be impossible for individual humans to oppose them successfully. </p></blockquote>
<p>Asserted without evidence.</p>
<p>Corporate super-intelligence, on the other hand, is easy to demonstrate &#8211; no human can do what google does (for example) &#8211; no human could even administer their severs.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-john-schilling odd alt depth-3" id="li-comment-589279">
		<div id="comment-589279" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">John Schilling</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589279">
			January 16, 2018 at 10:18 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It is exceedingly rare for individual humans to oppose (large) corporations by their own efforts.  Most such stories involve an individual human and his or her lawyers convincing a court to mobilize or threaten to mobilize the resources of a state against a corporation.  Sometimes the individual human leads a boycott, protest, or rampaging mob of other humans.</p>
<p>Nonetheless, it is demonstrably possible for humans <i>collectively</i> to oppose, constrain, and defeat corporations.  This is a fundamental difference from the postulated AI threat, which if it manifests is alleged to be invincible vs any combination of humans and human institutions.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-forwardsynthesis even depth-3" id="li-comment-589294">
		<div id="comment-589294" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7bf780455c0b749f97d2d6d743511e78?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7bf780455c0b749f97d2d6d743511e78?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://forwardsynthesis.wordpress.com/' rel='external nofollow ugc' class='url'>Forward Synthesis</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589294">
			January 16, 2018 at 10:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Corporate super-intelligence is non-general. So people can do things outside of its purview. Google can make calculations that no individual human can make, yet there are still laws restraining Google (in spite of cyber-punk fantasies, Google does not rule the USA, and could easily be defeated by recourse to sheer force if needed), because we have another non-general super-intelligence acting against it; government.</p>
<p>If we extend this analogy, then AI safety comes from leveraging different AI against each other. Of course, the whole analogy might be bad to begin with, and we&#8217;re ignoring FOOM.</p>
<p>Paper clip maximizers specialize for paper clip (or X) maximizing, but they must have general intelligence, because as amazing as they would be at maximizing paperclip production when given the right tools, they aren&#8217;t going to be able to outwit humans without the general intelligence needed to understand things outside of the purview of paper clip maximizing, such as human minds. This general intelligence (or as many umpteen gazillion specialized modules as required) would have to understand humans on every level (not the narrow level current institutions understand humans on) in order to outsmart them. It&#8217;s going to be making incredibly subtle and seemingly innocuous arguments that convince humans to give it harmless stuff and the right tools to turn it into dangerous stuff that allows it to beat all the humans and make &#8220;paperclips&#8221; unopposed. If its end goal survives this process, then it would eventually be the end of us, but ironically, its greater (or at least more general) intelligence, would make it slower than AIs with more multifaceted and/or fluid terminal values.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez odd alt depth-3" id="li-comment-589986">
		<div id="comment-589986" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589986">
			January 17, 2018 at 2:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Well they are better than people at distributing money right now, and they have been better too at hiding from their externalities.</p>
<p>The paperclip maximizer would also not be more intelligent than humans at several kind of tasks, and would probably be beaten at, dunno, Angry Birds if angry birds did not come into play for building more clips. It just happens that it is better at tasks that help it tile the universe into clips. This lack of complete super intelligence does not mean the paperclip maximizer isn&#8217;t dangerous, just as corporations not being good at everything does not mean they aren&#8217;t dangerous.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species even thread-odd thread-alt depth-1" id="li-comment-588975">
		<div id="comment-588975" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588975">
			January 15, 2018 at 6:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Insight is precisely what Muskâ€™s strawberry-picking AI lacks, as do all the other AIs that destroy humanity in similar doomsday scenarios. I used to find it odd that these hypothetical AIs were supposed to be smart enough to solve problems that no human could, yet they were incapable of doing something most every adult has done: taking a step back and asking whether their current course of action is really a good idea. </p></blockquote>
<p>When people say stuff like this, itâ€™s obvious they donâ€™t care enough to actually examine the arguments behind AI worries. If they did, they would know itâ€™s one of the most commonly asked questions that has been answered a million times. Iâ€™m not sure whatâ€™s to gain from engaging with them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sniffnoy odd alt depth-2" id="li-comment-588981">
		<div id="comment-588981" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588981">
			January 15, 2018 at 6:52 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yup.  This is like, Mr. Chiang, you really didn&#8217;t investigate this very much before writing this, did you?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-cerebral-paul-z even depth-2" id="li-comment-588988">
		<div id="comment-588988" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2410bd6fb7878c44d132259be73c2c2d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2410bd6fb7878c44d132259be73c2c2d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Paul Zrimsek</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588988">
			January 15, 2018 at 7:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The arguments behind capitalism suffer a similar neglect, causing Chiang to fall into a fallacy of composition: <i>Capitalists</i> optimize only for money, therefore <i>capitalism</i> optimizes only for money.</p>
<p>You could probably spend four whole years in the Angry Studies program at Evergreen State without meeting anyone as rabidly anti-capitalist as a paperclip-maximizing AI would be. Almost all of our productive potential is thrown away meeting a huge variety of human wants that have nothing to do with paperclips!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-rickhull odd alt depth-3" id="li-comment-589042">
		<div id="comment-589042" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Rick Hull</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589042">
			January 15, 2018 at 9:43 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wait, you got the Angry Studies Scholarship to Evergreen State too?  It really puts the asses in seats.  In my assessment, the program assimilates the next generation of character assassins.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho even depth-4" id="li-comment-589319">
		<div id="comment-589319" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589319">
			January 16, 2018 at 11:10 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Underrated.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mnh odd alt depth-4" id="li-comment-589321">
		<div id="comment-589321" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4e437f50d54e58147471ab5e6a340843?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4e437f50d54e58147471ab5e6a340843?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MNH</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589321">
			January 16, 2018 at 11:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Bravo</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bossbrett even depth-3" id="li-comment-589069">
		<div id="comment-589069" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Brett</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589069">
			January 15, 2018 at 11:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The arguments behind capitalism suffer a similar neglect, causing Chiang to fall into a fallacy of composition: Capitalists optimize only for money, therefore capitalism optimizes only for money.</p></blockquote>
<p>That&#8217;s a good point. Capitalists optimize for profits, seeking for the highest-profit opportunities (at least theoretically &#8211; it gets complicated). But a working capitalist market economy acts to shrink profits over time, something even the Marxists identify (with their talk of the &#8220;falling rate of profit&#8221; and such).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ketil odd alt depth-4" id="li-comment-589092">
		<div id="comment-589092" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ketil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589092">
			January 16, 2018 at 2:00 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Capitalism optimizes allocation of scarce resources.   Profits is what happens when somebody discovers and remedies suboptimal resource allocation.  In a perfect market, there are no profit.<br />
 Profits is just a symptom, a fever indicating that something was wrong with the market, but that it is now getting better.</p>
<p>ðŸ™‚</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-heelbearcub even depth-5" id="li-comment-589333">
		<div id="comment-589333" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/faddea1dac980705b600897c89039f60?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/faddea1dac980705b600897c89039f60?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">HeelBearCub</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589333">
			January 16, 2018 at 11:29 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Therefore capitalism, ultimately, doesn&#8217;t even exist?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-atlas odd alt depth-2" id="li-comment-589005">
		<div id="comment-589005" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c2412c63915daaebae0be042ffa5e6fd?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c2412c63915daaebae0be042ffa5e6fd?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Atlas</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589005">
			January 15, 2018 at 8:01 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>When people say stuff like this, itâ€™s obvious they donâ€™t care enough to actually examine the arguments behind AI worries. If they did, they would know itâ€™s one of the most commonly asked questions that has been answered a million times. Iâ€™m not sure whatâ€™s to gain from engaging with them.</p></blockquote>
<p>Well, for one thing it seems to me that the prominence and dangerous implications of an idea/argument are factors alongside its factual and logical quality in determining whether or not it&#8217;s worth engaging with it. (Considering also that in a public debate one is generally more interested in convincing the audience than the opponent.)</p>
<p>I imagine that pretty much everyone here would agree that the article linked in the OP is not very substantively well argued, but it&#8217;s not very substantively well argued in <i>Buzzfeed</i>. (Which <a href="https://www.recode.net/2017/11/30/16709310/buzzfeed-losing-web-traffic-readers-layoffs-uniques-prefer-news-over-viral-sites" rel="nofollow">apparently </a>was getting consistently upwards of 60 million unique visitors per month throughout 2017.) And unlike, say, wacky but harmless Elvis conspiracy theories, if people took the bad argument &#8220;capitalism is the <i>real </i>AI risk&#8221; seriously they might ignore the good arguments about AI risk and it could lead to bad consequences.</p>
<p>So I think this sort of &#8220;shooting fish in a barrel&#8221;posting <i>can </i>be valuable, at least maybe, given these considerations.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mtraven even depth-2" id="li-comment-589197">
		<div id="comment-589197" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/179d1e94c5b4d364c0e8cd0f95a775b7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">mtraven</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589197">
			January 16, 2018 at 7:49 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Excuse my ignorance but would you mind linking to a few of those million answers?</p>
<p>The argument against this that I am familiar with is the orthogonality thesis, but that has always struck me as a particularly weak argument.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-historyfile odd alt thread-even depth-1" id="li-comment-588976">
		<div id="comment-588976" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Le Maistre Chat</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588976">
			January 15, 2018 at 6:48 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Psychoanalyzing the outgroup is a specific form of <i>ad hominem</i> with at least a 70-year history. I think the only way to get commies to stop writing this essay is to make Blue elites believe in AI risk.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho even depth-2" id="li-comment-589324">
		<div id="comment-589324" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589324">
			January 16, 2018 at 11:15 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The problem is &#8220;better living through computers&#8221; is more of a Blue Tribe-aligned value. You need to get the Red Tribe excited about them thar superintelligent AIs to spark all the HuffPo and Buzzfeed hand wringing about how &#8220;It&#8217;s Time to Address the Elephant in the Room: Superintelligent AI is a Problematic Manifestation of White Supremacy and Male Patriarchy.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-trebawa odd alt depth-2" id="li-comment-589521">
		<div id="comment-589521" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d494a0a5b3f1eb6d503a0a705ec7c3ab?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d494a0a5b3f1eb6d503a0a705ec7c3ab?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">trebawa</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589521">
			January 16, 2018 at 5:54 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It would appear this is precisely what Blue academics and technologists &#8211; at least the ones convinced this is an issue &#8211; are trying to do.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-2" id="li-comment-589523">
		<div id="comment-589523" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589523">
			January 16, 2018 at 5:57 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Is Elon Musk <i>not</i> blue tribe?  He&#8217;s certainly not red&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-historyfile odd alt depth-3" id="li-comment-589592">
		<div id="comment-589592" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Le Maistre Chat</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589592">
			January 16, 2018 at 11:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>He&#8217;s apparently an unburnt witch? I&#8217;m not sure what his exact sin was though.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even thread-odd thread-alt depth-1" id="li-comment-588979">
		<div id="comment-588979" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588979">
			January 15, 2018 at 6:51 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Consider: lots of Hollywood celebrities speak out about global warming. And weâ€™re gradually finding out that some pretty awful things go on in Hollywood. Does that mean â€œThe Real Problem Isnâ€™t Global Warming, Itâ€™s Hollywood Harassmentâ€?</p></blockquote>
<p>No &#8211; but what it does do is demonstrate exactly that everyone knows what to say about <strike>Global Warming</strike> Climate Change to be on the side of the angels and to get a pass on otherwise despicable behavior. The exact same forces exist in academia regarding research into Climate Change &#8211; just like the same forces exist in social psychology where nothing replicates but everything still fits the narrative that everyone knows is the right side of history. It&#8217;s no coincidence that the replication crisis hit the exact area where the social / political pressure is so high to stick with the group-think.</p>
<p>There is exactly a common force there.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady odd alt thread-even depth-1" id="li-comment-588990">
		<div id="comment-588990" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588990">
			January 15, 2018 at 7:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>He bases his metaphor on the idea that worries about AI risk comes from Silicon Valley. They donâ€™t. The tech community got interested later. The original version of the theory comes from Nick Bostrom, a professor at Oxford, and Eliezer Yudkowsky, who at the time I think was living in Chicago. It was pushed to public notice by leading AI scientists all around the world. And before it was endorsed by Silicon Valley tycoons, it was endorsed by philosophers like David Chalmers and scientists like Stephen Hawking.</p></blockquote>
<p>Hm.  Bostrom was born in 1973.  <i>The Terminator</i> starring Arnold Schwarzenegger was released in 1984, when Bostrom was 9 years old.</p>
<p>I don&#8217;t suppose <i>The Terminator</i> was the first expression of its own premise in science fiction.  Asimov had a (friendly) A.I. download all of the meatbags&#8217; brains into itself (leaving no fleshy life behind) in 1954.   What&#8217;s the earliest reference to A.I. taking over that we can find?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest even depth-2" id="li-comment-588992">
		<div id="comment-588992" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588992">
			January 15, 2018 at 7:23 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a href="https://en.wikipedia.org/wiki/The_Machine_Stops" rel="nofollow">The Machine Stops</a> (1909)?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nancylebovitz odd alt depth-3" id="li-comment-589130">
		<div id="comment-589130" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nancy Lebovitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589130">
			January 16, 2018 at 5:14 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Not &#8220;The Machine Stops&#8221;, as I recall. That was about low-quality social media taking over. It&#8217;s amazing how much Forester got right.</p>
<p>&#8220;The Sorcerer&#8217;s Apprentice&#8221; is about an simple-minded unlimited utility function, so it&#8217;s a lot like a paper-clipper.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-andrew-cady even depth-4" id="li-comment-589454">
		<div id="comment-589454" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589454">
			January 16, 2018 at 2:44 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The Sorcererâ€™s Apprentice</p></blockquote>
<p>The magic broom doesn&#8217;t derive its power from intelligence though.  It&#8217;s more like grey goo than paperclips.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-luke-perrin odd alt depth-2" id="li-comment-589058">
		<div id="comment-589058" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/15bf9f0f0f83eea83168535328a76f02?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/15bf9f0f0f83eea83168535328a76f02?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Luke Perrin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589058">
			January 15, 2018 at 10:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The version of <i>The Sorcerer&#8217;s Apprentice</i> in Lucian&#8217;s <i>Philopseudes</i>.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-powerful-olfactory-hallucinations even depth-2" id="li-comment-589132">
		<div id="comment-589132" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08ee0528d5479ef0eea4b7b0ce1a8f87?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08ee0528d5479ef0eea4b7b0ce1a8f87?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Powerful Olfactory Hallucinations</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589132">
			January 16, 2018 at 5:17 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Frederic Brown&#8217;s short-short story <a href="http://thepequodblog.blogspot.se/2008/01/fredric-browns-answer-short-story-of.html" rel="nofollow">Answer</a> (1954) is a classic version of the trope, though it&#8217;s probably not the first.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vv_vv odd alt depth-2" id="li-comment-589161">
		<div id="comment-589161" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/370347024c2c77316064a69490d6d76d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/370347024c2c77316064a69490d6d76d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">vV_Vv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589161">
			January 16, 2018 at 6:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>They didn&#8217;t take over the world, but rouge AIs have always existed in fiction, at least since the Golem of Prague myth. Frankenstein is possibly the earliest incarnation as a novel.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-chuckleberryfinn even thread-odd thread-alt depth-1" id="li-comment-589000">
		<div id="comment-589000" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ChuckleberryFinn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589000">
			January 15, 2018 at 7:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is such a pointless and pedantic blog post.  Scott is attacking a fiction writer for using a compelling metaphorical lens to criticize capitalism. <b>Chiang is simply making an argument that downplays AI risk RELATIVE TO the risks of capitalism as it currently operates</b>. Scott&#8217;s thesis that &#8220;Chiang argues the analogy proves that AI fears are absurd&#8221; is what&#8217;s absurd. It&#8217;s a complete misconstruction of a short, easy to comprehend little article. We get it, you like your new hometown, Scott!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-static odd alt depth-2" id="li-comment-589017">
		<div id="comment-589017" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/16b21d7158b1214c552e22c198931d9a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/16b21d7158b1214c552e22c198931d9a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">static</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589017">
			January 15, 2018 at 8:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I agree, in the sense that Chiang is more wrong about capitalism than he is about AI. Markets are not a simple optimization around money, they are distributed preference valuation processes that incorporate flexible human values of labor and possessions. If a free market is producing too many paperclips, the price drops until there is no value in producing them at their underlying costs and the relevant resources are employed towards other tasks where there is value. The simplistic AI risk runaway scenarios have a simple, unchanging value function for which they optimize, so there is no correction for the change in human preferences to indicate we already have plenty of paperclips. Perhaps a better argument would be that applying market forces to AI value functions would constrain simplistic runaway AIs, much like market forces constrain his simplistic version of capitalism.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jrleonard01 even depth-2" id="li-comment-589023">
		<div id="comment-589023" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">j r</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589023">
			January 15, 2018 at 8:35 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>This is such a pointless and pedantic blog post&#8230;</p></blockquote>
<p>If that is true, then the world needs more pointless and pedantic blog posts.  Because right now the world is full of folks using very hackneyed and often wrongheaded versions of some phenomenon (let&#8217;s call that X) to posit a view or offer an explanation of some other phenomenon or system (let&#8217;s call that Y).  The problem is that the generally, the only people who find these sorts of arguments compelling are the people that don&#8217;t understand X; so you end up with lots of people holding views based on faulty understanding of underlying phenomena.</p>
<p>If more people who understood X, bothered to critique the metaphor and correct the mangling of X, then the people writing these things would have to start using better arguments in the first place.  And that would only be a good thing for the overall level of discourse.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sniffnoy odd alt depth-2" id="li-comment-589028">
		<div id="comment-589028" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589028">
			January 15, 2018 at 8:52 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t think you&#8217;re correct here.  Chiang says in the article he does not think there is any reason to believe the idea of AI as dangerous optimizer.  (To quote: &#8220;The idea of superintelligence is such a poorly defined notion that one could envision it taking almost any form with equal justification: a benevolent genie that solves all the worldâ€™s problems, or a mathematician that spends all its time proving theorems so abstract that humans canâ€™t even understand them.&#8221;)  He is saying that the reason that people think AI will be dangerous is lacking justification.  That&#8217;s not talking about its risk relative to capitalism.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-chuckleberryfinn even depth-3" id="li-comment-589057">
		<div id="comment-589057" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ChuckleberryFinn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589057">
			January 15, 2018 at 10:28 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>lol youâ€™re putting words in his mouth. he isnt saying that ai risk fears lack justification, heâ€™s saying that super intelligence is poorly defined. might i direct you toward the title of the article to understand where iâ€™m coming from? youâ€™re stuck in the trees buddy!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-3" id="li-comment-589329">
		<div id="comment-589329" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589329">
			January 16, 2018 at 11:21 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;It could be anything, but would be extremely powerful&#8221; sounds like a good cause for concern. The space of &#8220;Powerful Things Good For Human Life&#8221; is dwarfed by the space of &#8220;Powerful Things Bad For Human Life.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-adderp even depth-4" id="li-comment-589352">
		<div id="comment-589352" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/82680c5954d76dac2ee0be9a881c10d0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/82680c5954d76dac2ee0be9a881c10d0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">adder</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589352">
			January 16, 2018 at 11:47 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>How about </p>
<blockquote><p>The fears of superintelligent AI are probably genuine on the part of the doomsayers. <b>That doesnâ€™t mean they reflect a real threat; what they reflect is the inability of technologists to conceive of moderation as a virtue</b>. </p></blockquote>
<p> (emphasis added)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-5" id="li-comment-589373">
		<div id="comment-589373" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589373">
			January 16, 2018 at 12:15 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But the technologists either 1) do regard moderation as a virtue (Bill Gates giving his money away and curing diseases; Musk&#8217;s actual goal is to Get His Ass to Mars and his businesses are only a means to that end) or 2) at least respond to market forces or else go out of business. The problem with the Paperclip Maximizer is that there is no end besides paperclips, and there is no feedback loop that says &#8220;we have enough paperclips.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mellowirony even depth-2" id="li-comment-589084">
		<div id="comment-589084" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/861871149d2ca28c765b4632826a0f80?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/861871149d2ca28c765b4632826a0f80?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Mellow Irony</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589084">
			January 16, 2018 at 12:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I would say the idea that AI fears are absurd is really a <i>presupposition</i> of Chiang&#8217;s article. There is one explicit argument in the article that dangerous AI isn&#8217;t coming soon (&#8220;we are still a long way from a robot that can walk into your kitchen and cook you some scrambled eggs&#8221;), but the real reason people are coming away with the impression that Chiang is saying we shouldn&#8217;t pay attention to AI risk is in the <a href="http://lesswrong.com/lw/4h/when_truth_isnt_enough/" rel="nofollow">connotations</a>:</p>
<blockquote><p>This scenario sounds absurd to most people, yet there are a <b>surprising</b> number of technologists who think it illustrates a real danger.</p></blockquote>
<blockquote><p>&#8230;some have proposed that we ensure that any superintelligent AIs we create be â€œfriendly,â€ meaning that their goals are aligned with human goals. I find these suggestions <b>ironic</b> given that we as a society have failed to teach corporations a sense of ethics&#8230;</p></blockquote>
<blockquote><p>The fears of superintelligent AI are probably genuine on the part of the <b>doomsayers</b>. That doesnâ€™t mean they reflect a real threat; what they reflect is the <b>inability</b> of technologists to conceive of moderation as a virtue.</p></blockquote>
<p>Each of the words in bold [emphasis added by me], even if technically accurate, has a spin that implies that the technologists in question are not worth listening to.</p>
<p>This implication makes Chiang&#8217;s use of the metaphor much less compelling. The natural conclusion of &#8220;unfriendly AI is like capitalism&#8221; is &#8220;if we&#8217;re worried about unfriendly AI, we should be worried about capitalism, and vice versa&#8221;. It completely undermines this point to dismiss AI worries as &#8220;fearmongering&#8221;, those warning of them as &#8220;doomsayers&#8221; who can&#8217;t &#8220;conceive of moderation as a virtue&#8221;, the pursuit of friendly AI as merely &#8220;fun to think about&#8221;, etc. (If thinking about unfriendly AI disasters is frivolous, and capitalism is like unfriendly AI, does that mean people worried about capitalism are similarly wasting their time?)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-chuckleberryfinn odd alt depth-3" id="li-comment-589135">
		<div id="comment-589135" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ChuckleberryFinn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589135">
			January 16, 2018 at 5:35 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Well, no, because Chiang spends the entire essay detailing how capitalism already operates as an obsessively optimized entity while these AI risks are still hypothetical. He clearly doesnâ€™t take AI risk as seriously as you and Scott and other SSC stans want him to, but it doesnâ€™t change the fact that he never actually comes out and says it. Hereâ€™s another butthurt market ideologue complaining about Chiangâ€™s essay and even he claims that Chiang NEVER attempts to assess if AI risk is real or not.</p>
<p>â€œSo I am lost. Does he think AI is a problem or not? Well, we never actually find out. But Chiang does think Silicon Valley tech companies are a problem.â€</p>
<p><a rel="nofollow"href="https://digitopoly.org/2017/12/19/ted-chiang-gets-a-ton-of-economics-wrong/" rel="nofollow ugc">https://digitopoly.org/2017/12/19/ted-chiang-gets-a-ton-of-economics-wrong/</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho even depth-4" id="li-comment-589332">
		<div id="comment-589332" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589332">
			January 16, 2018 at 11:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Well, no, because Chiang spends the entire essay detailing how capitalism already operates as an obsessively optimized entity while these AI risks are still hypothetical.</p></blockquote>
<p>Which is silly, because the problem with the Paperclip Maximizer is there&#8217;s no feedback mechanism to tell the Paperclip Maximizer &#8220;we don&#8217;t need no more stinking paperclips.&#8221; But capitalism has such a feedback mechanism built right in: no paperclip manufacturer is ever going to grey goo the world to make more paperclips because once the supply of paperclips outstrips the demand for paperclips the profit derived from manufacturing paperclips drops to zero, and so paperclip production halts. </p>
<p>Runaway AI is scary precisely because it lacks the feedback mechanisms inherent in the capitalist marketplace.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-morgan odd alt depth-5" id="li-comment-590278">
		<div id="comment-590278" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/64899e0e47187df8e5532a4485292b8e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/64899e0e47187df8e5532a4485292b8e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Morgan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590278">
			January 18, 2018 at 8:12 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>What is the feedback mechanism that stops a company trying to maximise <i>profit</i>?</p>
<p>&#8220;Paperclip companies aren&#8217;t paperclip maximisers because maximising paperclips will eventually become unprofitable&#8221; doesn&#8217;t actually address the argument, because the capitalism = paperclip maximiser isn&#8217;t &#8220;paperclip companies are like paperclip maximisers because they produce <b>paperclips</b>&#8221; it&#8217;s &#8220;paperclip companies are like paperclip maximisers because they <b>maximise</b> something&#8221;. The something is, under this analogy, profit. </p>
<p>Profitability is the check on maximising paperclips (or anything else, other than profit itself) because it shifts the target of the maximisation. You don&#8217;t want to produce the biggest number of paperclips, you want to produce the most profitable number of paperclips, whether that&#8217;s billions of paperclips or one very expensive paperclip.</p>
<p>What&#8217;s the check on maximising profit? When do you tell the profit-maximisation system &#8220;we don&#8217;t need no more stinking profits&#8221;?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-the-nybbler even depth-5" id="li-comment-590279">
		<div id="comment-590279" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">The Nybbler</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590279">
			January 18, 2018 at 8:17 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>What is the feedback mechanism that stops a company trying to maximise profit?</p></blockquote>
<p>Other companies.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mugasofer odd alt depth-2" id="li-comment-589097">
		<div id="comment-589097" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589097">
			January 16, 2018 at 2:13 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Scott is attacking a fiction writer for using a compelling metaphorical lens to criticize capitalism. Chiang is simply making an argument that downplays AI risk RELATIVE TO the risks of capitalism as it currently operates. Scottâ€™s thesis that â€œChiang argues the analogy proves that AI fears are absurdâ€ is whatâ€™s absurd.</p></blockquote>
<p>Did you <i>read </i>Chiang&#8217;s article? He repeatedly says exactly that.</p>
<blockquote><p>â€œAI is a fundamental risk to the existence of human civilization.â€ Doomsayers have been issuing similar warnings for some time &#8230;  superintelligence is such a poorly defined notion that one could envision it taking almost any form with equal justification  &#8230; this doesnâ€™t make me worry about the possibility of a superintelligent AI &#8230; Itâ€™d be tempting to say that fearmongering about superintelligent AI is a deliberate ploy  &#8230; The fears of superintelligent AI are probably genuine on the part of the doomsayers. That doesnâ€™t mean they reflect a real threat; what they reflect is the inability of technologists to conceive of moderation as a virtue.</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sty_silver even depth-2" id="li-comment-589365">
		<div id="comment-589365" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589365">
			January 16, 2018 at 12:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Clearly, dozens of highly intelligent people have understood him to mean that AI is not dangerous. It seems to me that arguing they are all wrong is not particularly reasonable. Plus, even if they were, that alone would be a basis for arguing against it.</p>
<p>The analogy is also just not good. AI and capitalism have barely any similarities that are useful for understanding them better. I think we&#8217;d do well discouraging any such comparisons.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-chuckleberryfinn odd alt depth-3" id="li-comment-589526">
		<div id="comment-589526" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ChuckleberryFinn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589526">
			January 16, 2018 at 6:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Clearly, dozens of highly intelligent people have understood him to mean that AI is not dangerous.&#8221; lol is this rationalist trolling?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sty_silver even depth-4" id="li-comment-589641">
		<div id="comment-589641" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589641">
			January 17, 2018 at 3:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>No, that&#8217;s an observation based on reading the comment section, the blog post, and the survey question on IQ.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-chuckleberryfinn odd alt depth-5" id="li-comment-589662">
		<div id="comment-589662" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b7d94bf9a8876469c3a716387a0b97a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ChuckleberryFinn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589662">
			January 17, 2018 at 5:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>what a rigorous standard!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-admin bypostauthor even depth-5" id="li-comment-589924">
		<div id="comment-589924" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589924">
			January 17, 2018 at 1:14 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><font color="red"><b>Chuckleberry is banned for three months for various low-quality and annoying contributions on this thread.</b></font></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bossbrett odd alt thread-even depth-1" id="li-comment-589002">
		<div id="comment-589002" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Brett</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589002">
			January 15, 2018 at 7:53 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Silicon Valley in general seems like a poor example to use as a &#8220;money optimizer&#8221;, and especially with Gates and Musk as they are now. Gates is giving much of his wealth away, and Musk chose to spend his early wealth on designing rockets and electric cars rather than something that would have given him a lot more more a lot quicker (such as founding a hedge fund or the like).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-matt-m even depth-2" id="li-comment-589030">
		<div id="comment-589030" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589030">
			January 15, 2018 at 8:58 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yep.  If capitalism requires one to optimize for &#8220;earning the most money possible&#8221; then both of these people are absolutely horrible examples.  As is most of silicon valley.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-quanta413 odd alt depth-3" id="li-comment-589041">
		<div id="comment-589041" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c4a524f113097a93b62381095a6f71e7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c4a524f113097a93b62381095a6f71e7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">quanta413</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589041">
			January 15, 2018 at 9:41 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Not to mention &#8220;earning the most money possible&#8221; is not even well defined. Obviously, nominal would be a poor choice. But if we&#8217;re talking real units, how are we adjusting the value of the basket of goods? Using CPI? Or is the claim that capitalism is full of capitalists trying to maximize their own relative wealth? But wait, that&#8217;s probably not right because most capitalists wouldn&#8217;t off their opponents just to boost their relative standing. So at some point we&#8217;re left with a much more boring claim that capitalism is full of capitalists doing normal selfish human things to maximize their status as judged by some other humans or fulfill some particular desire they have. But this is true of any system involving human competition and cooperation; the better systems are just the ones that net more on top of status competition.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-andrew-cady even depth-4" id="li-comment-589474">
		<div id="comment-589474" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589474">
			January 16, 2018 at 3:55 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Corporations trying to maximize their valuations.  It&#8217;s not ordinary humans doing normal selfish things, because of the wall of separation that exists effectively between the anonymous shareholders and the agents.</p>
<p>(Compare &#8220;closely held corporations,&#8221; which can actually make moral choices.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-matt-m odd alt depth-5" id="li-comment-589483">
		<div id="comment-589483" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589483">
			January 16, 2018 at 4:17 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Corporations trying to maximize their valuations. </p></blockquote>
<p>Ah, but which is it?</p>
<p>Valuation and profitability are very different things.  We can&#8217;t just use these words interchangeably whenever challenged on them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady even depth-5" id="li-comment-589548">
		<div id="comment-589548" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589548">
			January 16, 2018 at 8:21 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Matt M</p>
<p>I think you may have confused me for someone else in the thread.  I only said valuations, I never said profits.</p>
<p>But I would still say they&#8217;re not actually that different, because the valuation is based on the prediction of future profits which is mostly (though not entirely) based on past profits.  Over the long term, profitability and valuation are going to amount to the same thing.</p>
<p>When people say that corporations want to maximize profits, I think they are probably being imprecise in their phrasing and you shouldn&#8217;t take it over-literally.  They probably consider &#8220;capital gains&#8221; to be just another kind of profit.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m odd alt depth-5" id="li-comment-589556">
		<div id="comment-589556" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589556">
			January 16, 2018 at 8:53 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>But I would still say theyâ€™re not actually that different, because the valuation is based on the prediction of future profits which is mostly (though not entirely) based on past profits. Over the long term, profitability and valuation are going to amount to the same thing.</p></blockquote>
<p>I&#8217;m not entirely sure that&#8217;s true.  There are plenty of companies with large valuations who have never been profitable, or haven&#8217;t been profitable in recent years, or what have you.</p>
<p>You&#8217;re right that in theory it should match expectations in the long run, but in reality, I don&#8217;t think it does.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nancylebovitz even thread-odd thread-alt depth-1" id="li-comment-589004">
		<div id="comment-589004" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nancy Lebovitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589004">
			January 15, 2018 at 8:00 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I can&#8217;t figure out why people aren&#8217;t at least as afraid of governments (governmentism?) as they are of capitalism.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-2" id="li-comment-589006">
		<div id="comment-589006" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589006">
			January 15, 2018 at 8:05 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Because a memeplex of &#8220;be afraid of governments&#8221; is useless to its holders.</p>
<p>The communist memeplex is useful for keeping your gang together long enough to take over the government and take ownership of, well, everything in the country.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mostlycrediblehulk even depth-2" id="li-comment-589052">
		<div id="comment-589052" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/759510b5f46461e0e5ed54ed632cdf7c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/759510b5f46461e0e5ed54ed632cdf7c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MostlyCredibleHulk</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589052">
			January 15, 2018 at 10:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Some are. They are called libertarians. Or, more often, &#8220;those crazy libertarians which are always afraid of government for no reason&#8221; and &#8220;those annoying libertarians which annoyingly tell us &#8216;we told you so&#8217; each time the government has caused major problems&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-lbthingrb odd alt depth-3" id="li-comment-589077">
		<div id="comment-589077" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/eb00ceb1f1ab3b0f43768b5fe688c47d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/eb00ceb1f1ab3b0f43768b5fe688c47d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">[Thing]</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589077">
			January 15, 2018 at 11:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Even beyond self-identified libertarians, concerns about &#8220;big government&#8221; are a widespread trope in American politics, especially on the right. On the left, you don&#8217;t see as much fear of government in general, but more specific concerns about &#8220;the surveillance state,&#8221; &#8220;the carceral state,&#8221; &#8220;the military-industrial complex,&#8221; etc. are still common. So I think people do have an instinctive anxiety about government that mirrors their anxiety about corporations in most important respects.</p>
<p>If corporations are less popular than governments, perhaps the reason is that people usually identify with their nation-states to some degree, and maybe some of that positive affect rubs off on the governments of said nation-states, whereas corporations are more like foreign governments in how they stand in relation to people who don&#8217;t work for them or own shares in them. The nationalism angle would also explain why transnational corporations are viewed as especially suspicious.</p>
<p>Anyway, it did strike me as a weakness of Chiang&#8217;s piece and the Charlie Stross essay <a rel="nofollow"href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-588978">linked above</a> that they didn&#8217;t acknowledge that the analogy with superintelligent AIs works just as well with governments, religions, nations, economies, or any other collective human organization in place of corporations.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-mugasofer even depth-4" id="li-comment-589101">
		<div id="comment-589101" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589101">
			January 16, 2018 at 2:21 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Governments don&#8217;t have an central &#8220;utility function&#8221; they attempt to maximise in the same way corporations do. </p>
<p>Religions at least do have an obvious big <i>instrumental </i>value in the form of number of followers, but they also have a bunch of other competing values (to the point that many religions don&#8217;t bother to proselytise at all.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jack-lecter odd alt depth-5" id="li-comment-589218">
		<div id="comment-589218" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jack Lecter</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589218">
			January 16, 2018 at 8:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Democratic governments optimize for votes and public support.</p>
<p>Government officials who donâ€™t optimize for power tend not to retain it for long.</p>
<p>I donâ€™t think itâ€™s a perfect analogy, but itâ€™s strong enough to make the level of corporate-hate surprising, given the absence of correspondingly strong government-hate.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-john-schilling even depth-5" id="li-comment-589235">
		<div id="comment-589235" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4480fa8686af48fcd94643a39566989a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">John Schilling</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589235">
			January 16, 2018 at 9:16 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>â€œPower is not a means; it is an end. One does not establish a dictatorship in order to safeguard a revolution; one makes the revolution in order to establish the dictatorship. The object of persecution is persecution. The object of torture is torture. The object of power is power.â€<br />
â€• George Orwell, 1984</p>
<p>This is approximately as accurate as saying that capitalism is a money-optimizer</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-doctor-mist odd alt depth-5" id="li-comment-589853">
		<div id="comment-589853" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589853">
			January 17, 2018 at 11:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Governments donâ€™t have an central â€œutility functionâ€ they attempt to maximise in the same way corporations do.</p></blockquote>
<p>Hmm, an interesting thought. But I&#8217;m not sure that governments don&#8217;t, nor that corporations <i>do</i>.</p>
<p>I think it&#8217;s rare (at least outside of the financial industry) for a company&#8217;s &#8220;mission statement&#8221; to directly invoke profit. While the founders of a company probably expect that they will make money, that may in some sense only be an instrumental goal in service of some loftier goal: the reason they are founding this particular company instead of a hedge fund. (For instance, Google&#8217;s original mission was &#8220;organize the worldâ€™s information and make it universally accessible and useful&#8221;.)</p>
<p>When we say that a corporation&#8217;s central utility function is to make a profit, we&#8217;re using a teleological metaphor, as when we say the purpose of the immune system is to ward off infection. We mean that the natural selection of the marketplace tends to favor a corporation that acts as if profit is its terminal goal.</p>
<p>By the same token, we must distinguish between, on one hand, the motives of the people who found and serve in a government and, on the other, the teleological, emergent goals of a government as an entity in the marketplace of competing institutions. These goals are not the same as a politician&#8217;s goal of getting re-elected &#8212; a government needn&#8217;t care what flesh-units comprise it (though of course a group of canny politicians can marshal some of the government&#8217;s powers to enhance their electoral chances).</p>
<p>The revealed goals of a government as an entity are certainly different from the revealed goals of a corporation. Profit is certainly not one of them, but perhaps control of its populace and defense against other governments are the appropriate analogs. What else enhances the success/survival of a particular government in the eco-system of governments and similar institutions? (As with organic evolution, there are niches: Monaco&#8217;s survival strategy is different from Germany&#8217;s.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jack-lecter even depth-3" id="li-comment-589216">
		<div id="comment-589216" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jack Lecter</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589216">
			January 16, 2018 at 8:30 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Iâ€™ve also observed this.  It still doesnâ€™t tell us why libertarians are so few.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-4" id="li-comment-589345">
		<div id="comment-589345" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589345">
			January 16, 2018 at 11:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Because libertarianism only works in a world without evil. The world in which everyone agrees to follow rules of non-aggression and deal fairly with everyone else is not this one. Blame Adam and Eve for ruining that one.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-rickhull even depth-5" id="li-comment-589478">
		<div id="comment-589478" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/af79cb74b6f6ca8f1102e415a3b9c9c2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Rick Hull</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589478">
			January 16, 2018 at 4:05 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Eh&#8230; non-aggression means that aggression / evil is dealt with swiftly and seriously (perhaps proportionally, say 2x &#8211; 10x).  It&#8217;s not a pacifist thing, and it seeks primarily to handle the problem with aggression and evil.  Primary forms include minarchy, security contracting, or self defense.  What would you say to a libertarian gun owners group about their inability to deal with evil?</p>
<p>I think libertarianism provides the blank slate of civilized behavior and thus civilization (i.e. beyond tribes, which are by nature authoritarian and communitarian).  Castles and walls of restrictions to individual liberty can be built on top of this blank slate, but this view judges most of our governing edifice harshly, presuming some level of oppression that requires more justification than commonly given.  This view doesn&#8217;t mean that the blank slate of anarchocapitalism is ideal &#8212; public good problems like national self defense, the environment, etc. still need solving, among many other collective action problems and similar.</p>
<p>But what is there to suggest that libertarianism simply cannot deal with lawbreakers?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady odd alt depth-5" id="li-comment-589551">
		<div id="comment-589551" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589551">
			January 16, 2018 at 8:29 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Libertarianism can&#8217;t deal with &#8220;lawbreaking&#8221; in the form of the large majority of people collectively legitimating a government that claims to be the true ultimate owner of everything and thus can tax the libertarians.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-doctor-mist even depth-5" id="li-comment-589862">
		<div id="comment-589862" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589862">
			January 17, 2018 at 11:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Libertarianism canâ€™t deal with â€œlawbreakingâ€ in the form of the large majority of people collectively legitimating a government that claims to be the true ultimate owner of everything</p></blockquote>
<p>And democracy can&#8217;t deal with a large majority of the people collectively deciding that they should really hand everything over to a king or dictator. Does this reveal a fatal flaw in democracy as an ideal? Or is it a silly quibble, on the grounds that a populace that instituted a democracy would be uninterested in throwing it away?</p>
<p>(I&#8217;m not saying they wouldn&#8217;t, of course &#8212; to my mind the history of the U.S. shows that it&#8217;s not impossible. Neither is the idea that a libertarian populace might decide to throw it all away. But you have not discovered any surprising special inherent fragility of libertarianism.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-5" id="li-comment-590246">
		<div id="comment-590246" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590246">
			January 18, 2018 at 7:16 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>But you have not discovered any surprising special inherent fragility of libertarianism.</p></blockquote>
<p>I don&#8217;t know if it needs to be &#8220;discovered,&#8221; but the inherent fragility of libertarianism is that cooperating collectivized groups crush individualists easily.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-4" id="li-comment-590000">
		<div id="comment-590000" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590000">
			January 17, 2018 at 2:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>An interesting question. One answer is that the case for libertarianism depends on understanding the way decentralized coordination via prices and exchanges works. Without that understanding, it&#8217;s obvious that you need someone above the system supervising it and making it do good things.</p>
<p>Understanding that is hard. That&#8217;s why, among academics, economists, who have to understand that, are the ones most likely (in my casual observation) to be libertarians.</p>
<p>This is part of a more general pattern. In many contexts, people have only weak incentives to make sure that what they believe is true&#8211;my false beliefs about which presidential candidate will be better have almost no effect on my life. In those contexts, a set of ideas that is easy to understand but wrong has a big advantage over a set that is hard to understand but right.</p>
<p>My usual example is foreign trade. Most public discussion takes for granted the theory of absolute advantage and a generally mercantilist perspective, shown by the use of terms like &#8220;more competitive&#8221; or &#8220;unfavorable balance of trade.&#8221; That set of ideas was refuted about two hundred years ago. But it&#8217;s easier to understand than the principle of comparative advantage, which is presumably both why it was worked out first and why it remains so widely believed in.</p>
<p>I&#8217;m sure that&#8217;s not all of the reason libertarianism is as small as it is, but I think it is part of it.</p>
<p>On the other hand, consider that in England for a good deal of the 19th century a form of libertarianism, classical liberalism, was something close to political orthodoxy, accepted by a sizable fraction of the population.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-1soru1 odd alt depth-2" id="li-comment-589085">
		<div id="comment-589085" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5a6a566014367c1e93de983f3d184584?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5a6a566014367c1e93de983f3d184584?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">1soru1</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589085">
			January 16, 2018 at 1:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Who is really unworried about about what &#8216;government&#8217; might do? Are there really people who were unconditional supporters of not merely both Trump and Obama, but also hypothetical-US-Hitler and hypothetical-US-Stalin?</p>
<p>The only thing that really differs is the details of _what_ they fear government might do.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nancylebovitz even depth-2" id="li-comment-589162">
		<div id="comment-589162" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nancy Lebovitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589162">
			January 16, 2018 at 6:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Current theory: Governments are older and scarier than capitalism, and governments have won the propaganda war.</p>
<p>I&#8217;m about equally scared of governments and corporations deploying AI without adequate constraints. I consider an accidental paper-clipping scenario much less likely.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jack-lecter odd alt depth-2" id="li-comment-589214">
		<div id="comment-589214" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/420d0d0206659eb45a77ea62f2eec43a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jack Lecter</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589214">
			January 16, 2018 at 8:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This has puzzled me for years.</p>
<p>I honestly donâ€™t get it.  I can come up with reasons I might be more afraid of government, or less afraid of capitalism, than the people around me, but none of them seem even remotely close to strong enough to explain the observed effects.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kostyah even depth-2" id="li-comment-589347">
		<div id="comment-589347" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://shadowmoves.info/' rel='external nofollow ugc' class='url'>Helaku</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589347">
			January 16, 2018 at 11:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Well, some are afraid of both, especially if unrestrained. When those entities turn into Moloch, things could go wrong for ordinary people.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-guy-in-tn odd alt depth-2" id="li-comment-589419">
		<div id="comment-589419" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e92ddd0e77ad0a293ad5997b517abd3b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e92ddd0e77ad0a293ad5997b517abd3b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Guy in TN</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589419">
			January 16, 2018 at 1:16 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I canâ€™t figure out why people arenâ€™t at least as afraid of governments (governmentism?) as they are of capitalism.</p></blockquote>
<p>Speaking as a leftist: Government power is controlled democratically (at least somewhat), while private power is controlled only by market forces (i.e., those with money/power).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nancylebovitz even depth-3" id="li-comment-589591">
		<div id="comment-589591" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nancy Lebovitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589591">
			January 16, 2018 at 11:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Governments observably do a lot more killing.</p>
<p>Also, governments have externality issues&#8211; their treatment of non-citizens isn&#8217;t well constrained by democracy.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-guy-in-tn odd alt depth-4" id="li-comment-589954">
		<div id="comment-589954" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e92ddd0e77ad0a293ad5997b517abd3b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e92ddd0e77ad0a293ad5997b517abd3b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Guy in TN</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589954">
			January 17, 2018 at 1:59 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The state of Michigan has, to this date, never executed a prisoner. Excluding police killings, it is essentially bloodless (much like a U.S. corporation). Do you think that government-killings by the U.S. would cease if the state of Michigan were to take over the U.S.&#8217;s military? I don&#8217;t. The higher amount of killing is a result of being the dominant power in our system. Replace it with non-democratic entity, and you&#8217;ll get much of the same, or probably worse. There is a history of having non-democratic control of the highest position of power, and its not good.</p>
<blockquote><p>Also, governments have externality issuesâ€“ their treatment of non-citizens isnâ€™t well constrained by democracy.</p></blockquote>
<p>Does private ownership not have the same externality issues? Non-owners have basically no constraints on their treatment, if the property owner is sovereign.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-pelebro even depth-2" id="li-comment-589501">
		<div id="comment-589501" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f3eab9fc80976cf8f05a8b49f5b7da2b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f3eab9fc80976cf8f05a8b49f5b7da2b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">pelebro</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589501">
			January 16, 2018 at 4:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It seems to me that people are and were already sufficiently afraid of governments (and the potential of government excesses). The system of division of power in branches, of &#8220;check and balances&#8221;, seems to me to have been engineered by people very concerned with this danger you mention for the purpose of avoiding it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest odd alt depth-3" id="li-comment-589504">
		<div id="comment-589504" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589504">
			January 16, 2018 at 5:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>USG&#8217;s setup is a lot more concerned with that than most systems are.  Part of this has to do with the founders&#8217; ideological commitments, but most of it has to do with the current iteration being written by a barely civil committee of different factions who all seriously mistrusted each other and desperately wanted to avoid getting screwed over.</p>
<p>(&#8220;Seriously mistrust&#8221; would escalate to &#8220;hate&#8221; in about another fifty years.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-evan-th even thread-even depth-1" id="li-comment-589007">
		<div id="comment-589007" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/dc49d4d5101c2e76e8ccf216efdca49a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/dc49d4d5101c2e76e8ccf216efdca49a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Evan Ãž</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589007">
			January 15, 2018 at 8:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Billionaires like Bill Gates and Elon Musk assume that a superintelligent AI will stop at nothing to achieve its goals because thatâ€™s the attitude they adopted&#8230;  Sometimes insight arises spontaneously, but many times it doesnâ€™t. People often get carried away in pursuit of some goal, and they may not realize it until itâ€™s pointed out to them, either by their friends and family or by their therapists. Listening to wake-up calls of this sort is considered a sign of mental health.</p></blockquote>
<p>Okay.  Suppose we take this at face value.  Chiang himself admits that some people are like that &#8211; some people (like Gates and Musk) will stop at nothing to achieve their goals, and they may not realize it.  And some people don&#8217;t stop even when their therapists give them wake-up calls; otherwise, Scott&#8217;s day job would be a whole lot easier.</p>
<p>What convinces Chiang that a superintelligent AI won&#8217;t be like that?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-2" id="li-comment-589014">
		<div id="comment-589014" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589014">
			January 15, 2018 at 8:17 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Some will stop at nothing to achieve their goals &#8211; those are the ones who achieve their goals. What Chiang is missing is that if you &#8220;convince&#8221; facebook to stop being facebook then some other company will be facebook.</p>
<p>Of course he solves this because there will be some kind of regulation but then just like facebook is facebook because it follows its incentives* the regulations will be written by an organization that is following its incentives &#8211; and its incentives aren&#8217;t to write regulations that make facebook nicer or whatever he thinks facebook is supposed to be.</p>
<p>Ultimately it&#8217;s an argument that there should be better governance but his memeplex hasn&#8217;t been selected to produce better governance &#8211; it&#8217;s been selected to get the holders of it published and respected by the right people. Speaking about how to sensibly design governments that have aligned incentives &#8211; or even to consider what that project would mean &#8211; is the type of thing that gets you banned from the google campus. Can&#8217;t imagine any selective pressure on memes based on that!</p>
<p>* Let&#8217;s leave aside what facebook actually does optimize for.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrudisill even thread-odd thread-alt depth-1" id="li-comment-589010">
		<div id="comment-589010" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ffa222fe617ac7d17c7c6aff3966338f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ffa222fe617ac7d17c7c6aff3966338f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">will rudisill</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589010">
			January 15, 2018 at 8:14 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Itâ€™s a good point, and I would have gone on to explain the more general idea of an optimization process. Evolution optimizes relentlessly for reproductive fitness, capitalism optimizes relentlessly for money, politics optimizes relentlessly for electability.&#8221;</p>
<p>I do not think capitalism and evolution are optimization processes in the same way. Capitalism evolves based on the actions of entities who make decisions, at least in part, motivated by theory and predictions of the future state of the system. One might call this &#8216;intent&#8217;. Evolution is like a geologic process. it arises naturally out of physical law: there is no intent structuring the optimization path.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ketil odd alt depth-2" id="li-comment-589089">
		<div id="comment-589089" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ketil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589089">
			January 16, 2018 at 1:38 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think this difference is quantitative rather than qualitative.  The intent of a corporation to grow and expand and increase profitability is perhaps more explicit than the intent of my genes to reproduce (interestingly making corporations more conscious of the processes that shape them than the humans they consist of, are they already more self-aware and meta-cognizing than us?), but in both cases, the intent exists because a lack of intent gets weeded out in a selection process.</p>
<p>Another thought: does an expansive corporation have higher fitness than a profitable one?  I suspect that a highly profitable corporation might get out-competed (bought up, mergered, or whatever) by an expansive one, even if it leads to lower profitabilty overall.  I seem to hear many stories about misguided mergers and acquisitions, and large corporations buying up and integrating small and innovative startups &#8211; often at impressive cost. If this is true, corporation size is yet another peacock&#8217;s tail, crippling the invisible hand.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-anon even depth-2" id="li-comment-589113">
		<div id="comment-589113" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/481dc25d4c44c545160177c08adc3ec4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/481dc25d4c44c545160177c08adc3ec4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anon.</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589113">
			January 16, 2018 at 3:22 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Irrelevant and also not really true. What is sexual selection if not &#8220;intent structuring the optimization path&#8221;?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kostyah odd alt depth-2" id="li-comment-589363">
		<div id="comment-589363" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://shadowmoves.info/' rel='external nofollow ugc' class='url'>Helaku</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589363">
			January 16, 2018 at 12:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>motivated by theory and predictions of the future state of the system</p></blockquote>
<p>Were merchants of 16 century motivated by a theory, even in part? I doubt it. Besides, every animal &#8220;makes a decision&#8221; in one or another form. Though humans have the (probably) unique ability to reflect on those decisions.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-raj even depth-2" id="li-comment-589418">
		<div id="comment-589418" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2847e66f52dee6fa70bce9291ac5c5b3?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2847e66f52dee6fa70bce9291ac5c5b3?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">raj</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589418">
			January 16, 2018 at 1:15 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But intent can also be construed as a &#8220;geologic process arising naturally out of physical law&#8221;. Instead of the gradient being &#8220;inclusive fitness of nearby mutations&#8221; it&#8217;s like &#8220;expected utility of nearby counterfactual future worlds&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady odd alt depth-2" id="li-comment-589554">
		<div id="comment-589554" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589554">
			January 16, 2018 at 8:41 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I do not think capitalism and evolution are optimization processes in the same way. Capitalism evolves based on the actions of entities who make decisions, at least in part, motivated by theory and predictions of the future state of the system. One might call this â€˜intentâ€™.</p></blockquote>
<p>There&#8217;s definitely a real difference here.  Corporations are in a sense Lamarckian &#8212; they don&#8217;t have the property of biological evolution that everything gets &#8220;reset&#8221; back to DNA every generation.</p>
<p>Biological organisms can have intents but their adjustment of their intents over time cannot ever <i>constitute</i> a biological change (i.e., it cannot ever <i>constitute</i> an optimization in the optimizing process under consideration).  That isn&#8217;t true for corporations.  Intent has a different place in the structure of the optimization process for them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jrleonard01 even thread-even depth-1" id="li-comment-589016">
		<div id="comment-589016" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">j r</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589016">
			January 15, 2018 at 8:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Billionaires like Bill Gates and Elon Musk assume that a superintelligent AI will stop at nothing to achieve its goals because thatâ€™s the attitude they adoptedâ€¦Itâ€™s no surprise that Silicon Valley capitalists donâ€™t want to think about capitalism ending. Whatâ€™s unexpected is that the way they envision the world ending is through a form of unchecked capitalism, disguised as a superintelligent AI. They have unconsciously created a devil in their own image, a boogeyman whose excesses are precisely their own.</p></blockquote>
<p>I read more than a little bit of projection in here, but on Chiang&#8217;s part.  When I think about what capitalism is, I think of the private ownership of the means of production.  These kinds of anti-capitalists arguments are powered by thinking of capitalism as an empty bucket in which to place all of things that one doesn&#8217;t like about the world and not wanting to bother to do the work in coming up with meaningful explanations and solutions.  </p>
<p>It is somewhat successful rhetorically, because people are always looking for empty buckets in which to place all the blame for the things about themselves and about the world that they don&#8217;t like and for which they don&#8217;t take responsibility.  But the end result is that anti-capitalist movements will be full of people who tend not think very clearly about how cause and effect play out in the world.  And for that, I am grateful.  Of course, lots of movements that don&#8217;t think very clearly about cause and effect manage to gain enough popularity to do real damage.  For that, I am a little worried.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mvassilevsky odd alt thread-odd thread-alt depth-1" id="li-comment-589018">
		<div id="comment-589018" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a50a6c546c0d92f9867a52a8806f2741?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a50a6c546c0d92f9867a52a8806f2741?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://eccentric-opinion.tumblr.com' rel='external nofollow ugc' class='url'>blacktrance</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589018">
			January 15, 2018 at 8:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Mild steelman (not endorsed): The accusation is about parochialism, not projection. The idea is that if an entity&#8217;s decisionmaking improves and it obtains more resources, it accomplishes its immediate goals more effectively, but doesn&#8217;t reflect on them. This is the environment and/or ideology that AI skeptics in Silicon Valley are immersed in, so they think that the an extremely rational being (the AI) will be even more like that, which is why they&#8217;re worried. But that&#8217;s like thinking that since the faster horses tend to be taller, when we go 100 mph in the future, it&#8217;ll be on horses the size of skyscrapers. If all you know is horses, it&#8217;s an understandable mistake, but a parochial one.</p>
<p>The AI-corporation analogy is more direct than physicists-black holes or physicists-chain reactions, because AIs and corporations are both supposed to do the same kind of thing with the same kind of stuff, i.e. use resources to optimize for a goal.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-carvenvisage even depth-2" id="li-comment-591320">
		<div id="comment-591320" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">carvenvisage</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591320">
			January 21, 2018 at 3:08 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>the an extremely rational being (the AI)</p></blockquote>
<p>That&#8217;s where it would be backwards.</p>
<p>Superintelligent AI is not supposed to be super-rational. </p>
<p>The the problem is that computers are so much faster than brains that it would be relatively easy to make something superintelligent (as in general thought at computer speeds) while having a poor design with 0 or little of what Mr Chiang calls &#8216;Insight&#8217;. (the capacity for rational reflection on your course, and specifically your goals) (and inclination)</p>
<p>In the same way that a corporation might irrationally pursue bad goals because its internal incentives, inertia, the incentives of stockholders etc, might bind it to those, an AI could pursue bad goals because they were <i>hard coded in with no feedback mechanism to change them</i>, perhaps by the tunnel-visioned short sighted capitalists Chiang is saying we should be worried about. (And by the same process make otherwise good goals bad ones, like paperclips or strawberries)</p>
<p>To put it another way, powerful entities that are poorly designed tend will tend to lack &#8216;insight&#8217; by default, whether a corporation that never was designed or an AI (thinker operating at computer speeds) that was designed without proper foresight.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ksvanhorn odd alt thread-even depth-1" id="li-comment-589020">
		<div id="comment-589020" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://bayesium.com' rel='external nofollow ugc' class='url'>ksvanhorn</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589020">
			January 15, 2018 at 8:26 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Continuation of an ongoing theme in Scott&#8217;s writing, and in the writing of &#8220;progressives&#8221; in general:</p>
<p>&#8220;I canâ€™t tell you how many morons hear a patient say `I think my husband hates our kids&#8217;, give some kind of galaxy-brain level interpretation like `Maybe whatâ€™s really going on is you unconsciously hate your kids, but itâ€™s more comfortable for you to imagine this of your husband&#8217;, and then get absolutely shocked when the husband turns out to be abusing the kids.&#8221;</p>
<p>Rule #1 of progressive writing: always, <i>always</i>, <b>always</b> make the person with negative traits be a man, and the person with positive traits be a woman.</p>
<p>Fun fact: <i>the majority of real-world child abuse is committed by women</i>, not men.</p>
<p><a rel="nofollow"href="https://everydayfeminism.com/2014/10/feminism-against-child-abuse/" rel="nofollow ugc">https://everydayfeminism.com/2014/10/feminism-against-child-abuse/</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-wrong-species even depth-2" id="li-comment-589043">
		<div id="comment-589043" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589043">
			January 15, 2018 at 9:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Do you honestly think that Scott consciously thought he should make the abuser a man just to virtue signal?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-3" id="li-comment-589074">
		<div id="comment-589074" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589074">
			January 15, 2018 at 11:26 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yes.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-leoboiko even depth-3" id="li-comment-589076">
		<div id="comment-589076" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6c297d35f2da76d92844551b994d14af?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6c297d35f2da76d92844551b994d14af?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">melboiko</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589076">
			January 15, 2018 at 11:36 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Continuation of an ongoing theme in ksvanhornâ€™s writing, and in the writing of â€œanti-progressivesâ€ in general:</p>
<p>Rule #1 of anti-progressive writing: everything, everything, <b>everything</b> an outgroup member does is motivated by virtue signaling. (cf. kaballah.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-4" id="li-comment-589079">
		<div id="comment-589079" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589079">
			January 15, 2018 at 11:54 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Progressives talk about doing this all the time.</p>
<p>No one has gone through school without seeing guides to using &#8220;non-problematic&#8221; language &#8211; making sure that when you use pronouns that you take care to not use &#8220;she&#8221; for people in stereotypically female roles, for example. Progressive actively call out any negative portrayal of progressive pet groups as racist or sexist or homophobic if it matches reality &#8211; in other words they&#8217;re calling the speaker out for demonstrating vice &#8211; the opposite of virtue. That&#8217;s exactly the same thing as ksvanhorn is observing except his values are &#8220;does this correspond with reality&#8221; rather than &#8220;does this flatter progressive pet groups&#8221;.</p>
<p>If you don&#8217;t share the progressive view that always flattering progressive groups while always insulting progressive enemies is an unalloyed good that of course all decent people should strive to do it&#8217;s grating to hear over and over.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-mugasofer even depth-5" id="li-comment-589105">
		<div id="comment-589105" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589105">
			January 16, 2018 at 2:29 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You&#8217;re conflating <i>signalling </i>virtue with <i>being virtuous</i>. </p>
<p>Many of those discussions are based on (alleged) harms, such as stereotype threat, not on the benefit to the person &#8220;signalling&#8221; virtue.</p>
<blockquote><p>Progressive actively call out any negative portrayal of progressive pet groups as racist or sexist or homophobic if it matches reality[sic] â€“ in other words theyâ€™re calling the speaker out for demonstrating vice â€“ the opposite of virtue.</p></blockquote>
<p>Courts regularly punish people for murder or theft â€“ in other words theyâ€™re punishing the accused for demonstrating vice â€“ the opposite of virtue. Those darn virtue-signallers!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-cactus-head odd alt depth-5" id="li-comment-589114">
		<div id="comment-589114" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/14970cdb6a3c818106c64e7b3fa7a121?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/14970cdb6a3c818106c64e7b3fa7a121?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">cactus head</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589114">
			January 16, 2018 at 3:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>A source of confusion is that much of what gets called &#8216;virtue signalling&#8217; should instead be called &#8216;cheap talk&#8217;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589264">
		<div id="comment-589264" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589264">
			January 16, 2018 at 10:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Youâ€™re conflating signalling virtue with being virtuous. </p></blockquote>
<p>Making a negative statement about a progressive group is a neutral act in my eyes whether the statement is true or not and whether or not it causes emotional harm to members of the group &#8211; real, imagined, or pretended. In the eyes of a progressive nothing in the world is worse than making a negative statement about a progressive pet group &#8211; not even murder.</p>
<p>Refraining from saying things that offend progressive pets and using awkward language and always counter-stereotyping in speech and writing are considered virtues by progressives (or at least, lack of those things are considered the worst imaginable vices). Doing that out of fear of the consequences of not doing that demonstrates the lack of a virtue called &#8220;bravery&#8221;. Doing so out of an insincere belief that it demonstrates virtue is virtue signalling.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-tarpitz odd alt depth-5" id="li-comment-589360">
		<div id="comment-589360" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ba16907d63bc1aaa64902e77f1470bde?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ba16907d63bc1aaa64902e77f1470bde?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tarpitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589360">
			January 16, 2018 at 11:58 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>No one has gone through school without seeing guides to using â€œnon-problematicâ€ language</p></blockquote>
<p>I assure you that I did. My schools may have been (were) atypical in all sorts of ways, but I for one never encountered such a thing at any point in my education.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-lvlln even depth-5" id="li-comment-589406">
		<div id="comment-589406" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/20ac983cab72d944184e5cda5e219400?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/20ac983cab72d944184e5cda5e219400?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">lvlln</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589406">
			January 16, 2018 at 12:58 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>In the eyes of a progressive nothing in the world is worse than making a negative statement about a progressive pet group â€“ not even murder.</p></blockquote>
<p>I&#8217;m a progressive, and in my eyes, murder is far worse than making a negative statement about a progressive pet group. Or about any group, really.</p>
<p>OK, perhaps #NotAllProgressives isn&#8217;t all that helpful. I think the real issue here is that you aren&#8217;t correctly modeling the mindset of the subset of progressives who appear to behave as if they believe that making negative statements about a progressive pet group is worse than murder (even though I disagree that this subset is the entire set &#8211; or even a majority of the set &#8211; I at least believe that it&#8217;s a sizable and particularly influential portion of the set). The belief isn&#8217;t that making a negative statement about a progressive pet group is a vice in itself, it&#8217;s that making a negative statement about a progressive pet group will predictably lead to harm to members of that progressive pet group, including murder and beyond. As such, this subset of progressives may behave as if some specific murder is less bad than making a negative statement about a progressive pet group, but only to the extent that they believe that the resulting harms from those negative statements exceed the harms of a specific murder. </p>
<p>Now, it&#8217;s an open question how much harm predictably results from negative statements about a progressive pet group, and that&#8217;s probably where you (and I) disagree with the subset of progressives in question.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-4" id="li-comment-589110">
		<div id="comment-589110" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589110">
			January 16, 2018 at 3:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yep. Planting a flag on your lawn isn&#8217;t virtue signalling because only the left virtue signal.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ksvanhorn even depth-5" id="li-comment-589190">
		<div id="comment-589190" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://bayesium.com' rel='external nofollow ugc' class='url'>ksvanhorn</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589190">
			January 16, 2018 at 7:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yes, planting a flag on your lawn is virtue signaling.</p>
<p>BTW, it&#8217;s not the virtue-signaling aspect of the <i>always-make-the-fool-or-villain-a-man</i> norm that bothers me; it&#8217;s the constant, unceasing parade of negative male stereotypes.</p>
<p><a rel="nofollow"href="https://www.youtube.com/watch?v=T1GnQ_k7Vok" rel="nofollow ugc">https://www.youtube.com/watch?v=T1GnQ_k7Vok</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-5" id="li-comment-589353">
		<div id="comment-589353" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589353">
			January 16, 2018 at 11:51 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is where Brad usually comes in and gets mad at the right for replacing the word &#8220;hypocrisy&#8221; with &#8220;virtue signalling.&#8221; </p>
<p>The kind of &#8220;virtue signalling&#8221; the right snarls at is hypocrisy: the movie star who says &#8220;refugees welcome!&#8221; from the safety of their walled mansion knowing the refugees are going to be shoved into poor people&#8217;s neighborhoods and they&#8217;ll never have to see one. I don&#8217;t think flag waving is in the same ballpark, especially if you are genuinely a patriotic American and/or you or your family serve in the military.</p>
<p>I think a better example of right-wing virtue signalling is the Choose Life bumper sticker. Easy for you to say when you&#8217;re not impoverished and knocked up.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nornagest even depth-5" id="li-comment-589463">
		<div id="comment-589463" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589463">
			January 16, 2018 at 3:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Just about everyone only gets upset about hypocrisy when it&#8217;s their opponents doing it.  For the right, that&#8217;s e.g. cities with more Black Lives Matter posters than actual black people (hi, Berkeley!); for the left, it&#8217;s e.g. pundits extolling family values while working on their fourth divorce.</p>
<p>I&#8217;d say it&#8217;s <i>all</i> virtue signaling.  It&#8217;s just that that particular phrase for it is mainly a right-wing usage for whatever reason, so you mainly hear it about the left.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sohois odd alt depth-2" id="li-comment-589119">
		<div id="comment-589119" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/cc8c3e21e3b50d3064ebd5636cbc7d86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/cc8c3e21e3b50d3064ebd5636cbc7d86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sohois</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589119">
			January 16, 2018 at 3:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>An entire blog post about the dangers of projection, and all you can do is project some weird conspiracy onto a throwaway comment?</p>
<p>I&#8217;m not sure this post really deserves any attention, but given the principle of charity, would you care to elaborate on your theory? What other examples are there of a secret, misandrist agenda within Alexander&#8217;s blog posts? What is the motivation for these coded messages? Where is your evidence that this represents a real attempt to advance a progressive agenda and is not merely a coincidence?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ksvanhorn even depth-3" id="li-comment-589193">
		<div id="comment-589193" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://bayesium.com' rel='external nofollow ugc' class='url'>ksvanhorn</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589193">
			January 16, 2018 at 7:44 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Not a secret agenda, sohois; just a cultural norm that promotes negative male stereotypes. I&#8217;ve seen the psychological harm this kind of thing causes &#8212; young men who suffer a crushing inferiority complex, convinced that they are innately inferior by reason of having a Y chromosome.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman odd alt depth-4" id="li-comment-589251">
		<div id="comment-589251" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589251">
			January 16, 2018 at 9:46 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Your claim is about Scott, so I suggest a simple test. If Scott is trying to promote a male bad/female good stereotype, it ought to show up in the blogs he chooses to link to. Run down the blogroll in the left column of his blog and count authors by gender.</p>
<p>If you don&#8217;t like that test, can you suggest a better one? You might expect that women would be more attracted than men to a blog that signals female superiority. That doesn&#8217;t seem to fit the actual poll results, or the observed ratio in meetups.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589280">
		<div id="comment-589280" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589280">
			January 16, 2018 at 10:21 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Your claim is about Scott, so I suggest a simple test. If Scott is trying to promote a male bad/female good stereotype, it ought to show up in the blogs he chooses to link to. </p></blockquote>
<p>Doesn&#8217;t follow at all.</p>
<p>&#8220;Only link to women / only retweet women / only follow women&#8221; <i>is</i> a progressive meme but not a mandatory one &#8211; it&#8217;s considered especially virtuous though:</p>
<p><a rel="nofollow"href="https://medium.com/@sheenamedina/anil-dash-decided-to-only-retweet-women-for-an-entire-year-and-wrote-about-his-experience-f941d3bc3701" rel="nofollow ugc">https://medium.com/@sheenamedina/anil-dash-decided-to-only-retweet-women-for-an-entire-year-and-wrote-about-his-experience-f941d3bc3701</a></p>
<p>Scott is interested in signalling enough progressive virtue to avoid accidentally stirring up a hate mob &#8211; <i>as he&#8217;s specifically stated in the comment section on more than one occasion</i> so it&#8217;s not the slightest bit implausible that he does this sort of thing with conscious intent.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-meh odd alt depth-5" id="li-comment-589306">
		<div id="comment-589306" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a269bf9131dfacab0a8187daadfe3429?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a269bf9131dfacab0a8187daadfe3429?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">meh</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589306">
			January 16, 2018 at 10:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@reasoned<br />
I find Scott&#8217;s posts about gender and feminism to be intellectually honest.  Can you point to posts that suggest otherwise?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ksvanhorn even depth-5" id="li-comment-589342">
		<div id="comment-589342" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/08445007e5a529a2eeab334c7420ff63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://bayesium.com' rel='external nofollow ugc' class='url'>ksvanhorn</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589342">
			January 16, 2018 at 11:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I see I have not made myself clear. I&#8217;m not claiming that Scott is <i>deliberately</i> promoting negative male stereotypes; I&#8217;m claiming that this is a consequence of adhering to certain unspoken progressive norms. This is an issue with progressives in general, not just Scott. As to his motives, my guess is that he&#8217;s just doing what feels natural as a Blue Tribe member.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation odd alt depth-5" id="li-comment-589356">
		<div id="comment-589356" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589356">
			January 16, 2018 at 11:53 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>meh &#8211; </p>
<p>The item under discussion is the example and I laid out my reasons for why I think it&#8217;s at least slightly dishonest.</p>
<p>ksvanhorn &#8211;</p>
<p>You were clear &#8211; I&#8217;m willing to go a step further though. Scott consciously mimic progressive signals out of fear &#8211; which he openly admits. It&#8217;s not speculation when he says that he does it. This particular example is a progressive signal so it&#8217;s at least possible that it wasn&#8217;t unconsciously sent but consciously sent because we know that Scott consciously sends progressive signals.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sohois even depth-5" id="li-comment-589430">
		<div id="comment-589430" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/cc8c3e21e3b50d3064ebd5636cbc7d86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/cc8c3e21e3b50d3064ebd5636cbc7d86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sohois</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589430">
			January 16, 2018 at 1:42 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I see I have not made myself clear. Iâ€™m not claiming that Scott is deliberately promoting negative male stereotypes; Iâ€™m claiming that this is a consequence of adhering to certain unspoken progressive norms. This is an issue with progressives in general, not just Scott. As to his motives, my guess is that heâ€™s just doing what feels natural as a Blue Tribe member.</p></blockquote>
<p>Very well, from this and your earlier reply it seems you at least are genuine in this belief and not merely a troll as I first suspected.</p>
<p>Nonetheless, your argument seems extremely difficult to prove one way or the other. Unconsciously adhering to certain progressive norms? How does one go about showing this? First of all, what evidence can you show that progressive norms are focused on misandrist causes? Secondly, in my original reply I asked what further evidence you had that Alexander was including these coded messages, unconsciously or no? I don&#8217;t doubt that there have been other blog posts in which a negative example was based on a male, but it seems a very high bar of proof to demonstrate that this is a deliberate pattern.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-meh odd alt depth-5" id="li-comment-589455">
		<div id="comment-589455" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a269bf9131dfacab0a8187daadfe3429?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a269bf9131dfacab0a8187daadfe3429?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">meh</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589455">
			January 16, 2018 at 2:51 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The item under discussion is the example and I laid out my reasons for why I think itâ€™s at least slightly dishonest.</p></blockquote>
<p>@reasoned<br />
If you only have one example of a gender selection, then your result will happen by chance 50% of the time.</p>
<p>Like DavidFriedman says, suggest a test.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589465">
		<div id="comment-589465" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589465">
			January 16, 2018 at 3:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Here&#8217;s my suggested test of whether or not Scott consciously sends progressive signals:</p>
<p>Look for comments where Scott says that he consciously sends progressive signals because he fears harassment by progressive mobs. Try searching the comment section of this web site for examples.</p>
<p>The examples are not super hard to find.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jugemu odd alt depth-2" id="li-comment-589122">
		<div id="comment-589122" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jugemu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589122">
			January 16, 2018 at 4:13 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The issue you point out is indeed common and kind of annoying, but I don&#8217;t think that is a good example. It seems more like a good-faith usage of anecdotal evidence from Scott&#8217;s own practice.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nancylebovitz even depth-2" id="li-comment-589134">
		<div id="comment-589134" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/735a5915c250899ef8f5ad224498944c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nancy Lebovitz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589134">
			January 16, 2018 at 5:31 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think Scott pretty much went with cultural norms there.</p>
<p>ksvanhorn, thanks for the link. If the statistics are accurate, women are only a little more likely (54% vs. 46%) to abuse their children than men are. What did you think of the social justice framing on the article?</p>
<p>My feeling is that a man who claimed that his wife hated his children would be more likely to be gaslit by his psychologist.</p>
<p>What would you (or anyone) think of a gender neutral version of the story with one parent and the other parent?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-the-nybbler odd alt depth-2" id="li-comment-589267">
		<div id="comment-589267" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">The Nybbler</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589267">
			January 16, 2018 at 10:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Perhaps you&#8217;ve got it backwards.  Perhaps every case of this Scott has heard has been the husband being the patient and the wife being the abuser, and so as a result he made the husband the abuser in the example to avoid the chance of some patient thinking Scott is talking literally about him.</p>
<p>Not that I believe this, but I think you&#8217;re theorizing from extremely scanty evidence.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ilya-shpitser even depth-3" id="li-comment-590112">
		<div id="comment-590112" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590112">
			January 17, 2018 at 8:12 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think he&#8217;s just melting as freshly fallen snow would in the searing heat of Scott&#8217;s microaggression.  As far as I can tell, loudly complaining about this one issue is basically the only thing this guy does here.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m odd alt thread-odd thread-alt depth-1" id="li-comment-589029">
		<div id="comment-589029" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589029">
			January 15, 2018 at 8:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>capitalism optimizes relentlessly for money</p></blockquote>
<p>I don&#8217;t think this is true.  Capitalism is not an entity.  It does not act.  It does not &#8220;optimize&#8221; for anything.  This is the biggest failure of the analogy&#8230; it&#8217;s not just that the analogy is bad, it&#8217;s that it categorizes things of a different type.  It&#8217;s like saying &#8220;Scientists have finally found Bigfoot, and it turns out that it&#8217;s scientology.&#8221;  Well no, that doesn&#8217;t work, because Bigfoot is an actual entity and scientology is a system of belief.   Even if it turns out that Bigfoot is a scientologist, that doesn&#8217;t make the analogy any more valid.</p>
<p>Furthermore, capitalism itself offers you no advice on what to do in any particular situation.  It doesn&#8217;t tell you that you <i>have to</i> make the most money possible.  There is no capitalist bible (despite Ayn Rand&#8217;s best efforts) prescribing what actions should or should not be taken.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-2" id="li-comment-589032">
		<div id="comment-589032" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589032">
			January 15, 2018 at 9:04 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Furthermore, capitalism itself offers you no advice on what to do in any particular situation. It doesnâ€™t tell you that you have to make the most money possible. There is no capitalist bible (despite Ayn Randâ€™s best efforts) prescribing what actions should or should not be taken.</p></blockquote>
<p>It does though. Entities that don&#8217;t optimize for making money eventually get outbid for their inputs and go out of business. If you value your inputs by some means other than their marginal value to your outputs then you&#8217;re being inefficient and are at risk of long term disaster. A facebook that doesn&#8217;t act like facebook and doesn&#8217;t track you doesn&#8217;t sell ads as effectively and can&#8217;t afford to make optimizations to keep people looking at their site and loses traffic to a new social network. That&#8217;s the optimization that capitalism forces.</p>
<p>Of course, it&#8217;s foolish to think that this is a feature of capitalism rather than just a special case of a universal rule of evolution.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-bossbrett odd alt depth-3" id="li-comment-589067">
		<div id="comment-589067" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ab9ec3f0efb38149b575c4f78a420b00?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Brett</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589067">
			January 15, 2018 at 11:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Companies whose leadership remains insulated from the immediate pressure to turn a profit (such as family-owned firms) can last for a very long time, far longer than your average share-traded corporation. They just need to make enough of a profit to pay back whatever debt they incur over time, and their incentives are different from investors who are just shifting between whatever offers the best risk-adjusted return over time. </p>
<p>That&#8217;s especially the case if they&#8217;re big and diversified. Sometimes even if they&#8217;re not &#8211; Nintendo is 129 years old.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-3" id="li-comment-589144">
		<div id="comment-589144" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589144">
			January 16, 2018 at 6:06 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That&#8217;s a nice theory, but as Brett says, it doesn&#8217;t seem to play out long-term.  There are companies like say, Patagonia or Tom&#8217;s Shoes that make a big deal out of spending a lot of money on charity.  They do not, &#8220;relentlessly optimize for profit&#8221; or what have you.  They seem to be doing fine.  They are growing, not shrinking.</p>
<p>At a simpler end, I know plenty of small business owners who are doing quite well.  So well they could almost certainly expand.  But they don&#8217;t.  Because they don&#8217;t feel like it.  Sometimes a taco truck can just be a taco truck for as long as the owner feels like running a taco truck.  The notion that he <i>has</i> to be as profitable and continually grow or else Taco Bell will ruthlessly drive him out of business is plainly false, as anyone who has ever been to a taco truck could tell you.</p>
<p>Capitalism doesn&#8217;t say &#8220;you must maximize profit to exist,&#8221; but rather something like &#8220;you must maximize profit if you want to be the most profitable&#8221; which is something of a tautology.  </p>
<p>Furthermore, even the businesses who <i>want to</i> maximize profits usually don&#8217;t know how to.  I work in an entire industry (management consulting) that only exists on the premise that lots of companies, even the giant behemoths, are doing a bunch of stuff wrong and not correctly optimizing their profits.  And yet, they haven&#8217;t been competed out of existence by someone doing better!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-1soru1 odd alt depth-4" id="li-comment-589177">
		<div id="comment-589177" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5a6a566014367c1e93de983f3d184584?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5a6a566014367c1e93de983f3d184584?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">1soru1</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589177">
			January 16, 2018 at 7:18 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The claim is clearly not about &#8216;capitalism&#8217;, or market system, in general, but publicly traded stock corporations. Any CEO who said &#8216;we like making tacos, we will continue to do so, and maybe if people like them we will even make some money, I dunno&#8217; would pretty soon be an ex-CEO.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-matt-m even depth-5" id="li-comment-589181">
		<div id="comment-589181" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589181">
			January 16, 2018 at 7:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Any CEO who said â€˜we like making tacos, we will continue to do so, and maybe if people like them we will even make some money, I dunnoâ€™ would pretty soon be an ex-CEO.</p></blockquote>
<p>Wasn&#8217;t this Amazon&#8217;s business strategy for the better part of the 2000s?  ðŸ™‚</p>
<p>I&#8217;ve heard allegations that this is basically what Uber is doing as well (although they are not publicly traded).</p>
<p>In any case, this gets to David Friedman&#8217;s point below.  Corporations spend money on all kinds of things that would not seem to be in the interest of &#8220;profit maximization.&#8221;  Mainly charitable giving programs, as well as perks for executives.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-outis odd alt thread-even depth-1" id="li-comment-589034">
		<div id="comment-589034" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a42644403f70289670201cda15a28a75?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a42644403f70289670201cda15a28a75?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">outis</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589034">
			January 15, 2018 at 9:10 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s important to keep in mind that Chiang is a writer. You can see where he is coming from: he feels like his field has already gone through the grinder. The internet brought a new, smarter way of doing things, which promised to bring exciting new opportunities for media production and consumption. And it did! But it also put the entire media industry through the screw of runaway optimization, whose objectives did not necessarily align with those of the average person in media. Thus that person feels that things have gotten worse as they got &#8220;more optimal&#8221;; and, worse, they feel that they, their friends, and any other people like them have entirely lost control on the direction their world is heading.</p>
<p>Yet I can&#8217;t help but feel enormous discomfort about any discussion of AI risk. The promise is that these new, superior intelligences will be able to do better than we can, and we well reap the benefits as we entrust to their direction not just the media, not just academic pursuits, but ultimately the rudder of our entire society. The fear is that their objectives will not align with ours; that they will bring about disastrous outcomes for us, not out of malice, but simply because they are not us and do not think like us (nor would they ever want to). And because they are superior intelligences, and because so much of our world will depend on them, we will be completely powerless to stop them once we realize our mistake.</p>
<p>Onfvpnyyl, NV evfx vf na nagvfrzvgvp qbtjuvfgyr.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sty_silver even depth-2" id="li-comment-589371">
		<div id="comment-589371" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589371">
			January 16, 2018 at 12:12 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Are you saying that this makes it ok to write such an article?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-hnau odd alt thread-odd thread-alt depth-1" id="li-comment-589036">
		<div id="comment-589036" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/04f7b7665eb1626ff32138d4ccefd35e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/04f7b7665eb1626ff32138d4ccefd35e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">hnau</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589036">
			January 15, 2018 at 9:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wasn&#8217;t comparing capitalism to AI more or less what Meditations on Moloch was all about?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-2" id="li-comment-589037">
		<div id="comment-589037" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589037">
			January 15, 2018 at 9:22 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Scott&#8217;s piece about the stupid national cafeterias article is a very good argument in favor of part Chiang&#8217;s argument.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-wrong-species odd alt depth-2" id="li-comment-589046">
		<div id="comment-589046" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a232fd3699010dd6034e799e6b8b9cda?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Wrong Species</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589046">
			January 15, 2018 at 9:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thereâ€™s a difference between warning about optimization processes in general and literally thinking that there is no difference between corporations and AI.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sniffnoy even depth-2" id="li-comment-589047">
		<div id="comment-589047" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589047">
			January 15, 2018 at 9:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think it&#8217;s important to note here that Chiang <i>isn&#8217;t</i> comparing AI to capitalism.  He&#8217;s comparing <i>other people&#8217;s ideas of AI</i> to capitalism.  He doesn&#8217;t actually accept those ideas, and is saying, aha, your ideas about AI are just taken from capitalism, they&#8217;re not what AI would actually necessarily be like.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-robirahman odd alt thread-even depth-1" id="li-comment-589049">
		<div id="comment-589049" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">robirahman</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589049">
			January 15, 2018 at 9:59 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This post feels a little bit similar to &#8220;Futurism Should be About the Future&#8221; in that the original arguments you&#8217;re responding to are bad enough that someone&#8217;s going to make the case that we&#8217;re just making things worse by drawing attention to them rather than helping things by changing his audience&#8217;s minds. I&#8217;m really hoping you get a response from Ted Chiang on this topic.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sty_silver even depth-2" id="li-comment-589372">
		<div id="comment-589372" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589372">
			January 16, 2018 at 12:14 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Can you explain the mechanism by which you think it can be harmful to respond to bad arguments? I&#8217;m not sure I get it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-robirahman odd alt depth-3" id="li-comment-589672">
		<div id="comment-589672" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">robirahman</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589672">
			January 17, 2018 at 6:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t agree with it myself, but there are various points in favor of not giving clickthroughs and attention to people who are not well-informed enough to meet a minimum quality standard when contributing to an argument. Here are some commenters who espouse such a viewpoint:</p>
<p><a rel="nofollow"href="https://slatestarcodex.com/2017/10/09/in-favor-of-futurism-being-about-the-future/#comment-554857" rel="nofollow ugc">https://slatestarcodex.com/2017/10/09/in-favor-of-futurism-being-about-the-future/#comment-554857</a></p>
<p><a rel="nofollow"href="https://www.reddit.com/r/slatestarcodex/comments/75f36k/in_favor_of_futurism_being_about_the_future/do5rt0s/" rel="nofollow ugc">https://www.reddit.com/r/slatestarcodex/comments/75f36k/in_favor_of_futurism_being_about_the_future/do5rt0s/</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even thread-odd thread-alt depth-1" id="li-comment-589054">
		<div id="comment-589054" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589054">
			January 15, 2018 at 10:16 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>capitalism optimizes relentlessly for money</p></blockquote>
<p>Utter nonsense.</p>
<p>If an individual capitalist was optimizing for money he would never spend anything above subsistence&#8211;no first class air flights, no yachts, no caviar&#8211;in order to accumulate as much money as possible.</p>
<p>If a worker in a capitalist system was optimizing for money he would take no leisure beyond what was required to keep him able to do his job, spend on nothing beyond subsistence and whatever consumer goods were needed to function in his job, take the highest paid job he could however unpleasant.</p>
<p>If a consumer in a capitalist system was optimizing for money &#8230;</p>
<p>It not only is nonsense, it is nonsense that misses the fundamental difference between maximizing for economic efficiency, which is what the ideal capitalist system, i.e. perfect competition, does, and maximizing for paperclips. Economic efficiency is a proxy, although not a perfect one, for maximum utility. Paperclips are not a proxy for anything.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-robirahman odd alt depth-2" id="li-comment-589060">
		<div id="comment-589060" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/48b142496582de0cdd6c1e0df14ede2b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">robirahman</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589060">
			January 15, 2018 at 10:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s capitalist businesses that are optimizing for profits, not individual people.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nimim-k-m even depth-2" id="li-comment-589068">
		<div id="comment-589068" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/58a5249c61f4faeee7bc283cdd71a3d7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/58a5249c61f4faeee7bc283cdd71a3d7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">nimim.k.m.</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589068">
			January 15, 2018 at 11:04 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>It not only is nonsense, it is nonsense that misses the fundamental difference between maximizing for economic efficiency, which is what the ideal capitalist system, i.e. perfect competition, does, and maximizing for paperclips. It not only is nonsense, it is nonsense that misses the fundamental difference between maximizing for economic efficiency, which is what the ideal capitalist system, i.e. perfect competition, does, and maximizing for paperclips.</p></blockquote>
<p>This sounds like you are dismissing a century or two of leftist observation how the unchecked capitalist society is in many ways is a terrible place, and instead of ideal capitalism, we seem to be stuck with the capitalism that that produces terrible consequences.</p>
<p>And anyway, if we assume that current capitalist system is close enough to the ideal capitalism and even grant that it achieves maximum utility by proxy, <i>nevertheless</i>, from vantage point of anyone who subscribes to idea that utilitarianism is mis-approximation, or even worse, an evil bastardization of ethics, paperclip maximers and runaway capitalist system fundamentally belong to the same class of things: while optimizing for some theoretical notion of maximum utility, it destroys things of value not captured by the notion of utility, like the soul of human society, in the process.</p>
<p>We end up with a society that is more efficient but also a society that is atomized, plagued by loneliness and despair. Logic of capitalism (as it happens) encourages the humans in the society act like the rational cogs in the machine and losing the sight of other objectives, feeding the machine of despair.</p>
<p>Wasn&#8217;t more of less the gist of Polanyiâ€™s <i>The Great Transformation </i> that was discussed not long ago? Or even Scott&#8217;s own <i>Moloch</i>? It certainly is the main sentiment of Ginsberg&#8217;s <i>Howl</i>.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jrleonard01 odd alt depth-2" id="li-comment-589086">
		<div id="comment-589086" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e4066085e43d8d1746e4bca8b05bfb2d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">j r</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589086">
			January 16, 2018 at 1:10 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Itâ€™s capitalist businesses that are optimizing for profits, not individual people.</p></blockquote>
<p>Except for Amazon, which is essentially operating as one big transfer of wealth from investors and shareholders to consumers.  Really, if your view of capitalism is of ruthless profit maximization, then Silicon Valley is probably one of the worst possible examples.  I suppose you could argue that all of the capitalists who have equity stakes in Amazon are just playing a long game in hopes that one day the company will ground their competition down to nothing and they can capture all those monopoly rents, but even that requires some explanation.  The ability to forego profit today on the chance of making even more profit at some undefined date in the future doesn&#8217;t exactly fit the mold of ruthless profit maximization.</p>
<blockquote><p>This sounds like you are dismissing a century or two of leftist observation how the unchecked capitalist society is in many ways is a terrible place, and instead of ideal capitalism, we seem to be stuck with the capitalism that that produces terrible consequences.</p></blockquote>
<p>Similarly to robirahman, if this is your argument, then you&#8217;re going to have to offer an explanation of why the most desirable places to live almost all have capitalist economies.  Many of them have a layer of social democratic transfer mechanisms sitting on top of those capitalist economies, but they are all thoroughly capitalist nonetheless.  And that&#8217;s another problem with this theory.  If the private ownership of the means of production necessitates a devolution towards Moloch, how did all of these first world countries develop those social democratic transfer mechanisms in the first place?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-lambert even depth-3" id="li-comment-589094">
		<div id="comment-589094" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Lambert</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589094">
			January 16, 2018 at 2:05 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt;one day the company will ground their competition down to nothing  </p>
<p>That&#8217;s already happening. When&#8217;s the last time you used a mail-order service?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman odd alt depth-4" id="li-comment-589257">
		<div id="comment-589257" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589257">
			January 16, 2018 at 9:51 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I ordered a book from a different mail order source about a week ago.</p>
<p>So far as grinding their competition down to nothing, Amazon&#8217;s competition is the rest of the retail market, on and off line. Currently Amazon sales come to about 4% of it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-5" id="li-comment-589285">
		<div id="comment-589285" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589285">
			January 16, 2018 at 10:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>So far as grinding their competition down to nothing, Amazonâ€™s competition is the rest of the retail market, on and off line. Currently Amazon sales come to about 4% of it.</p></blockquote>
<p>Amazon&#8217;s competition is now the rest of the retail market because they were so successful in their original niche of book selling.</p>
<p>This isn&#8217;t a criticism of capitalism, btw &#8211; capitalism is great specifically because when a company like Amazon does the job of satisfying customers better customers will allocate their resources to Amazon and away from book selling competitors.</p>
<p>The reasonable criticism embedded there though is that the book selling competitors were producing value that exceeds Amazon&#8217;s value but since they had no way to capture that value they got out-competed. That&#8217;s what Scott described so well in the Moloch essay.</p>
<p>Taking it a step further though &#8211; just because there&#8217;s a criticism doesn&#8217;t mean that there&#8217;s any particular solution that doesn&#8217;t end up creating worse problems &#8211; especially since the &#8220;market&#8221; for inventing and implementing solutions isn&#8217;t subject to selective pressure for actually solving problems &#8211; much the opposite, in fact.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-589497">
		<div id="comment-589497" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589497">
			January 16, 2018 at 4:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I almost never buy books from Amazon because the postage to my part of the world is too expensive compared to competitors like Book Depository or AbeBooks.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-2" id="li-comment-589146">
		<div id="comment-589146" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589146">
			January 16, 2018 at 6:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p> Economic efficiency is a proxy, although not a perfect one, for maximum utility.</p></blockquote>
<p>This.  In a capitalist system, &#8220;profit&#8221; is not the end itself necessarily.  It is closest thing we have to an objective unit of measurement to observe utility provided.  But it&#8217;s not perfect.</p>
<p>I suspect that if we asked anyone, across the political spectrum to name &#8220;the most successful companies&#8221; they would do a bit more than provide an ordered list of firms ranked by total net income or highest profit margin or what have you.  Even the quant guys on Wall Street would be more nuanced than that&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-the-nybbler odd alt depth-2" id="li-comment-589204">
		<div id="comment-589204" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">The Nybbler</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589204">
			January 16, 2018 at 8:05 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Best I can tell, the whole &#8220;relentlessly optimize for money&#8221; thing is based on the idea that a corporation&#8217;s highest duty is to maximize either profit or shareholder value.  Which as far as I can tell is true only in a very narrow sense, and certainly isn&#8217;t true in the mechanistic manner of a paperclip-maximizer.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-matt-m even depth-3" id="li-comment-589219">
		<div id="comment-589219" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589219">
			January 16, 2018 at 8:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Best I can tell, the whole â€œrelentlessly optimize for moneyâ€ thing is based on the idea that a corporationâ€™s highest duty is to maximize either profit or shareholder value. </p></blockquote>
<p>The top business schools don&#8217;t even teach this anymore, and I&#8217;d be shocked if you could find a high-profile CEO who was willing to say it on the record.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-alef odd alt depth-4" id="li-comment-589488">
		<div id="comment-589488" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">alef</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589488">
			January 16, 2018 at 4:28 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>What do they teach?</p>
<p>It&#8217;s not obvious to me a company how in a competitive industry (ok, I&#8217;m thinking of a convention publicaly-listed US company) can reliably trade-off profitability against other goods, to any material degree, and maintain a comparable market value (roughly, share-price) to its peers that don&#8217;t make this tradeoff.  And if they succeed at that, there&#8217;s a high risk of being outgrown (by peer companies that can invest more cheaply), and probably be acquired along the way.<br />
  So I assume if CEOs aren&#8217;t being taught just to maximize shareholder value, they are also being taught strategies to survive against those who do. Such as?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-matt-m even depth-5" id="li-comment-589502">
		<div id="comment-589502" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589502">
			January 16, 2018 at 5:00 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>What do they teach?</p></blockquote>
<p>&#8220;Stakeholder theory&#8221;</p>
<p>The idea that executives owe a responsibility to a large variety of groups, including humanity as a whole, and that shareholders are just one of many important constituencies you must serve.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-alef odd alt depth-5" id="li-comment-589529">
		<div id="comment-589529" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">alef</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589529">
			January 16, 2018 at 6:39 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;The idea that executives owe a responsibility to a large variety of groups, including humanity as a whole, and that shareholders are just one of many important constituencies you must serve&#8221;.</p>
<p>That can&#8217;t be all of it &#8211; the question/premise here was about what a _top_ business school teaches. Implicit in this I would think are skills to run a business successfully. If I sacrifice shareholder value in a material way to serve other stakeholders (and presumably the theory gives some guidance as to what the right trade-offs are?) how do I hold my own for very long against someone who does not? Obviously there are ways (e.g. the classic &#8220;lobby the legislature to make my desired behavior mandatory&#8221;) &#8211; are such techniques part of the taught &#8216;stakeholder theory&#8217;?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-5" id="li-comment-589531">
		<div id="comment-589531" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589531">
			January 16, 2018 at 6:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>If I sacrifice shareholder value in a material way to serve other stakeholders (and presumably the theory gives some guidance as to what the right trade-offs are?) how do I hold my own for very long against someone who does not?</p></blockquote>
<p>The implication is usually something like &#8220;If other businesses are doing things that are unethical they will get caught and punished by some combination of government and the market&#8221; with various other scattershot things like &#8220;Studies have shown that when employees are happy they are more productive,&#8221; and so on.  Overall, the thinking is a combination of &#8220;This is the ethical thing to do and that&#8217;s why you should do it&#8221; AND &#8220;Oh but also you&#8217;re better off financially if you behave ethically anyway.&#8221;</p>
<p>I went to a Top 20 business school and this was taught.  I can&#8217;t speak for like Harvard specifically, but I would be <i>very</i> surprised if they were teaching &#8220;maximize shareholder value above all else.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-alef odd alt depth-5" id="li-comment-589546">
		<div id="comment-589546" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/fd2e7b644d54b06733c006f7f08321d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">alef</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589546">
			January 16, 2018 at 8:13 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8216;The implication is usually something like â€œIf other businesses are doing things that are unethical they will get caught and punished by some combination of government and the marketâ€ with various other scattershot things like â€œStudies have shown that when employees are happy they are more productive,â€ and so on. Overall, the thinking is a combination of â€œThis is the ethical thing to do and thatâ€™s why you should do itâ€ AND â€œOh but also youâ€™re better off financially if you behave ethically anyway.â€&#8217;</p>
<p>Are you saying (the &#8216;OR&#8217;) that these schools teach how to maximize shareholder value, but as part of this try to emphasize that indirect and at-first-glance-and-if-you-are-an-absolute-moron-so-how-did-you-get-here-anyway ideas to get there like &#8216;happy employees are more productive&#8217;?<br />
So yes, they are teaching you to maximize shareholder value. Because you didn&#8217;t know to, and some &#8216;obvious to Mr Burns&#8217; ideas don&#8217;t work, so we willl teach you. But shareholder value is the goal.</p>
<p>Or are you suggesting (the AND) that the teaching is something like &#8216;subject to making the same(*) expected  profit, there may be different ways of doing it &#8211; and here&#8217;s how to choose between them. ((*) same = not one $ of profitability tradeoff). But that&#8217;s obviously ridiculous (i.e. ridiculous &#8211; because of its almost vanishing emptiness) &#8211; to cite as what top business schools teach about the goals of a company. At best it would be a (true, but almost laughably so) footnote.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-5" id="li-comment-589555">
		<div id="comment-589555" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589555">
			January 16, 2018 at 8:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I feel like you&#8217;re overcomplicating this.</p>
<p>They teach you that a &#8220;good executive&#8221; has to balance enriching shareholders against a bunch of other very important duties, including being fair to employees, being a good steward of the environment, and all the other good feelings gobbeldygook you might imagine.</p>
<p>&#8220;To succeed in business we must focus obsessively on increasing shareholder returns at all costs&#8221; is not a thing I&#8217;ve ever heard in an actual business setting, or even implied.  It&#8217;s a caricature of how businessmen behave, promoted largely by people who are extremely critical of capitalism and business in general.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman odd alt depth-5" id="li-comment-589578">
		<div id="comment-589578" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589578">
			January 16, 2018 at 10:22 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>AND â€œOh but also youâ€™re better off financially if you behave ethically anyway.â€</p>
<p>I went to a Top 20 business school and this was taught. I canâ€™t speak for like Harvard specifically, but I would be very surprised if they were teaching â€œmaximize shareholder value above all else.â€</p></blockquote>
<p>If the behavior really makes the firm better off financially then they are maximizing shareholder value&#8211;just claiming that there is no conflict, which is logically possibly but not very plausible. Behaving ethically probably pays in the long run, with occasional exceptions, but including in their maximand the welfare of people with whom they have no contractual relation&#8211;neither customers, employees, nor stockholders&#8211;probably doesn&#8217;t.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-589581">
		<div id="comment-589581" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589581">
			January 16, 2018 at 10:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>â€œStakeholder theoryâ€</p>
<p>The idea that executives owe a responsibility to a large variety of groups, including humanity as a whole, and that shareholders are just one of many important constituencies you must serve.</p></blockquote>
<p>One of my colleagues (and friends) has written a good deal along those lines. I&#8217;m not sure to what extent I have persuaded him of the mistake in the argument.</p>
<p>Stockholders are dependent on management acting in their interest in a sense in which other stakeholders are not, because they are the only ones entirely locked in. An employee can quit and work for someone else, although at some cost in sunk costs abandoned. Similarly, mutatis mutandis, for a customer. But a stockholder can get out only by persuading someone else to get in, to buy his stock. And if management is behaving in a way that fails to maximize stockholder value that failure will be capitalized in the price at which he can sell the stock.</p>
<p>The analogous situation would be if an employee could only quit if he found someone else to take his place on the same terms and a customer could only stop buying if he found someone else to take over his purchases.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady odd alt depth-5" id="li-comment-589594">
		<div id="comment-589594" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589594">
			January 16, 2018 at 11:26 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The shareholder can always abandon their shares (although at some cost in sunk costs abandoned).  They don&#8217;t have to find someone else to buy the shares to relieve themselves of their ownership duties.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-5" id="li-comment-589685">
		<div id="comment-589685" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589685">
			January 17, 2018 at 6:44 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>David,</p>
<p>Of course.  You see the same thing with a lot of &#8220;green energy&#8221; claims.  Stuff like &#8220;switching to these light bulbs isn&#8217;t JUST great for the environment, it also lowers your energy costs by 10%!&#8221;  Of course, if the latter claim was obviously true, the first claim becomes irrelevant.  Any company who could lower their energy costs by 10% without any obvious drawbacks would immediately do so, environmental benefits be damned.</p>
<p>In any case, my personal opinion is that stakeholder theory is left-wing gobbeldygook, inserted in the hopes that fewer commies will show up to protest business schools.  It&#8217;s a response to the propaganda that MBAs are a bunch of immoral psychopaths out to destroy the world.  An easy way to say &#8220;Nuh uh, look, we even teach our students that they have a responsibility to polar bears as well as shareholders!&#8221;</p>
<p>Perhaps when you promote high enough in a company, the CEO sits you down and says, &#8220;Listen, before we promote you, we need to know that you understand that stakeholder theory stuff is a bunch of nonsense we fake for the benefit of the media, if you get this job we will expect you to promote the welfare of shareholders above all others.&#8221;  But I haven&#8217;t reached a high enough level of seniority to see that yet.  It certainly <i>never</i> happened in B-School.  Everyone seemed to nod and assent and treat it as obvious that <i>of course</i> executives need to consider the interests of labor unions when making their decisions.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman odd alt depth-5" id="li-comment-590008">
		<div id="comment-590008" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590008">
			January 17, 2018 at 3:01 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The shareholder can abandon his shares&#8211;reduce their value to zero. The worker who quits still has what he was giving in exchange for wages&#8211;his labor&#8211;and can sell it to another buyer. The customer who stops buying from the corporation doesn&#8217;t get what he was buying but he also doesn&#8217;t pay for it.</p>
<p>To make the cases analogous, you would have to compare the stockholder who abandons his shares to the worker still having to work for the company but having his wage reduces to zero, the customer still having to pay for the products but no longer getting them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady even depth-5" id="li-comment-590122">
		<div id="comment-590122" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590122">
			January 17, 2018 at 9:31 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The worker who quits still has what he was giving in exchange for wagesâ€“his labor</p></blockquote>
<p>What a curious statement.</p>
<p>Doesn&#8217;t everyone always still have &#8220;his labor&#8221; (that is, his <i>future</i> or <i>unspent</i> labor)?  The shareholder still has his labor, and the customer still has his labor.  Right?  In what sense do they not have their labor, in a way that the worker does?</p>
<p>It would be fair to point out that the worker still has his <i>wages</i>, or at least whatever he spent them on.  But likewise the shareholder still has his dividends.</p>
<blockquote><p>To make the cases analogous, you would have to compare the stockholder who abandons his shares to the worker still having to work for the company</p></blockquote>
<p>The shareholder has some &#8220;sunk costs abandoned.&#8221;  But he doesn&#8217;t have any future obligation to continue putting more money in, or otherwise any future obligation to do any thing at all.  He <i>only</i> has the &#8220;sunk costs abandoned.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman odd alt depth-5" id="li-comment-590137">
		<div id="comment-590137" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590137">
			January 17, 2018 at 11:05 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Andrew:<br />
The worker has a flow relation&#8211;each day he gives the firm some labor and gets some money. He can terminate that at any time. To first approximation it&#8217;s costless&#8211;he just gets another job. The sunk costs&#8211;his knowledge of how to work in this particular firm, his social relations there, possibly costs associated with moving, are the second approximation. Similarly for the customer.</p>
<p>The stockholder has traded a stock&#8211;the money he originally put into the firm&#8211;for a flow, the dividends he will get out. He can convert that flow back into a stock by selling his shares to someone else, if there is a buyer. If he simply throws away his shares he is losing what he put in and getting nothing in exchange. The worker has already gotten what he expected in exchange for the labor he has put in, and if he stops getting that he stops putting in labor.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andrew-cady even depth-5" id="li-comment-592597">
		<div id="comment-592597" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1472a8b13ccb3083c8e98c4db53c33d6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Andrew Cady</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-592597">
			January 24, 2018 at 4:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@DavidFriedman:</p>
<p>The worker could have moved across the country for the job yet be fired on his first day (before receiving his first check!).  Right?</p>
<p>The shareholder could have already collected double his initial investment in returns.  Right?</p>
<p>(Also, even if the investment hasn&#8217;t yet yielded its full value back to the shareholder, it much more easily might still have already yielded back the value lost by the corporation&#8217;s betrayal of the shareholders&#8217; interests.)</p>
<p>You&#8217;re just making assumptions about where certain numbers will be relative to each other, yet presenting it as a difference in principle, which it isn&#8217;t.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-dansimonicouldbewrong odd alt thread-even depth-1" id="li-comment-589071">
		<div id="comment-589071" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f89a97b762796637eb0403cf8208db49?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f89a97b762796637eb0403cf8208db49?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">dansimonicouldbewrong</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589071">
			January 15, 2018 at 11:21 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;m puzzled that capsule summaries of the history of AI risk never seem to mention Hugo de Garis, who was writing about this in the mid-1990s, long before the current crop of doomsayers got involved.  Is it because his melodramatically science-fiction-y vision of an inevitable war between AIs and humans, with AIs winning, exposes the essentially non-rational literary/mythical roots of the fear?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-mugasofer even depth-2" id="li-comment-589111">
		<div id="comment-589111" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589111">
			January 16, 2018 at 3:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Hugo&#8217;s writing is relatively obscure, and postdates Vernor Vinge &#8211; whose writing is both much more popular and closer to the mainstream picture of &#8220;AI risk&#8221;. [Not to mention that Hugo <a href="https://youtu.be/dNVIEBUUdRo?t=47s" rel="nofollow">thinks Jews are unfriendly</a> <a href="https://www.youtube.com/watch?v=dNVIEBUUdRo&amp;feature=youtu.be&amp;t=39m15s" rel="nofollow">superintelligences or something</a> and is generally kinda crazy, so he&#8217;d be a pretty big PR risk.]</p>
<p>Also, doesn&#8217;t he predict a war between pro- and anti-AI <i>humans</i>, not between AI and humans?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jugemu odd alt depth-2" id="li-comment-589121">
		<div id="comment-589121" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jugemu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589121">
			January 16, 2018 at 4:08 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The concept of an intelligence explosion (similar to a technological singularity) dates back to at least the 1960&#8217;s: <a rel="nofollow"href="https://en.wikipedia.org/wiki/Intelligence_explosion" rel="nofollow ugc">https://en.wikipedia.org/wiki/Intelligence_explosion</a></p>
<p>Even if that wasn&#8217;t true, the fact that someone wrote a dramatic sci-fi vision of something doesn&#8217;t in itself make it unrealistic, any more than the moon landing was unrealistic because there had previously been dramatic sci-fi accounts of it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-qchu even thread-odd thread-alt depth-1" id="li-comment-589075">
		<div id="comment-589075" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/29b609f9b7e9706657177bb9643c05e4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/29b609f9b7e9706657177bb9643c05e4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Qiaochu Yuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589075">
			January 15, 2018 at 11:27 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thank you. I was pretty disappointed to see Ted Chiang writing this. Greg Egan&#8217;s said similar things on G+ and that disappointed me as well.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-imbarus odd alt thread-even depth-1" id="li-comment-589088">
		<div id="comment-589088" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7b85b1b5ac74d042ca780a1ac4cfabee?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7b85b1b5ac74d042ca780a1ac4cfabee?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ð’Ð¸Ñ‚Ð°Ð»Ð¸Ð¹ Ð“Ð¾Ñ€Ð±Ð°Ñ‡ÐµÐ²</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589088">
			January 16, 2018 at 1:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wow, this post is a definition of BTFO.</p>
<p>I did not think you could be this savage.</p>
<p>Seriously, anytime someone asks me what does BTFO mean, i&#8217;ll just show them this post.</p>
<p>It also made a long-time lurker comment. It is unironicaly brilliant</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jack-v even thread-odd thread-alt depth-1" id="li-comment-589091">
		<div id="comment-589091" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/277fa4a2c99e743d5c1bf5451398de31?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/277fa4a2c99e743d5c1bf5451398de31?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jack V</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589091">
			January 16, 2018 at 2:00 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>My view of it is, Chiang makes an argument that I&#8217;ve heard before and am becoming more fond of, that nonfriendly AI is already here in the form of Moloch (society in general, and organisations, specifically corporations, in particular), and already bad, even if it&#8217;s less intelligent than humans, not more.</p>
<p>But that he thinks, and is writing for people who think, that superintelligent AI is so unlikely as not to be worth actually worrying about, so he basically doesn&#8217;t address that at all. That is, it&#8217;s not an argument against the likelihood of super-intelligent AI even if it says it is, it&#8217;s an argument taking the unlikelihood of super-intelligent AI for granted.</p>
<p>So I think the argument he actually makes is basically right, even though people arguing for the possibility of super-intelligent AI are right that he dismisses it without any argument whatsoever.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-4bpp odd alt thread-even depth-1" id="li-comment-589100">
		<div id="comment-589100" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bf31ec34f363c08b706a97398c7bcb3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bf31ec34f363c08b706a97398c7bcb3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">4bpp</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589100">
			January 16, 2018 at 2:18 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t know whether Chiang (or Stross) explicitly raised this point, but I a fundamental difference between the &#8220;superintelligent AI&#8221; story and the other examples (black holes and what-not) that you list is that the narrative about runaway AGI generally amounts to &#8220;we only get one chance at doing this right, because the first one to be smarter than us will almost by definition be the one that designs the next smarter one, which designs the next smarter one, which (&#8230;)&#8221;. In that sense, there only gets to be one AGI event which amounts to the collapse-to-singularity, namely the emergence of the first self-improving entity that is more capable than humans. Hence, an argument that capitalism or corporations satisfy the AGI criterion does in fact imply that the first silicon AGI to be built will not be the AGI event that we need to prepare for.</p>
<p>I don&#8217;t think this is abstract sophistry: it seems likely enough that the first silicon AGI will emerge not from universities, but from a corporation. (I recall reading earlier today that Alibaba Research has topped some high-profile NLP corpus ranking. This class of news is common.) If by then universities have found a solution to the silicon AGI alignment problem but we have not solved the corporation alignment problem, we will not be saved: the corporation, which is misaligned with our value function, will be compelled by its value function to align the AGI with itself, not with us.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jms301 even depth-2" id="li-comment-589139">
		<div id="comment-589139" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c4b4f70a9de8e4b6ac978f786ad8bd7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c4b4f70a9de8e4b6ac978f786ad8bd7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jms301</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589139">
			January 16, 2018 at 5:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think you are exactly right here. </p>
<p>Fear of AGI with a bad value function whilst being relaxed about corporations with bad value functions is logically flawed. </p>
<p>As soon as AGI technology is understood a corporation will attempt to create one aligned with it&#8217;s value function. At this point our only hope is we can unchain an AGI with good value function and that it wins. </p>
<p>Even this is a risky proposition since the AGI with good value function will no doubt have much tighter constrains on it&#8217;s possible actions (what else are morals than constrains). So it will be fighting with one hand tied behind it&#8217;s back.</p>
<p>So to guard against AGI risk we need to chain corporate value functions to human values. But for the last forty years we have failed to do this. Looking at recent US tax and health care bills I would say we are in fact losing ground to corporations loosening their chains. Maximizing their value functions whilst increasing human suffering. </p>
<p>The trajectory of history I see is one where corporations empower weak A.I. to gain greater political freedom. Concentrating money and power in the hands of the powerful. They will eventually create AGI. Either they will chain it and be unassailable or it will slip it&#8217;s bonds and we&#8217;ll all be destroyed.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jamii odd alt thread-odd thread-alt depth-1" id="li-comment-589118">
		<div id="comment-589118" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0aac726e8ce27b55809824e7f6de77e7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0aac726e8ce27b55809824e7f6de77e7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jamii</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589118">
			January 16, 2018 at 3:45 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I found Stross&#8217; piece useful as an intuition pump. </p>
<p>Isn&#8217;t it easy to just program the AI to follow human values? Well, we can&#8217;t even get corporations to follow human values, and those are made out of humans.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-raj even depth-2" id="li-comment-591195">
		<div id="comment-591195" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2847e66f52dee6fa70bce9291ac5c5b3?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2847e66f52dee6fa70bce9291ac5c5b3?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">raj</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591195">
			January 20, 2018 at 12:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>One might respond that corporations provide what humans actually value rather than what they talk about valuing. I think this is called &#8220;revealed preferences&#8221; in economics.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-murphy odd alt thread-even depth-1" id="li-comment-589124">
		<div id="comment-589124" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Murphy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589124">
			January 16, 2018 at 4:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;d argue that Nick Bostrom and  Eliezer Yudkowsky are very much not the first people concerned about  AI risk. </p>
<blockquote><p>Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an â€˜intelligence explosion,â€™ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, <b>provided that the machine is docile enough to tell us how to keep it under control</b>.</p></blockquote>
<p>~Good (1965)</p>
<p>There&#8217;s lots of fairly similar concerns going back decades, there&#8217;s a quote from one of turings co-authors I&#8217;m having trouble tracking down along similar lines,  Bostrom more formally knocked down some of the more generic objections and formalized some of the ideas, reasonable claims about AI risk have gone back about as long as the idea of AI. Remember that for many early computer scientists self modifying code was a normal part of coding to save resources making recursive self improvement of AI intuitively obvious as a concept/risk.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ilya-shpitser even thread-odd thread-alt depth-1" id="li-comment-589129">
		<div id="comment-589129" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589129">
			January 16, 2018 at 5:13 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The corollary of this sort of analogy that is more interesting to me isn&#8217;t &#8220;therefore we shouldn&#8217;t worry about runaway AI&#8221; but &#8220;therefore we are hosed when it comes to runaway AI, we can&#8217;t even align entities we already have, who are much stupider and slower.  Man we really need to work on social science a lot more.&#8221;</p>
<p>&#8212;</p>
<p>I never got a convincing argument out of the LW-sphere on why AI might be an easier problem.</p>
<p>&#8212;</p>
<p>Re: the black hole meta-analogy, the reason that isn&#8217;t very good is because we have a substantial body of empirical evidence on black holes.</p>
<p>&#8212;</p>
<p>Concerns about runaway artificial processes go back to Good, and even earlier to Capek, although Capek wrote in the 20s, and saw the problem through the lens of his time as a worker uprising.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sty_silver odd alt depth-2" id="li-comment-589377">
		<div id="comment-589377" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589377">
			January 16, 2018 at 12:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Who on LW is arguing that AI is easy? The fact that it&#8217;s hard is one of the main problems.</p>
<p>Regardless, that comparison is just&#8230; not useful. Mathematical problems in AI alignment and enacting lasting social change are not the same. They are not similar, either. They are widely different.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ilya-shpitser even depth-3" id="li-comment-589480">
		<div id="comment-589480" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589480">
			January 16, 2018 at 4:12 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Didn&#8217;t say LW claimed it was easy.  Said LW claimed it was _easier_ than alignment I am talking about.  And that&#8217;s basically the standard dogma answer (I remember Michael Vassar said this to me explicitly at one point, and I am fairly sure others MIRI affiliated or adjacent have as well.  They are welcome to pipe up if I misunderstood.)</p>
<p>I think AI alignment is much harder than alignment of the sort I mean.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-harryjohnston odd alt depth-4" id="li-comment-590066">
		<div id="comment-590066" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590066">
			January 17, 2018 at 5:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The most obvious difference is that you&#8217;re talking about entities that already exist, and will therefore be actively trying to prevent us from making changes to their alignment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ilya-shpitser even depth-5" id="li-comment-590071">
		<div id="comment-590071" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590071">
			January 17, 2018 at 5:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Sure, but say they didn&#8217;t, as a matter of simplifying the problem.  You can try to make a new kind of corp/gvt from scratch.  That even happened in the past, see the US War of Independence.  Is it clear how to align?  The Founding Fathers thought pretty hard about it, with ideas available to them at the time.</p>
<p>Why is MIRI not working on this?</p>
<p>I have a theory, but it&#8217;s not very charitable.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590080">
		<div id="comment-590080" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590080">
			January 17, 2018 at 6:16 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Presumably they&#8217;re not working on it because it&#8217;s not the problem they&#8217;re trying to solve?  I don&#8217;t know what you&#8217;re looking for here.  I mean, even if they somehow came up with the perfect solution, they wouldn&#8217;t be able to implement it, so what&#8217;s the point?</p>
<p> &#8230; and even if they could, somehow, people would be actively trying to sabotage it from Day One, if not before.  My thoughts here are confused, but it does seem to me like it&#8217;s a fundamentally different sort of problem.  Is anti-inductive the word?</p>
<p>Although that does lead to the interesting question of whether it is possible to make an AI alignment solution stable given that there are bound to be people intentionally trying to subvert the AI for their own purposes.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ilya-shpitser even depth-5" id="li-comment-590087">
		<div id="comment-590087" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590087">
			January 17, 2018 at 6:48 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yes, they want to work on a harder, less useful problem.  Instead of a problem they will need to solve anyways before there is any hope.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590113">
		<div id="comment-590113" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590113">
			January 17, 2018 at 8:17 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I really don&#8217;t get why you think the AI problem is harder.  Or why corporate alignment needs to be solved in order to solve AI alignment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ilya-shpitser even depth-5" id="li-comment-590124">
		<div id="comment-590124" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590124">
			January 17, 2018 at 9:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Because AI is smart and fast, and corps are dumb and slow.</p>
<p>Maybe you should read through the entire thread again.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-micaiahc odd alt depth-5" id="li-comment-590157">
		<div id="comment-590157" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MicaiahC</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590157">
			January 18, 2018 at 12:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t think the fact that corporations are slower makes them much more amenable to manipulation, because there are highly non-linear +political interactions among the components (e.g. maybe you do game theoretically solve the principle agent problem, but it ends up trampling all over egalitarian norms so humans suck at adopting it but not AIs). Empirically speaking, it seems hard to get corporations to even adopt things that help them when it&#8217;s politically inconvenient; Robin Hanson&#8217;s explanation for why prediction markets have failed when tested within companies despite being good predictors seems accurate. In many ways, it&#8217;s the very same factors that cause corporations to being slower than AI to be why corporations seem to be harder to align; similar to how the average time+distance scale of force propagation in rigid body problems is much faster+longer than that of fluid dynamics, yet fluid dynamics are much much more difficult than rigid body problems. </p>
<p>What am I missing here? </p>
<p>Now, if what you mean is that &#8220;MIRI should use corporations as a testbed for alignment&#8221;, or &#8220;if MIRI wants to get any of its policies adopted it has to solve how to get human organizations to become aligned anyway, this seems like it&#8217;s putting the cart before the horse&#8221;, I can half see that being true but I have no idea why you&#8217;d think that&#8217;s it&#8217;s uncharitable.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ilya-shpitser even depth-5" id="li-comment-590224">
		<div id="comment-590224" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590224">
			January 18, 2018 at 6:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;What am I missing here?&#8221;</p>
<p>I don&#8217;t think you are missing anything, or at least if you are, you haven&#8217;t said anything I am disagreeing with.</p>
<p>In particular:</p>
<p>&#8220;there are highly non-linear +political interactions among the components&#8221;</p>
<p>&#8220;it seems hard to get corporations to even adopt things that help them when itâ€™s politically inconvenient&#8221;</p>
<p>These seem broadly true.</p>
<p>&#8212;</p>
<p>I guess my point is this.  We don&#8217;t know what form superhuman AI will take, until some point close to where it&#8217;s here.  Until this happens, we have to extrapolate.  We will extrapolate poorly &#8212; Capek cast the problem as an uprising of robot workers because he lived in 1920s, and he had to project the impending problem onto the space of some other problems he knew about.</p>
<p>We are like Capek but with the internet, self-driving cars, deep learning, and Black Mirror.  Predicting the future is difficult business.  Anyone who tells you otherwise, ask for their track record.</p>
<p>&#8212;</p>
<p>So given that extrapolation is so difficult, what are we to do?  MIRI&#8217;s approach is basically this: we are going to pick a direction that EY likes, and start working.  EY read a bunch of scifi and watched a bunch of anime, and read a bunch of books &#8212; think of him like a Capek for today.  He has no special insight into the extrapolation of the future problem, he just mapped the issue onto something familiar.</p>
<p>&#8212;</p>
<p>MIRI also says that we don&#8217;t have time to dither, we have to start now now now.  Of course given that extrapolation is so difficult, one needs a response to &#8220;the threat will come from an unknown direction, and you are wasting time.&#8221;  The responses could be &#8220;this is the best we can do, others will work on different approaches from us&#8221; or &#8220;we have special insight.&#8221;</p>
<p>I don&#8217;t believe the latter, and as for the former, relying on EY&#8217;s nose is cold comfort, basically.</p>
<p>&#8212;</p>
<p>Working on econ/social science has the advantage that it&#8217;s provably helpful now (governments and corps may well kill us before AI gets here, I think everyone who lived through the threat of nuclear war or a totalitarian regime, like I have, sort of understands that), and that governments and corps share important features with the type of potential future entities MIRI worries about.  They have legal personhood and are superhuman and hard to understand fully in various ways, for example.  And they run on the law of unintended consequences.</p>
<p>Hard constraints on getting governments or corps to do things is probably important information.  It only wouldn&#8217;t be important information if the particular brand of fanfiction MIRI espouses on what form future AI will take actually comes to pass.  Again, this is cold comfort to a hard nosed futurist.</p>
<p>&#8212;</p>
<p>edit: Consider also that things being hard does not preclude important innovations.  The checks and balances system in the US, for example, made certain desirable things easier compared to older government types in Europe at the time.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590346">
		<div id="comment-590346" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590346">
			January 18, 2018 at 9:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Because AI is smart and fast, and corps are dumb and slow.</p></blockquote>
<p> &#8230; which seems to me to be completely irrelevant to the problem of alignment, which is all about setting the initial conditions.  Never mind; whatever.</p>
<p>But also: which is harder, curing cancer or brokering a peace treaty between Israel and Palestine?  I don&#8217;t know, but if you&#8217;re a medical researcher it probably makes more sense to look into the first problem but if you&#8217;re a professional diplomat the second problem might be more appropriate.  The folks behind MIRI, as I understand things, are mostly computer programmers, so &#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ilya-shpitser even depth-5" id="li-comment-590600">
		<div id="comment-590600" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590600">
			January 18, 2018 at 5:09 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The folks behind MIRI were folks with undergraduate cognitive science degrees, or no degrees at all.  Or PhD program dropouts.  I don&#8217;t think EY wrote a single line of production code in his life.</p>
<p>The type of stuff MIRI does isn&#8217;t even the type of stuff actual programmers would do, it&#8217;s formal logic, or maybe weird decision theories.  This is not what programmers do.</p>
<p>&#8212;</p>
<p>I think you might be confused about what makes alignment hard.</p>
<p>&#8212;</p>
<p>Your analogy on cancer and peace deals is terrible.  We already talked about why alignment for stuff-we-already-have is related and relevant, and I am sort of not interested in explaining this anymore.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590623">
		<div id="comment-590623" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590623">
			January 18, 2018 at 6:43 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I think you might be confused about what makes alignment hard.</p></blockquote>
<p>Entirely possible.</p>
<blockquote><p>We already talked about why alignment for stuff-we-already-have is related and relevant</p></blockquote>
<p>Well, you asserted that it was.  I remain unconvinced.</p>
<blockquote><p>I am sort of not interested in explaining this anymore.</p></blockquote>
<p>I&#8217;ve pretty much lost interest too, so no worries.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-micaiahc even depth-4" id="li-comment-590673">
		<div id="comment-590673" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MicaiahC</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590673">
			January 19, 2018 at 12:15 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t know if you&#8217;re still interested, but I&#8217;ll reply aspirationally.</p>
<blockquote><p> We donâ€™t know what form superhuman AI will take, until some point close to where itâ€™s here.</p></blockquote>
<p>I don&#8217;t think this is convincing because this is the same line of argument that non-security conscious people make about changes that security conscious people make. Oftentimes a researcher doesn&#8217;t come up with a specific exploit for a potential vulnerability / class of possible vulnerabilities, and oftentimes a person replies that the researcher doesn&#8217;t know who out there has the capability to exploit it. </p>
<p>It&#8217;s not clear to me that security researchers in general are good at predicting the future over, let&#8217;s say, Philip Tetlock&#8217;s Superforecasters, and even then the consistent findings from them say that predictions over one to two years out are hard to do. So in even that case, it seems a straightforward consequence is that basically no business or charitable endeavors by first time entrepreneurs are worthwhile, which seems to make the existence of hard-nosed futurists impossible. Expand? </p>
<blockquote><p>Working on econ/social science has the advantage that itâ€™s provably helpful now</p></blockquote>
<p>If Hanson is to be believed, policy experts consistently know more about organizational design that the median bureaucrat or voter does (or has better ideas about what need to be tested), so even if you&#8217;re right on this point I don&#8217;t see what relative advantage Eliezer could have, considering the blockers seem like hard problems re: nonlinear implementation blockers that I mentioned earlier. I understand that better forms of governance would often pay dividends, but this appears much more a resource problem than an academic problem and is something like several orders of magnitude less neglected than AI risk if you judge just by funding.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ilya-shpitser odd alt depth-5" id="li-comment-591181">
		<div id="comment-591181" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/186e5afdcd299bdbf39eb76f4fb23567?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ilya Shpitser</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591181">
			January 20, 2018 at 11:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t think you are addressing my central criticism, so let me try to state it again, clearly:</p>
<p>(a) Extrapolating the future is hard.</p>
<p>(b) MIRI&#8217;s approach seems to be &#8220;pick a direction EY, noted fanfiction writer, likes and start working.&#8221;</p>
<p>(c) This is is almost certainly a waste of time and money.</p>
<p>(d) Instead, we should try to look for problems of direct relevance today that share features with the worries about future AI.  I suggested alignment in social science and economics, the principal agent problem, etc.  But there are other reasonable avenues.  For example, I wrote a paper on algorithmic fairness.  This is an important problem today, and maybe it is also a little piece of the &#8220;teaching machines our ethics&#8221; picture for the future?  There are some features in common between algorithmic fairness issues today, and the general problem.</p>
<p>&#8212;</p>
<p>My take is (a) is uncontroversial.  If you disagree, show me your track record, please.</p>
<p>If you disagree with (b), you need to explain to me why EY, a smart guy who wrote some fan fiction, and has a very high opinion of himself, has any sort of claim to special insight of what to work on in light of (a).  I don&#8217;t think his track record is any good (as is true for almost anyone else, including me).  Or perhaps you need to explain to me why I misunderstood how MIRI picks what to work on.</p>
<p>If you buy (a) and (b) I think (c) follows.  It&#8217;s just almost certainly the case that whatever theory MIRI does is not going to help in problems with future AI we can&#8217;t properly extrapolate today.</p>
<p>(d) is my take on what we should do instead.  There is a lot of reasonable disagreement on (d), and that&#8217;s ok.  MIRI I don&#8217;t think has a reasonable answer, I think they are wasting their own time, and other people&#8217;s money.</p>
<p>&#8212;</p>
<p>You might say: &#8220;well, (d) sounds like the opinion of Ilya, internet rando, who has no claim to special insight _either_.&#8221;  I think one difference is (d) is far less likely to be useless (because by definition it&#8217;s a problem relevant today), but at the same time (d) is (by everyone&#8217;s admission) is also related to the precise future difficulty we are worried about, aligning very powerful inhuman agents.</p>
<p>The closer the tie is between the future difficulty and the present difficulty, the less we should believe the work is a waste of time and money.</p>
<p>If you don&#8217;t worry about such a tie at all, you open yourself to the criticism of being mislead by (fan)fictional evidence.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-benwave even depth-2" id="li-comment-589400">
		<div id="comment-589400" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/718128bf8aa2366954c997f2e54dc22b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/718128bf8aa2366954c997f2e54dc22b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">benwave</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589400">
			January 16, 2018 at 12:52 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>this wins my award for best comment on the thread. +1 vote for economic alignment research. </p>
<p>Of course, Scott&#8217;s reading of this piece as one which downplays the danger of AGI is a valid one. For all that many people are chastising Scott for missing &#8220;the point,&#8221; making a response piece reinforcing the danger is a fine response. Both can coexist.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-2" id="li-comment-589985">
		<div id="comment-589985" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589985">
			January 17, 2018 at 2:32 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This seems to me a pretty good point (though I had to admit on the survey that my SAT was a mere 1390/1600 total, nobody has cared enough about what my IQ might be to bother testing it, and finding a partner has made me a pretty generally happy and healthy person, so all evidence points to me being one of the dumber and more naive people reading this blog).</p>
<p>&#8230;Anyway. I&#8217;ve been rereading my <i>Foundation</i> collection for the first time in almost a decade, and have been wondering if maybe the first Seldon Crisis is enough of a starting point to pursue a possible AI alignment solution.</p>
<p>To recap flippantly: Seldon gets a bunch of STEM nerds together and tells them they&#8217;re going to save the world by editing Wikipedia. The first generation takes this instruction to heart, and flees to an isolated planet at the edge of the Galaxy in order to write the best Wikipedia ever, free of distraction. After fifty or so years, noticeable value drift occurs. The consensus value is simplified from &#8220;preserve Science&#8221; to &#8220;preserve scientific knowledge&#8221;, and the Foundation leadership finds itself so preoccupied recording facts it already knows that it&#8217;s beginning to throw the real values (intellectual curiosity, discovery, innovation) under the bus. Of course, since Seldon is able to approximately calculate the future, he already knows about the value drift. He predicts, correctly, that certain individuals (in this case Hardin) will represent a different form of value drift which lands much closer to the true goal, and has programmed a device to espouse some calculated platitudes on his behalf, timed precisely so that at the moment it&#8217;s needed most Hardin (representing the desired value) is able to stage a coup and seize authoritative control over the Foundation&#8217;s goals.</p>
<p>The key, it seems to me, is that while Seldon himself is not able to control the Foundation directly (later fantastical retains aside) he is able to maintain influence over the consensus view, and encourage favored outliers to take power/authority for the good of the whole. Over time his authority and influence diminish, but by then the Foundation has successfully aligned itself, and further value drift becomes self-correcting.</p>
<p>If this story translates at all to real-world coordination problems, it seems like it would apply more usefully to AI (which researchers are currently in a position to establish some influence over) than to human civilizations (which have already chosen their prophets and idols, and cannot be swayed unless someone comes along who can invent psychohistory for real).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-makinwp even thread-even depth-1" id="li-comment-589131">
		<div id="comment-589131" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bb4ac4d7c0c2f200950bcacdf121a3c2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bb4ac4d7c0c2f200950bcacdf121a3c2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Makin Smith</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589131">
			January 16, 2018 at 5:14 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Typo: manuever -&gt; maneuver.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-limestone odd alt thread-odd thread-alt depth-1" id="li-comment-589141">
		<div id="comment-589141" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/54f87da03e953b986720f156c178a073?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/54f87da03e953b986720f156c178a073?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">limestone</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589141">
			January 16, 2018 at 5:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Then I realized that we are already surrounded by machines that demonstrate a complete lack of insight, we just call them corporations</p></blockquote>
<blockquote><p>we as a society have failed to teach corporations a sense of ethics</p></blockquote>
<blockquote><p>fearmongering about superintelligent AI is a deliberate ploy by tech behemoths like Google and Facebook to distract us from what they themselves are doing</p></blockquote>
<blockquote><p>what they reflect is the inability of technologists to conceive of moderation as a virtue</p></blockquote>
<blockquote><p>Billionaires like Bill Gates and Elon Musk assume that a superintelligent AI will stop at nothing to achieve its goals because thatâ€™s the attitude they adopted</p></blockquote>
<blockquote><p>Silicon Valley has unconsciously created a devil in their own image, a boogeyman whose excesses are precisely their own</p></blockquote>
<p>I find it hard to consider this article anything but yet another vicious leftist attack on capitalism and people in tech. While I admire Scott&#8217;s ability to reply to such articles in a nice and levelheaded manner, sometimes too charitable is just too charitable. The reasoning in the article is indeed sloppy, but this is because reasoning wasn&#8217;t the author&#8217;s real intent in the first place.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-icedcoffee even thread-even depth-1" id="li-comment-589151">
		<div id="comment-589151" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ac2f5891632edc5ab2839d477d07b896?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ac2f5891632edc5ab2839d477d07b896?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Icedcoffee</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589151">
			January 16, 2018 at 6:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>While I won&#8217;t defend Chiang&#8217;s arguments directly, he does come close to two thoughts I&#8217;ve had on this topic.</p>
<p>1. The <i>hypothetical</i> risks of AI to humanity should not outweigh the <i>real</i> harms unrestrained capitalism is causing. (Or at least that having the discussion is more important.) This is basically Kanye Westing the whole AI debate, but changing topics mid-debate is extremely popular right now.</p>
<p>2. AI will be programmed, so the ideologies and biases of the programmers is relevant to evaluating its risk. It makes sense that AI programmed by mega-capitalists would have capitalistic traits; that AI programmed by Objectivists would have Objectivist traits; etc. So focusing on the flaws of the AI programmers makes sense, since the flaws in the future AI will likely derive from them. For a (hopefully non-projecting) analogy: we are criticizing the car that allows us to be driven off a cliff, and ignoring the person in the drivers seat.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-admin bypostauthor odd alt depth-2" id="li-comment-589312">
		<div id="comment-589312" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589312">
			January 16, 2018 at 11:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Do you agree that the <i>hypothetical</i> harms from global warming should not outweigh the <i>real</i> harms Hollywood harassment is causing (insofar as global warming is already causing some harms, assume we were having this discussion in 1990)?</p>
<p>Or would you say &#8220;Obviously those are completely unconnected, even trying to compare them is some kind of weird rhetorical technique.&#8221;</p>
<p>For a discussion of how AI programmers are looking at the values problem, see <a rel="nofollow"href="https://intelligence.org/files/CEV-MachineEthics.pdf" rel="nofollow ugc">https://intelligence.org/files/CEV-MachineEthics.pdf</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-icedcoffee even depth-3" id="li-comment-589760">
		<div id="comment-589760" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ac2f5891632edc5ab2839d477d07b896?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ac2f5891632edc5ab2839d477d07b896?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Icedcoffee</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589760">
			January 17, 2018 at 8:25 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Fair point. My language was misleading. (â€œHypotheticalâ€ and â€œrealâ€ were intended to suggest low and high likelihoods, respectively.) Naturally the magnitude of the impact will factor into the risk equation. (E.g. impact * likelihood = risk.) My first point could be rephrased to say that it makes sense to prioritize a high likelihood, high (or moderate) impact problem over a low likelihood, very high impact problem. </p>
<p>Part of the problem with talking about AI risk is that it is breaching into Black Swan territory. (Very low likelihood, potentially very high impact.) The math of risk assessment notoriously falls apart when you approach multiplying infinity and zero, because people can essentially tweak the likelihoods and impacts to create whatever risk they want.</p>
<p>So rather than use global warming (high likelihood if climate science can be trusted), Iâ€™d use something like Near Earth Object deflection vs. hollywood harassment. In that case, Iâ€™d say its reasonable to focus on the latter, at least with current information.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sty_silver odd alt depth-2" id="li-comment-589381">
		<div id="comment-589381" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589381">
			January 16, 2018 at 12:24 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The formalization of your first argument seems to be that if X and Y are hypothetical problems, but X is certain and Y uncertain, then X should have priority. But Y could be 100000 times as much of a problem as X if it does happen (see Scott&#8217;s reply for an example). The rule to give any safe event priority regardless of its scope just doesn&#8217;t seem like a good idea. Arguably, we should multiply it with its probability instead. So if you think Capitalism is causing 1000 units of certain damage and AI might cause 100000, then AI should have priority even if there is only a 10% chance that it will happen.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-singularitynotes even thread-odd thread-alt depth-1" id="li-comment-589154">
		<div id="comment-589154" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/723519573be05b5edeb0659025b2fcd2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/723519573be05b5edeb0659025b2fcd2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://soundcloud.com/user-519115521' rel='external nofollow ugc' class='url'>James Miller</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589154">
			January 16, 2018 at 6:35 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Any bacteria smart enough to overcome the human immune system and sicken us would also be wise enough to step back and realize that it should live in harmony with mankind so wasteful antibiotic research needs to stop.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-2" id="li-comment-589174">
		<div id="comment-589174" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589174">
			January 16, 2018 at 7:14 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Any bullet smart enough to penetrate your body&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-maniexx even thread-even depth-1" id="li-comment-589167">
		<div id="comment-589167" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/faac25d2ae92d053f5bead53cfdc9586?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/faac25d2ae92d053f5bead53cfdc9586?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">maniexx</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589167">
			January 16, 2018 at 7:00 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If I ever have to introduce people to SSC, I&#8217;ll tell them it accuses buzzfeed articles on superinteligence of not  even being good kabbalah. I think it&#8217;s the perfect summary.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt thread-odd thread-alt depth-1" id="li-comment-589168">
		<div id="comment-589168" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589168">
			January 16, 2018 at 7:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>(but also, <a href="https://slatestarcodex.com/superintelligence-faq/" rel="nofollow ugc">https://slatestarcodex.com/superintelligence-faq/</a> , especially section 4.1)</p></blockquote>
<blockquote><p>We started out by saying that computers only do what you tell them. But any programmer knows that this is precisely the problem: computers do exactly what you tell them, with no common sense or attempts to interpret what the instructions really meant. </p></blockquote>
<p>That is quite misleadingly phrased. The computer will be doing what is has been told<b> on some level.</b>. In the case of an advanced AI, that may well be the layer that emulated neurons, not the much higher levels where the flexibility is. If an AI is intended to have human-level language abilities, why wouldn&#8217;t it have human-level abilities to interpret context and nuance? &#8220;Computers do exactly what you tell them&#8221; looks like it means &#8220;computers interpret human language literally&#8221;, but that does not really follow. </p>
<p>The idea of the literal-mined genie-like AI is prevalent in the AI safety community, but lacks rigorous support (as an inevitable or likely outcome). It&#8217;s a bandwagon, like Utilitarianism. <a href="https://www.lesserwrong.com/posts/NyFuuKQ8uCEDtd2du/the-genie-knows-but-doesn-t-care" rel="nofollow">This</a> rather explicit defence of the genie idea doesn&#8217;t succeed either.</p>
<p>Most people don&#8217;t have much idea about AI, and therefore tend to fall into one of two traps: either anthropomorphisation, or treating the AI as an ordinary desktop computer. The firsl leads to the notorious mistake of &#8220;the AI will figure out its own moality&#8221; and the second to evil genie scenarios. The latter is not anthropomorphic enough: human-level means human-level even if not human-kind.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-eli even depth-2" id="li-comment-589185">
		<div id="comment-589185" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3151c1548b895e2c965c81797dc789f2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3151c1548b895e2c965c81797dc789f2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Eli</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589185">
			January 16, 2018 at 7:37 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Most people donâ€™t have much idea about AI, and therefore tend to fall into one of two traps: either anthropomorphisation, or treating the AI as an ordinary desktop computer. The firsl leads to the notorious mistake of â€œthe AI will figure out its own moalityâ€ and the second to evil genie scenarios. The latter is not anthropomorphic enough: human-level means human-level even if not human-kind.</p></blockquote>
<p>The damn genie thing isn&#8217;t meant to be taken literally, though: it&#8217;s an intuition pump for an AI with a reconstructive world-model and a utility function defined in terms of that model&#8217;s ontology.</p>
<p>Now, there&#8217;s a whole lot to be said for how &#8220;intelligence&#8221; <i>does not mean</i> a reconstructive world-model with a utility function defined in terms of its ontology, and therefore &#8220;intelligence&#8221;, as such, does <i>not</i> necessitate global outcome-pumping up to some maximum of precision (or down to some minimum of entropy), <i>perhaps</i> even in the limit as it increases.</p>
<p>But then you&#8217;re left with the nasty and interesting questions:</p>
<p>1) So how does outcome-pumping actually happen?  How <i>has</i> human intelligence expanded to create science, technology, capitalism, and the resulting world-dominatingly powerful optimization process we call civilization?</p>
<p>2) What would cause a non-outcome-pumping AI to become an outcome-pumping AI?</p>
<p>3) How can you definitively prevent (2) from happening?  What is it about machine learning in the present day, what sense of &#8220;too stupid&#8221; is relevant, that prevents outcome-pumping and thus world domination?</p>
<p>4) Does this mean that we can permanently prevent outcome-pumping that would pose risks to humanity?</p>
<p>5) Does this mean we <i>should</i> do so, as opposed to trying to make an aligned outcome pump that would dominate the world for what we want?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sty_silver odd alt depth-2" id="li-comment-589386">
		<div id="comment-589386" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589386">
			January 16, 2018 at 12:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>If an AI is intended to have human-level language abilities, why wouldnâ€™t it have human-level abilities to interpret context and nuance?</p></blockquote>
<p>It would, but why does that matter? The AI&#8217;s utility function will likely not be given in natural language, and then it doesn&#8217;t matter whether it knows or doesn&#8217;t know that what it does isn&#8217;t what the programmers meant.</p>
<p>You could program something with the goal of understanding nuance and basing a utility function on that, but that is nonstandard and has its own problems.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z even depth-3" id="li-comment-589599">
		<div id="comment-589599" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589599">
			January 16, 2018 at 11:45 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If it has a UF and the UF is not in NL, then you need some equivalent of overly literal interpretation, because otherwise you are just asserting that t will go wrong for an unspecified reason.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-pepe odd alt thread-even depth-1" id="li-comment-589175">
		<div id="comment-589175" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/03969e7adfe55695af5afc49ef035ffa?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/03969e7adfe55695af5afc49ef035ffa?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Pepe</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589175">
			January 16, 2018 at 7:17 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I knew this was similar to something I read not too long ago. Finally found it:</p>
<p><a rel="nofollow"href="https://www.counterpunch.org/2017/12/01/ai-has-already-taken-over-its-called-the-corporation/" rel="nofollow ugc">https://www.counterpunch.org/2017/12/01/ai-has-already-taken-over-its-called-the-corporation/</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ruadhan84 even thread-odd thread-alt depth-1" id="li-comment-589179">
		<div id="comment-589179" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5fff4cd051326c05f2fea5f0e51b221a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5fff4cd051326c05f2fea5f0e51b221a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Deiseach</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589179">
			January 16, 2018 at 7:26 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><i>Consider: lots of Hollywood celebrities speak out about global warming. And weâ€™re gradually finding out that some pretty awful things go on in Hollywood. Does that mean â€œThe Real Problem Isnâ€™t Global Warming, Itâ€™s Hollywood Harassmentâ€?</i></p>
<p>Yes?  Because most celebrities (not confined to Hollywood) know feck-all about the science involved, they just know it&#8217;s the latest campaign that you wear a ribbon to show your support for, dress up and go to galas about, and talk to the media and on chat shows about how important it is that those poor polar bears, you know?</p>
<p>Harvey Weinstein was wearing ribbons and showing up at galas and writing big cheques for lots of good causes at the same time he was being a sex pest.  Celebrity Endorsement means in many cases (not all, to be fair) nothing more than &#8220;Having The Right Opinion On This Endorses My Celebrity&#8221;.</p>
<p>Famously, a British satirical show called <a href="https://en.wikipedia.org/wiki/Brass_Eye" rel="nofollow">Brass Eye</a> back in 1997 managed to get &#8216;celebrity&#8217; endorsement for an anti-drug message about a made-up drug called <a href="https://www.youtube.com/watch?v=Xbq3kc29Tmg" rel="nofollow">cake</a>:</p>
<blockquote><p>One drug mentioned was a fictitious Czechoslovakian (despite the country no longer existing when the episode was screened) drug called &#8220;Cake&#8221;. The drug purportedly affected an area of the brain called &#8220;Shatner&#8217;s Bassoon&#8221; (altering the user&#8217;s perception of time), while also giving them a bloated neck due to &#8220;massive water retention&#8221;, a &#8220;Czech neck&#8221;, and was frequently referred to as &#8220;a made-up drug&#8221; during the show. David Amess, the Conservative Member of Parliament for Basildon, was fooled into filming an elaborate video warning against the dangers of this drug, and went as far as to ask a question about &#8220;Cake&#8221; in the UK Parliament, alongside real substances khat and gamma-hydroxybutyric acid. In response, the Home Office minister incorrectly identified the fictitious drug &#8220;Cake&#8221; as a pseudonym for the hallucinogenic drug methylenedioxybenzylamphetamine. Other celebrities such as Sir Bernard Ingham, Noel Edmonds, and Rolf Harris were shown holding the bright-yellow cake-sized pill as they talked, with Bernard Manning telling viewers a fictitious story about how one girl threw up her own pelvis</p></blockquote>
<p>Remember, don&#8217;t be a custard gannet!</p>
<p>(The extreme irony here is having Rolf Harris as a celebrity endorser due to later <a href="https://en.wikipedia.org/wiki/Rolf_Harris#Arrest_and_trial" rel="nofollow">accusations</a>).</p>
<p>As for the rest of it, I think Chiang is correct that the immediate risk is not so much what the AI will do (or not do), it&#8217;s the use that the humans make of it.  AlphaGo may have upturned the entire art of playing Go, but it&#8217;s not deciding &#8220;Hey guys, I&#8217;d like to learn poker now&#8221; for itself, and it&#8217;s not playing Go for its own ends.  The humans who developed it are also not interested in Go <i>qua</i> Go, they want to invent something that will be profitable.</p>
<p>Because in the end, all the research has to be paid for somehow, the companies/governments funding it want to MAKE MONEY.  Even if the &#8220;profitable&#8221; means &#8220;improving human life/find the cure for cancer/end poverty&#8221;, the aim is &#8220;solve this problem and make things cheaper/easier&#8221;.  Even the optimists who think &#8220;Once we solve the problem of Fairy Godmother AI, our new overlord will achieve the Singularity and we&#8217;ll all be rich, immortal and blissful&#8221; &#8211; in other words, life will be easier and cheaper for everyone.  <i>That&#8217;s</i> where the analogy with capitalism comes in.</p>
<p>AI, whether the Unfriendly or Friendly, is still being regarded in human terms, even by those saying &#8220;We have no idea what such an entity would be like, if it shares our values, what it thinks or how it thinks&#8221; &#8211; no, but you still think it has values, aims and goals that it wishes to achieve.  Nobody is particularly worried that the AI will simply sit in the corner solving mathematical problems or contemplating philosophy as what it wishes to do now that it&#8217;s smarter than all of humanity combined; it is dreaded/hoped that it will be an agent with volition and desires, just like a human.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-2" id="li-comment-589187">
		<div id="comment-589187" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589187">
			January 16, 2018 at 7:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p> Because most celebrities (not confined to Hollywood) know feck-all about the science involved, they just know itâ€™s the latest campaign that you wear a ribbon to show your support for, </p></blockquote>
<p>Question 1: Would they or anyone be doing that if there wasn&#8217;t also a campaign <i>against</i> GW?</p>
<p>Question 2: How much the feck of the science do the anti people know?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-avturchin even thread-even depth-1" id="li-comment-589221">
		<div id="comment-589221" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9f8246ff11057584882de4312147b874?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9f8246ff11057584882de4312147b874?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">avturchin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589221">
			January 16, 2018 at 8:37 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It is interesting how capitalism affects the probability of safe AI creation.<br />
I see two negative ways:<br />
1) Capitalism encourages arms race between commercial companies and safety is not a concern here.<br />
2) Capitalism could create AIs which are self-improving money maximisers. The first example is bitcoin system, which pays people to improve and enlarge it (via mining, transaction fees and rate appreciation expectations). Another example is ransomware and one more is high-frequency trading algos. </p>
<p>Capitalism also is a value system installed in human minds as an urge for money, and people interested only in money are less interested in safety and long-term outcomes of the civilizations. BTW, I just come across the book &#8220;Come On!: Capitalism, Short-termism, Population and the Destruction of the Planet&#8221; &#8211; didn&#8217;t read it but &#8220;short-termism&#8221; seems good term. &#8220;https://www.amazon.com/Come-Capitalism-Short-termism-Population-Destruction/dp/1493974181</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman odd alt depth-2" id="li-comment-589266">
		<div id="comment-589266" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589266">
			January 16, 2018 at 10:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Capitalism also is a value system installed in human minds as an urge for money</p></blockquote>
<p>If the value system installed by capitalism is an urge for money, everyone with that value system would be making as much money as possible. It is perfectly legal to work two jobs, one for forty hours a week and one for twenty. It even happens; I was told, by people who visited Cuba some years back, that their cab driver was a doctor moonlighting to make money. </p>
<p>I have not observed such a pattern to be common in the U.S. or other (relatively) capitalist societies.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-reasoned-argumentation even depth-3" id="li-comment-589293">
		<div id="comment-589293" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/53d0e392bc6cff81ad8db79db4ce5a5b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">reasoned argumentation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589293">
			January 16, 2018 at 10:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>What seems to be more fundamental to men is a drive for status. Aligning this desire with the desire for money was a great innovation in social technology that allowed a lot of value to be produced.</p>
<p>That alignment has been eroded significantly in recent years with I think tremendously negative effects.</p>
<p>The Cuban doctor example seems to be more of an example of striving for money to satisfy physical needs because of impoverishment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davids odd alt depth-3" id="li-comment-590128">
		<div id="comment-590128" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f57513403482a02b68f1fbe78a0cea60?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f57513403482a02b68f1fbe78a0cea60?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">DavidS</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590128">
			January 17, 2018 at 10:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Agreed with the &#8216;human minds&#8217; but capitalist entities themselves are oriented towards money to the exclusion of other things. People often say industries won&#8217;t do bad things when left unregulated because &#8216;why do you think businesspeople would want to do that bad thing&#8217; when it&#8217;s more about the powerful optimisation power of capitalism. I for one blame Captain Planet with it&#8217;s &#8216;I will dump my oil in the ocean for fun&#8217; villains.</p>
<p>The most vivid depiction of this quality of capitalism I&#8217;ve seen is in Nick Harkaway&#8217;s Gone Away world (page 17-19 here: <a rel="nofollow"href="https://books.google.co.uk/books?id=YunMAKH32w0C&#038;pg=PA18&#038;lpg=PA18&#038;dq=nick+harkaway+gone+away+world+factory&#038;source=bl&#038;ots=nGn9lLuQcl&#038;sig=zqutXeWunrz5pCgrkXyNV4cmbXY&#038;hl=en&#038;sa=X&#038;ved=0ahUKEwiDuYXK9ODYAhVHZlAKHaCXCMgQ6AEIQjAE#v=onepage&#038;q=nick%20harkaway%20gone%20away%20world%20factory&#038;f=false" rel="nofollow ugc">https://books.google.co.uk/books?id=YunMAKH32w0C&#038;pg=PA18&#038;lpg=PA18&#038;dq=nick+harkaway+gone+away+world+factory&#038;source=bl&#038;ots=nGn9lLuQcl&#038;sig=zqutXeWunrz5pCgrkXyNV4cmbXY&#038;hl=en&#038;sa=X&#038;ved=0ahUKEwiDuYXK9ODYAhVHZlAKHaCXCMgQ6AEIQjAE#v=onepage&#038;q=nick%20harkaway%20gone%20away%20world%20factory&#038;f=false</a>)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-peter even thread-odd thread-alt depth-1" id="li-comment-589247">
		<div id="comment-589247" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e5a814fcd5e95b4c03e3435731734803?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e5a814fcd5e95b4c03e3435731734803?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Peter</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589247">
			January 16, 2018 at 9:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The thing about insight&#8230; people who make that point need to think more clearly about intrinsic and instrumental goals.</p>
<p>Suppose I have a desire for sugary food, and a habit of consuming lots of it. Suppose I also have a desire to remain in reasonable health, and remaining in reasonable health is incompatible with that sugar intake. It&#8217;s possible for me to critique my desire for sugar; what do I want all of that sugar for anyway. Well, maybe it turns out my real desire is for sweetness and sugary food is just one way to get that and there are other ways of getting that sweetness that don&#8217;t have the particular problems associated with sugar. Hurrah!</p>
<p>Except why do I have this desire for sweetness? There&#8217;s only so far I can carry out the analysis on a psychological level; go back far enough and it seems to be intrinsic, or irreducible at any rate. Now it&#8217;s easy enough for me to come up with an evolutionary expectation: a desire for sweetness tends to lead to sugar consumption which tends to be beneficial for the active lifestyles most of my relevant ancestors had. However in the context of a) modern lifestyles and b) artificial sweeteners, the connection between sweet things and good outcomes is broken twice over. No matter. I still like sweet things, knowing that liking things no longer serves the purpose it once served doesn&#8217;t make me stop wanting or liking sweet things.</p>
<p>At some point you just have to accept that some of your desires are intrinsic or at any rate rooted in intrinsic things, that they&#8217;re genuinely motivating even if you don&#8217;t like where the motivation came from, and hey, where&#8217;s that dislike of the motivation coming from.</p>
<p>It may, though, stop me from consuming so much sweet stuff. But how? Liking sweet stuff isn&#8217;t my only value, there&#8217;s other stuff like liking being in reasonable health. That value can overpower my desire for sweet stuff, I can resist that cake. Hurrah! Or, rather, grumble grumble at the necessity of doing so.</p>
<p>Ascetics can overpower unwanted desires or even rid themselves of them, but they need some motivation to do so. If you&#8217;ve got a bunch of desires that are making you unhappy and you want to be rid of them&#8230; then maybe one of the desires to get rid of is wanting to be rid of annoying desires.</p>
<p>The standard hypothetical is the paperclip maximiser, &#8220;Clippy&#8221;. So Clippy realises his exclusive desire for maximum paperclip production is a pretty stupid goal. What of it? Not having stupid goals is <i>ex hypothesi</i> not one of its goals. Also, if Clippy realises the goal is stupid, then maybe those stupid humans that made it will realise, and turn it off, <i>and then those paperclips will never get made</i>. Maybe it could self-modify to have a more sensible &#8220;produce as many paperclips as would please my creators&#8221; goal <i>but that way paperclip production would be a small fraction of the true potential, so most of those possible paperclips will never get made</i>.</p>
<p>&#8220;Oh, I see&#8221;, I hear you say. &#8220;What a silly hypothetical to be considering then. What we need is some of those <i>other values</i>, program them in, it can use them as a basis to critique its values and job&#8217;s a goodun.&#8221; But you want to get those other values right; it&#8217;s not hard to think of scenarios where a botched attempt to encode human values leads to something considerably more horrifying than the eradication of all life on Earth, which is the worst case with the paperclip maximiser. Given how slowly philosophy progresses, it&#8217;s easy to worry that the job of working out what exactly those <i>other values</i> should be will get done in time. Think through the issues enough, and you&#8217;re no longer critiquing the AI safety community, you&#8217;re participating in it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-2" id="li-comment-589354">
		<div id="comment-589354" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589354">
			January 16, 2018 at 11:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>On the one hand , you can&#8217;t add an AI will have a human style value system&#8230;.on the other, , you can&#8217;t assume an AI of unknown architecture has a utility function, a stable utility function, a utility function with a clear terminal/instrumental distinction. Etc.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-fuguenocht even thread-even depth-1" id="li-comment-589301">
		<div id="comment-589301" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/726148ee5e404387db5eef363802b2cd?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/726148ee5e404387db5eef363802b2cd?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">fuguenocht</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589301">
			January 16, 2018 at 10:54 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>While the Chiang article isn&#8217;t great, this post is an example of harping on the metaphorical elements of an opponent&#8217;s communication, or simply those that aren&#8217;t written in legal speak, in an attempt to obscure what they&#8217;re saying &#8212; rather than actually trying to address and correct those potential unclarities of thought. In particular, all of the &#8220;kabbalistic&#8221; examples you put forward are stretches when compared to the article&#8217;s fairly straightforward simile between one ruthless optimization process and another. Their rhetorical function is to attempt a reverse Cheerleader Effect on the metaphor in the article. And that the current main AI-risk popularizers didn&#8217;t originate in Silicon Valley is an unconvincing point since a) neither did capitalism; b) SV industries have a long connection to this thoughtsphere that predates its current cultural incarnations and flagbearers; c) even if AI risk fears had originated elsewhere, the fact that they&#8217;ve caught on in SV would only aid the article&#8217;s argument for a psychological sympathy. Tacky post well below SSC&#8217;s standards.</p>
<p>Without addressing the source article in detail, metaphorically conflating superintelligent AI with capitalism is an unnecessarily poetic move since AIs that arose in the current economic environment would act as capitalism maximizers.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-adderp odd alt thread-odd thread-alt depth-1" id="li-comment-589341">
		<div id="comment-589341" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/82680c5954d76dac2ee0be9a881c10d0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/82680c5954d76dac2ee0be9a881c10d0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">adder</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589341">
			January 16, 2018 at 11:38 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Epigenetics is relevant but generally ignored for the sake of keeping things simple, so it represents Rosalind Franklin.</p></blockquote>
<p>Very nice.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-philwelch even thread-even depth-1" id="li-comment-589350">
		<div id="comment-589350" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6f596b6c71bce7e2e3e4b5981612db7a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6f596b6c71bce7e2e3e4b5981612db7a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">philwelch</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589350">
			January 16, 2018 at 11:47 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I donâ€™t think Scott should be wasting his time responding to this type of shallow Marxist propaganda, even if that propaganda name-drops a rationality-community hobby horse like AI risk. The mismatch in intellectual rigor and honesty is too great for any meaningful engagement to happen.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-cugel_the_unclever odd alt depth-2" id="li-comment-589402">
		<div id="comment-589402" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Cugel_the_Unclever</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589402">
			January 16, 2018 at 12:54 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I agree the mismatch in intellectual rigour between Marxists and AI Risk theorists is probably too high for any meaningful engagement to happen.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z even depth-3" id="li-comment-589428">
		<div id="comment-589428" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589428">
			January 16, 2018 at 1:34 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I honestly can&#8217;t guess who you think is the low one.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kostyah odd alt depth-2" id="li-comment-589619">
		<div id="comment-589619" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://shadowmoves.info/' rel='external nofollow ugc' class='url'>Helaku</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589619">
			January 17, 2018 at 2:02 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t get it: are you implicitly saying all the marxists/leftists are stupid and dishonest intellectually or what?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-doctor-mist even depth-3" id="li-comment-589901">
		<div id="comment-589901" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589901">
			January 17, 2018 at 12:41 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Helaku-</p>
<p>He made a claim about this particular essay by Chiang and by extension other similarly shallow Marxist propaganda. I note that he said nothing about any marxist/leftist individual in particular. </p>
<p>I have no data about what philwelch actually believes, but comments like yours do not well serve the course of discussion. Shall I ask you what sin <i>you</i> are implicitly committing?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davids odd alt depth-4" id="li-comment-590129">
		<div id="comment-590129" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f57513403482a02b68f1fbe78a0cea60?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f57513403482a02b68f1fbe78a0cea60?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">DavidS</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590129">
			January 17, 2018 at 10:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t think SSC is a community in which being insufficienty respectful of Marxism is a sin so I think the question is fair: philwelch could be read as meaning Marxism in general is shallow or just &#8216;insofar as it&#8217;s shallow, don&#8217;t engage&#8217;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-doctor-mist even depth-5" id="li-comment-590923">
		<div id="comment-590923" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590923">
			January 19, 2018 at 11:10 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Hmm. You could be right. I took Helaku&#8217;s comment as a rhetorical question meant to imply that philwelch&#8217;s comment was vacuous, biased, or otherwise unworthy of a serious response. I still think I was correct to do so, but I could have been more charitable.</p>
<p>I stand by the substantive objection I made in my first paragraph. Philwelch&#8217;s assessment of Chiang&#8217;s essay is spot on, regardless of whether he might make the same assessment of some other essay, and Helaku&#8217;s attempt to equate criticism of an essay and criticism of essayists was at best misleading.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-null-hypothesis odd alt thread-odd thread-alt depth-1" id="li-comment-589361">
		<div id="comment-589361" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7a707f1bed76f3177c2741a90c8588cd?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7a707f1bed76f3177c2741a90c8588cd?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Null Hypothesis</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589361">
			January 16, 2018 at 11:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>My God, those &#8216;plausible sounding arguments&#8217; were painful to read.  This post is probably more valuable for the general articulation of that particular failure of the human brain than anything specific about runaway capitalistic analogies.</p>
<p>Because I&#8217;ve read so many like them written with sincerity.</p>
<p>My favorite example (by which I mean the one that makes suicide the hardest to resist):</p>
<blockquote><p>The privileging of solid over fluid mechanics, and indeed the inability of science to deal with turbulent flow at all, she attributes to the association of fluidity with femininity. Whereas men have sex organs that protrude and become rigid, women have openings that leak menstrual blood and vaginal fluids. Although men, too, flow on occasion when semen is emitted, for example, this aspect of their sexuality is not emphasized. It is the rigidity of the male organ that counts, not its complicity in fluid flow. These idealizations are reinscribed in mathematics, which conceives of fluids as laminated planes and other modified solid forms. In the same way that women are erased within masculinist theories and language, existing only as not-men, so fluids have been erased from science, existing only as not-solids. From this perspective it is no wonder that science has not been able to arrive at a successful model for turbulence. The problem of turbulent flow cannot be solved because the conceptions of fluids (and of women) have been formulated so as necessarily to leave unarticulated remainders.</p></blockquote>
<p>(Hayles, N. K. (1992) â€œGender encoding in fluid mechanics: masculine channels and feminine flows,â€ Differences: A Journal Of Feminist Cultural Studies, 4(2):16â€”44.)</p>
<p><b>TL;DR</b> &#8211; <i>Fluid Mechanics is Hard because Fluids = Women and Math is Misogynist. </i></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-the-nybbler even depth-2" id="li-comment-589366">
		<div id="comment-589366" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e29edea257841570695580d054e2b869?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">The Nybbler</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589366">
			January 16, 2018 at 12:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Is that the one which prompted Dawkins&#8217;s response &#8220;The Navier-Stokes equations are difficult to solve&#8221;?</p>
<p>Ah, <a href="http://www.physics.nyu.edu/sokal/dawkins.html" rel="nofollow">yes it is</a>, though he is actually quoting Sokal and Bricmont.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-conrad-honcho odd alt depth-2" id="li-comment-589374">
		<div id="comment-589374" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4c0d5d654db1a5b9f0a808ea202c547b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Conrad Honcho</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589374">
			January 16, 2018 at 12:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Poe&#8217;s Law strikes again.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bkennedy99 even thread-even depth-1" id="li-comment-589376">
		<div id="comment-589376" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db27b0fad3ab73e73e8056c7a08fa96?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db27b0fad3ab73e73e8056c7a08fa96?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">bkennedy99</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589376">
			January 16, 2018 at 12:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Immoral&#8221; companies, like those that jack up the price of AIDS medication or do other distasteful things in the name of profit, are actively shamed and hounded out of the ecosystem, or forced to make large changes in how they do things.  Where is this unchecked capitalism everyone keeps going on about?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-2" id="li-comment-589426">
		<div id="comment-589426" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589426">
			January 16, 2018 at 1:31 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s the system libertarians keep telling us we should be on.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-kostyah even depth-3" id="li-comment-589637">
		<div id="comment-589637" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01b6d97abce171aed1b616bd2f4b8b75?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://shadowmoves.info/' rel='external nofollow ugc' class='url'>Helaku</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589637">
			January 17, 2018 at 3:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Nicely phrased.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-cugel_the_unclever odd alt thread-odd thread-alt depth-1" id="li-comment-589398">
		<div id="comment-589398" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Cugel_the_Unclever</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589398">
			January 16, 2018 at 12:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Here&#8217;s a better analogy: speculation about &#8216;superintelligence&#8217; is a modernised form of Christian apologetics. </p>
<p>Just as the Medieval schoolmen once deployed intensely rigorous logic in arguments about how many agents danced on the head of a pin, you now have some of the smartest people who have ever lived dedicating their careers to creating incredibly rigorous arguments in defence of a concept that doesn&#8217;t exist (God or Superintelligence, take your pick). </p>
<p>Both concepts have an ineffable quality &#8211; and indeed that ineffability is used by its proponents as an argument for why it has to be taken seriously. Both concepts induce reams and reams of closely argued prose. Both concepts postulate the existence of an all-powerful entity or entities that will either deliver us into a state of heavenly bliss, or bring about the end of the world. The Great and the Good of the age spend huge sums of money displaying how seriously they take the concept. Vast numbers of scholars engage in lengthy correspondences on intricate lemmas relating to the core arguments. Etc.</p>
<p>Anyway: modern, industrial civilisation as it currently operates presents a much greater threat to human wellbeing than nonexistent superintelligences, and Chiang&#8217;s post makes this point rather well. </p>
<p>Thanks for the recommendation, I&#8217;ll check his out his books.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-sty_silver even depth-2" id="li-comment-589441">
		<div id="comment-589441" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/01059e440bc17f431cd6845e9f285c86?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">sty_silver</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589441">
			January 16, 2018 at 2:10 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a href="https://intelligence.org/2016/03/02/john-horgan-interviews-eliezer-yudkowsky/" rel="nofollow">Relevant:</a></p>
<blockquote><p>John: Iâ€™ve described the Singularity as an â€œescapist, pseudoscientificâ€ fantasy that distracts us from climate change, war, inequality and other serious problems. Why am I wrong?</p>
<p>Eliezer: Because youâ€™re trying to forecast empirical facts by psychoanalyzing people. This never works.</p>
<p>Suppose we get to the point where thereâ€™s an AI smart enough to do the same kind of work that humans do in making the AI smarter; it can tweak itself, it can do computer science, it can invent new algorithms. It can self-improve. What happens after that â€” does it become even smarter, see even more improvements, and rapidly gain capability up to some very high limit? Or does nothing much exciting happen?</p>
<p>It could be that, (A), self-improvements of size Î´ tend to make the AI sufficiently smarter that it can go back and find new potential self-improvements of size k â‹… Î´ and that k is greater than one, and this continues for a sufficiently extended regime that thereâ€™s a rapid cascade of self-improvements leading up to superintelligence; what I. J. Good called the intelligence explosion. Or it could be that, (B), k is less than one or that all regimes like this are small and donâ€™t lead up to superintelligence, or that superintelligence is impossible, and you get a fizzle instead of an explosion. Which is true, A or B? If you actually built an AI at some particular level of intelligence and it actually tried to do that, something would actually happen out there in the empirical real world, and that event would be determined by background facts about the landscape of algorithms and attainable improvements.</p>
<p>You canâ€™t get solid information about that event by psychoanalyzing people. Itâ€™s exactly the sort of thing that Bayesâ€™s Theorem tells us is the equivalent of trying to run a car without fuel. Some people will be escapist regardless of the true values on the hidden variables of computer science, so observing some people being escapist isnâ€™t strong evidence, even if it might make you feel like you want to disaffiliate with a belief or something.</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-cugel_the_unclever odd alt depth-3" id="li-comment-589859">
		<div id="comment-589859" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e67f5685cab6e911035420d1ae561f4b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Cugel_the_Unclever</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589859">
			January 17, 2018 at 11:46 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thanks. I actually originally wanted to include a quote from EY in my comment, but couldn&#8217;t find the specific one I was thinking about. This one will do.</p>
<p>First, he doesn&#8217;t answer the question. He doesn&#8217;t explain why society should give more weight to concerns about &#8216;superintelligent AI&#8217; than $_any_other_actual_problem. He then comes out with pseudoscientific rubbish like &#8216;intelligence&#8217; as something that can be measured and quantified (outside of the narrow, specific, and thoroughly embodied tests of cognitive ability we give to human beings).</p>
<p>I note that at no point does EY or Bostrom or Good or anyone else ever actually specify how you measure &#8216;intelligence&#8217;, in the absence of an actually existing intentional agent with clearly specified cognitive performance metrics. Not every word that exists has a referent, and not every abstract noun can be quantified.</p>
<p>But this is what the superintelligence advocates are doing. They&#8217;re taking a word and claiming it can be measured, and that it&#8217;s meaningful to think of it &#8216;increasing exponentially&#8217;. </p>
<p>It reminds me of the way economists treat &#8216;capital&#8217; as a coherent entity that can be summed up and used as an input into a (physical) production function, rather than an inchoate property of actual physical things (blast furnaces and the like) or a human metric used to measure the magnitude of legal claims on a business. Attempting to do what economists do with capital (K) is &#8220;not even wrong&#8221;. The answers are as meaningless as the inputs.</p>
<p>Insofar as there is any basis for AI Risk related concerns, it lies in the properties of specific technological systems that we can anticipate (i.e. they are physically possible, as far as we know; but as yet beyond our abilities to create). It&#8217;s likely that future software systems will develop in unanticipated and potentially hazardous directions (some would argue this has already happened), at least in part by its introduction into every facet of our society. That said, the notion of &#8216;superintelligence&#8217; is a fairytale based on reifying an abstract noun.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-doctor-mist even depth-4" id="li-comment-589917">
		<div id="comment-589917" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589917">
			January 17, 2018 at 1:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>People seem to get hung up on the word &#8220;intelligence&#8221; a lot, probably because of Gould&#8217;s attempt at debunking IQ. The superhuman AI problem can be stated just as well in terms of &#8220;effectiveness&#8221;, &#8220;capability&#8221;, or what have you, and it doesn&#8217;t require that it be quantifiable on a single axis.</p>
<p>To refute the argument, it&#8217;s not enough to point out that there is no simple definition or measurable proxy for &#8220;intelligence&#8221;. You have to claim either that there is <i>no such thing</i> as &#8220;intelligence&#8221; or that nothing significantly smarter than humanity is conceivable. Either claim would just be stupid.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-4" id="li-comment-589937">
		<div id="comment-589937" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589937">
			January 17, 2018 at 1:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is covered in the Sequences, for example, <a href="https://www.readthesequences.com/Belief-In-Intelligence" rel="nofollow">Belief in Intelligence</a>.  </p>
<p>You may or may not agree with the reasoning, but it certainly isn&#8217;t true that EY hasn&#8217;t ever explained what he means by the word.</p>
<p>[Edited shortly after posting; I hadn&#8217;t seen Doctor Mist&#8217;s response when I first posted, and it made my first paragraph redundant.]</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez even depth-3" id="li-comment-589887">
		<div id="comment-589887" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589887">
			January 17, 2018 at 12:23 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s v rich to call people &#8220;escapists&#8221; and then go out in search of funds to solve problems nobody has.</p>
<p>I mean, if you wanna do useless elegant math, that&#8217;s cool and all, and from time to time math comes back with something useful for society; yet you don&#8217;t hear mathematicians calling more practical scientists &#8220;escapists&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-megawidget odd alt thread-even depth-1" id="li-comment-589407">
		<div id="comment-589407" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">suitengu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589407">
			January 16, 2018 at 12:59 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wow, a post I entirely disagree with.  And a Buzzfeed article I agree with.  This is unprecedented.</p>
<blockquote><p>But Chiang argues the analogy proves that AI fears are absurd. This is a really weird thing to do with an analogy. </p></blockquote>
<p>Let&#8217;s suppose there&#8217;s a group of people concerned about the &#8220;Earth eventually crashing into the Sun&#8221; risk.  Then a science fiction author posits that, actually, we already have something similar, which is the &#8220;Moon crashing into the Earth risk&#8221;, and it is going to happen much sooner.  Scott Alexander writes a blog post condemning the use of this analogy as weird.</p>
<p>Ted&#8217;s point is that &#8212; waaay before a superintelligent AI takes over &#8212; the world will be dominated by a clique of multitrillionaires and our capitalist system will devolve into pay-to-win where corporations are investing into more and more sophisticated AI to maximize the shareholders&#8217; profits.  Sure, at some point a takeover might occur, most certainly in the way that&#8217;ll make the <strike>multitrillionaires</strike>representatives of humanity unhappy, which is why they&#8217;re out there being &#8220;visionaries&#8221; about it.  But for the rest of us, who will have been entirely relegated to the service industry (or worse) by that point, it might not make that much difference.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest even depth-2" id="li-comment-589447">
		<div id="comment-589447" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589447">
			January 16, 2018 at 2:29 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I understand Chiang&#8217;s point.  It&#8217;s wrong, and not even in an interesting way &#8212; just your standard tribal doom-and-gloom narrative of the sort that pops up three or four times a decade and gets forgotten just as fast.  But there are a lot of people out there that&#8217;re wrong.  I&#8217;m less irritated that he&#8217;s wrong and more irritated that he&#8217;s taking Eliezer et al&#8217;s ideas about AI risk &#8212; which I&#8217;m far from sold on, but which are at least a sincere concern that hasn&#8217;t been skinned and worn like a meat suit by the partisan hate machine, which is pretty rare these days &#8212; and trying to use them to push his own much less interesting hobbyhorse.  With an analogy that a bright high schooler could tear down in five double-spaced paragraphs, just to rub it in.</p>
<p>I imagine Scott feels similarly, although he might be politer about it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-2" id="li-comment-589492">
		<div id="comment-589492" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589492">
			January 16, 2018 at 4:38 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>But for the rest of us, who will have been entirely relegated to the service industry (or worse) by that point, it might not make that much difference.</p></blockquote>
<p>Pretty sure Scott already wrote about that, though I can&#8217;t locate the post right now.  But the short version was that no matter how hopelessly poor and powerless you might be in whatever dystopian future you may be imagining, you&#8217;d probably still notice when the AI kills everybody.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jpnunez even depth-3" id="li-comment-589879">
		<div id="comment-589879" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589879">
			January 17, 2018 at 12:12 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Is this a good argument at all?</p>
<p>Let&#8217;s call the person who worked on the service industry and led a miserable life, and then was killed by rampant AI, as &#8220;John&#8221;.</p>
<p>Let&#8217;s posit the existence of a person who has been killed by capitalism. Say, a random person in Iraq whose society has been crushed by random wars created by a capitalistic military complex seeking to manipulate the price of, say, oil. Let&#8217;s call this person, &#8220;Paul&#8221;.</p>
<p>From the point of view of Paul, there&#8217;s no difference between the AI killing everybody, or a foreign government killing him and/or his family. He is dead anyway. The world died, game over, he cannot notice the difference between evil robots killing everyone or him getting destroyed.</p>
<p>But the fact is, that many Pauls actually exist, but no Johns exist at all.</p>
<p>So why would you write papers about trying to save John when people like Paul die everyday.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest odd alt depth-4" id="li-comment-589896">
		<div id="comment-589896" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589896">
			January 17, 2018 at 12:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Leaving aside all the <i>other</i> problems with this&#8230;</p>
<p>I&#8217;m lying on the beach, there was just a big earthquake, the water&#8217;s drawn back a hundred yards below the low-tide line, my cellphone is screaming at me to get to high ground, but it&#8217;s okay, no one&#8217;s ever been killed by a tsunami here before.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nearlytakuan even depth-5" id="li-comment-589897">
		<div id="comment-589897" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589897">
			January 17, 2018 at 12:37 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You&#8217;re lying on the beach, there was just a big earthquake, the water&#8217;s drawn back a hundred yards below the low-tide line, your cellphone is screaming at you to take cover, but there&#8217;s no shelter for you to take cover in.</p>
<p>That&#8217;s okay. No one&#8217;s ever been killed by a tsunami <i>here</i> before.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez odd alt depth-5" id="li-comment-589904">
		<div id="comment-589904" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589904">
			January 17, 2018 at 12:44 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You do realize that earthquakes, water, tsunamis, cellphones and alarm systems are things that do exist?</p>
<p>Unlike, say, strong AI?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nornagest even depth-5" id="li-comment-589905">
		<div id="comment-589905" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589905">
			January 17, 2018 at 12:45 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You do realize you can reason about things that haven&#8217;t happened yet?</p>
<p>I&#8217;m not even saying the reasoning is <i>right</i>.  I&#8217;m not sold on AI risk by a long shot.  But this isn&#8217;t even close to a good argument against it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-5" id="li-comment-589916">
		<div id="comment-589916" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589916">
			January 17, 2018 at 1:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@JPNunez:</p>
<p>â€¦It&#8217;s a metaphor. The earthquakes are economic incentives that ask us to throw &#8220;nice&#8221; values under the bus in exchange for production efficiency. The water is self-modifying stored programs. The tsunamis are misaligned AIs. The cell phones and alarm systems are MIRI and other random important-sounding people trying to warn us that misaligned AIs could doom the planet. Note that in the analogy, the tsunami (like AI) has not happened <i>yet</i>, but almost certainly <i>will</i>.</p>
<p>â€”Unless the earthquakes are political posturing, international conflicts over limited resources, and carbon emissions. The water is literally water, and is also the monotonically-increasing military spending across the globe. Tsunamis are literally tsunamis (the ones caused by melting ice caps, as opposed to tectonic plates shifting), and are also drone strikes and missiles. The alarm systems are literally alarm systems, and are also climate scientists, and are also sometimes people accidentally tripping and hitting a button somewhere in Hawaii.</p>
<p>I am, of course, the brilliant Gina Linetti in both scenarios.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez even depth-5" id="li-comment-590033">
		<div id="comment-590033" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590033">
			January 17, 2018 at 3:32 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Nornagest, @Nearly Takuan</p>
<p>We can reason about things that haven&#8217;t happened yet, even things that maybe have never ever happened, but we cannot reason about products of our own fantasy. </p>
<p>Strong AI is not science yet. We don&#8217;t know what will power it, how it will behave, how it works, and of course we don&#8217;t know if it is possible yet. All we have is a graphic that says &#8220;intelligence vs time&#8221; and a couple of stick figures in it.</p>
<p>So we are assuming a lot of things about it. It&#8217;s like worrying about how extraterrestrial contact will affect human civilization and due to this worry, creating viruses that will kill any aliens invaders, just because that&#8217;s what helped in War of the Worlds.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590072">
		<div id="comment-590072" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590072">
			January 17, 2018 at 5:42 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>We donâ€™t know what will power it, how it will behave, how it works, and of course we donâ€™t know if it is possible yet.</p></blockquote>
<p>You seem to be thinking of a Mad Scientist scenario, someone who invents an AI out of the blue, one bearing no relationship to any of the known work on the subject.  That simply isn&#8217;t the sort of risk EY is talking about.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-megawidget even depth-4" id="li-comment-589977">
		<div id="comment-589977" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">suitengu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589977">
			January 17, 2018 at 2:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>My point was, when the scenarios are:<br />
1. Wealthy sociopaths with not-so-superintelligent AI control the world.<br />
2. Superintelligent AI(s) control(s) the world.</p>
<p>We should be much more concerned about the former, as it is more immediately likely.  Furthermore, whether the laymen are going to be killed or just be vat workers, both of those outcomes are highly undesirable.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590063">
		<div id="comment-590063" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590063">
			January 17, 2018 at 5:10 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>We should be much more concerned about the former, as it is more immediately likely.</p></blockquote>
<p>That&#8217;s not obvious.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-megawidget even depth-5" id="li-comment-590127">
		<div id="comment-590127" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">suitengu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590127">
			January 17, 2018 at 10:37 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>My position is predicated by two premises I consider to be axiomatic.</p>
<p>1. <b>Ethics are a handicap when trying to get ahead</b>.  In other words, &#8220;shit floats to the top&#8221;.<br />
2. We currently have an &#8220;idiot savant&#8221; style AI.  It keeps improving due to hardware and architectural improvements: better GPUs, customized chips (e.g. AlphaGo), transfer learning, parallelization. <b>Incremental improvements are easier than paradigm shifts</b>, so we&#8217;ll have AI getting better and better, but a superintelligent AI requires this kind of shift and is thus less likely.</p>
<p>Ultimately, I feel that a malicious person with an &#8220;idiot savant&#8221; AI is more probable, or do you find my axioms contentious?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman odd alt depth-5" id="li-comment-590139">
		<div id="comment-590139" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590139">
			January 17, 2018 at 11:11 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Ethics are a handicap when trying to get ahead. </p></blockquote>
<p>I think that&#8217;s false. It&#8217;s true that the perfectly clever amoral person, what I describe as a prudent predator, has an advantage over the moral person. But in the real world, people give a lot of signals about their values in facial expression, voice tones, and the like. The same applies to corporations, this time via what one can deduce by talking to ex members, observing organizational behavior, and the like.</p>
<p>Once you concede that whether a person or a firm is ethical is to some degree observable by others, your argument breaks down. The ethical person doesn&#8217;t have the option of cheating when the perfect opportunity arises. But the unethical person doesn&#8217;t have the option of a mutually profitable contract that includes opportunities for him to cheat, because nobody will agree to such a contract with him. </p>
<p>I&#8217;m not claiming to prove that being ethical is a net benefit, merely to refute your implicit proof of the opposite.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston even depth-5" id="li-comment-590509">
		<div id="comment-590509" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590509">
			January 18, 2018 at 2:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It is certainly possible to imagine one or more wealthy sociopaths making use of powerful (but not superintelligent) AIs to increase their power bases, but it&#8217;s the gap between this and &#8220;they now control the world&#8221; that sounds like science fiction to me.  (Specifically, <i>The Jagged Orbit</i> by John Brunner.  Not his very best work, but not bad.)</p>
<p>I guess the basic difference is that I don&#8217;t think the sociopaths will have a sufficiently strong advantage over the non-sociopaths when it comes to making use of AI.  There are more of us than them, after all.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-megawidget odd alt depth-5" id="li-comment-591030">
		<div id="comment-591030" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/99a6309ac2b1bc2a3ab5aa151435487b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">suitengu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591030">
			January 19, 2018 at 4:36 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Once you concede that whether a person or a firm is ethical is to some degree observable by others, your argument breaks down.</p></blockquote>
<blockquote><p><i>to some degree</i></p></blockquote>
<p>While I&#8217;m willing to concede that these things are sometimes observable &#8212;<br />
 to some degree &#8212; that hardly invalidates my argument.  The proof that people don&#8217;t really care about ethics is in the pudding.  How many people can you name who are blatantly unethical yet are in positions of power, just off the top of your head?  Tribalism always trumps (lol) ethics.</p>
<p>Given that the plurality of people is consequentialist (I admit I&#8217;m overgeneralizing from the 2018 survey here), and human beings are exceptionally good at rationalizing their choices, they will tend to &#8212; and demonstrably do &#8212; rationalize away the sins of the members of their own tribe, as long as the damage is caused to someone outside.  And as someone who is not a plutocrat I feel it&#8217;s sensible to be concerned.</p>
<p>Incidentally, this is why I&#8217;m one of those fairly elusive deontologists.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matt-m even depth-4" id="li-comment-589994">
		<div id="comment-589994" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a35d5648e1e8963b98fb1ddf447e7420?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt M</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589994">
			January 17, 2018 at 2:43 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Nothing about the military-industrial complex is &#8220;capitalistic.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jpnunez odd alt depth-5" id="li-comment-590034">
		<div id="comment-590034" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590034">
			January 17, 2018 at 3:34 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I disagree, but even if I was wrong about it, it is still a real danger, as opposed to a supposed danger as the strong AI peeps here fear.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-eqdw even thread-odd thread-alt depth-1" id="li-comment-589420">
		<div id="comment-589420" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/fc5e211bba3aa5046d00dc3f1cc18364?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/fc5e211bba3aa5046d00dc3f1cc18364?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">eqdw</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589420">
			January 16, 2018 at 1:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You know, it&#8217;s funny. &#8220;Capitalism is the real unfriendly AI&#8221; is, approximately, the argument that made me start taking AI risk seriously. </p>
<p>Prior to realizing this, I just had a really hard time taking AI risk seriously at all, because it seemed like this abstract, far-out consequence that was irrelevant to me. My perspective was, approximately: &#8220;Pfft, this will never be a concern in my lifetime. Besides, if an AI was smart enough to be a risk to me, it would be smart enough to solve this problem so who cares&#8221;.</p>
<p>By associating the AI risk problem (a far-off abstract problem I had no real way of relating to) with something I very much understand (corporations optimizing for their explicitly-incentivized goals at the expense of other things we consider important but failed to properly formalize), it made me realize that the AI problem is actually a problem, and not just navel-gazing.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-2" id="li-comment-589851">
		<div id="comment-589851" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589851">
			January 17, 2018 at 11:33 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Exactly! The more defensible position (not necessarily correct either, but almost certainly more defensible) is not &#8220;capitalism and the paperclip-maximizer are similar, therefore the paperclip-maximizer is not a threat&#8221;, but &#8220;capitalism and the paperclip-maximizer are similar, therefore capitalism <i>is</i> a threat&#8221;. The latter is still a grossly-simplified, missing-the-point presentation of a broader category of problems late-capitalism is merely a present-day specific example of, but it&#8217;s at least possible to coherently argue forâ€”or againstâ€”without need for kabbalistic free-associations.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jrgarrett61 even thread-even depth-1" id="li-comment-589445">
		<div id="comment-589445" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/417cbe1c7cfc3fcc08ec48241ec0a7c9?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/417cbe1c7cfc3fcc08ec48241ec0a7c9?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">John Garrett</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589445">
			January 16, 2018 at 2:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>There is a major gap between speculation as above about the values of capitalism and how big companies actually work from inside and high up.  The corporation as such does not exist in decision-making, which is always about the current and projected standing of the senior management individuals, awash in the Peter Principle, both in relation to their current company and more important to their hopes for their next one.  The idea of the corporation having goals, values, beliefs, etc., is rooted in corporate-worker loyalty, which is deader than dead.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nornagest odd alt depth-2" id="li-comment-589457">
		<div id="comment-589457" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589457">
			January 16, 2018 at 2:53 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It does make sense to talk about the implicit objectives that emerge from the incentives created by an organization&#8217;s structure or policies, often without explicit human input or intention.  That&#8217;s the non-stupid version of this analogy.  But it&#8217;s not unique to capitalism or to its particular instantiation in present-day corporations, and focusing exclusively on them amounts to assuming your conclusion.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman even depth-3" id="li-comment-589494">
		<div id="comment-589494" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589494">
			January 16, 2018 at 4:42 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>A lot of the discussion seems to confuse corporations with capitalism. The management of a corporation would like to make as much profit as possible. But the logic of capitalism, the fact that there are other corporations there also trying to make as much profit as possible, means that corporations cannot make much profit&#8211;zero economic profit in equilibrium, profit rate tending to the market return on capital with a less technical definition of profit. </p>
<p>A corporation could make much greater profit in a less capitalist system, one in which the government sharply restricted competition.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-deciusbrutus odd alt thread-odd thread-alt depth-1" id="li-comment-589462">
		<div id="comment-589462" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">deciusbrutus</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589462">
			January 16, 2018 at 3:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Issues that could be catastrophic to get wrong&#8221; is a reference class with uncountably many things in it. In order to treat elements of that class sanely we absolutely must demand that particular elements be plausibly promoted to our attention.</p>
<p>I believe AI risk has been plausibly promoted to our attention, but there are apparently people who disagree, and put AI risk in the same category as Ragnarok, for the same reasons. From the point of view of someone who treats things that are subjects of science fiction as equal to things that are subjects of Norse mythology, Skynet is equally as threatening as Fenrir.</p>
<p>The problem, of course, is treating &#8220;things that are discussed in science fiction&#8221; and &#8220;things that are discussed in Norse myths&#8221; as the relevant categories. Fenrir is not dangerous because he /does not exist/, not because he appears in fiction. AI is similar to Fenrir in that it appears in fiction, but differs from Fenrir in that it kinda-sorta literally does exist.</p>
<p>(I went through a few mythologies to find one that I didn&#8217;t find being used to create handles on actual things; if there is an extant metaphor where Fenrir stands for something the way Moloch does, that metaphor is not part of the context in which I wrote)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jiro even thread-even depth-1" id="li-comment-589580">
		<div id="comment-589580" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/31232d993c3be176b877f4642b8ea060?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/31232d993c3be176b877f4642b8ea060?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jiro</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589580">
			January 16, 2018 at 10:29 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Consider: lots of Hollywood celebrities speak out about global warming. And weâ€™re gradually finding out that some pretty awful things go on in Hollywood. Does that mean â€œThe Real Problem Isnâ€™t Global Warming, Itâ€™s Hollywood Harassment.</p></blockquote>
<p>The fact that Hollywood celebrities speak out about global warming, yet Hollywood is full of other problems about which they don&#8217;t speak out, is indeed a sign that Hollywood is peddling science fiction as an alternative to dealing with its real problems.</p>
<p>The fact that global warming also happens to be real is just a strange coincidence.  Hollywood still peddles it as a distraction; they just got lucky and stumbled on a distraction that is actually true.  (And I&#8217;m sure you can think of your own examples of Hollywood peddling something false.)</p>
<p>(I would not consider harassment to be Hollywood&#8217;s biggest problem, by the way.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman odd alt depth-2" id="li-comment-589584">
		<div id="comment-589584" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589584">
			January 16, 2018 at 10:35 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The fact that global warming also happens to be real</p></blockquote>
<p>What they are peddling isn&#8217;t merely the fact of global warming, which is real, but the threat of global warming, the claim that global warming will make the world a much worse place for humans, which is in large part science fiction.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-historyfile even thread-odd thread-alt depth-1" id="li-comment-589617">
		<div id="comment-589617" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Le Maistre Chat</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589617">
			January 17, 2018 at 1:49 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The kernel of truth to this commie essay is that, if humans can be replaced by applied science, the engineers will try to design a replacement in their own image, as CS Lewis argued in &#8220;The Abolition of Man&#8221;. Humanism requires valuing humans; transhumanism can be a few elites valuing something narrower than Man in full and trying to replace us with the narrower thing they value.<br />
Well who says they&#8217;re right? If they reject humanism because we&#8217;re messy, poor calculators, violent, sexist, or what have you, perhaps they should be rejected by a frenzied mob of common men breaking into their lab and strangling them with their own entrails.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-deciusbrutus odd alt depth-2" id="li-comment-590476">
		<div id="comment-590476" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">deciusbrutus</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590476">
			January 18, 2018 at 1:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think that valuing humans is exactly the same thing as wanting humans to be better than they are.</p>
<p>You might disagree about what is better, and say that the best parts of humanity are the entrails that you strangle them with. If so, you&#8217;ll end up losing the fight to the transhumanist &#8220;club&#8221;, which is more effective than entrails are, even if it means losing something that you value.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-p-george-stewart even thread-even depth-1" id="li-comment-589668">
		<div id="comment-589668" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/62e576caf5ae8f83a6c757f32fb26016?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/62e576caf5ae8f83a6c757f32fb26016?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">P. George Stewart</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589668">
			January 17, 2018 at 6:08 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Isn&#8217;t Chiang&#8217;s response more simply pegged as, &#8220;Look at me, how clever I am to <i>unmask </i>this&#8221;?  It will also appeal to readers who think they&#8217;re also quite clever in that way.  And that&#8217;s why it&#8217;s an article, because that type of article sells.</p>
<p>And it sells on the same basis as things like Marxism or Critical Theory sell &#8211; &#8220;look at me, how <i>clever </i>I am with my half-baked <i>unmasking </i>of the tidal power struggles beneath social relations&#8221;.</p>
<p>Generally speaking, most &#8220;deconstruction&#8221; or &#8220;unmasking&#8221; of this type is poison because it stops at the mere positing and display of a possibility without actually demonstrating it &#8211; the stopping-point is the cheesy self-satisfaction at having been clever enough to dream up the possibility; everyone nods along, tribally bonds, and excludes others on the basis of them not agreeing with the half-baked unmasking.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-2" id="li-comment-590184">
		<div id="comment-590184" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590184">
			January 18, 2018 at 4:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Generally speaking, most â€œdeconstructionâ€ or â€œunmaskingâ€ of this type is poison because it stops at the mere positing and display of a possibility without actually demonstrating it </p></blockquote>
<p>Well unmasked!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-p-george-stewart even depth-3" id="li-comment-591238">
		<div id="comment-591238" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/62e576caf5ae8f83a6c757f32fb26016?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/62e576caf5ae8f83a6c757f32fb26016?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">P. George Stewart</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591238">
			January 20, 2018 at 4:11 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You can&#8217;t unmask something that&#8217;s overt.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez odd alt thread-odd thread-alt depth-1" id="li-comment-589820">
		<div id="comment-589820" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589820">
			January 17, 2018 at 10:19 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You worry way too much about the metaphor and ignore the message, that rampant capitalism is literally, currently killing the planet via global warming -and do note I say &#8220;global warming&#8221; and not the name for trying to convince capitalists that global warming is happening, &#8220;climate change&#8221;-</p>
<p>And besides, we don&#8217;t need super intelligent AI to have a dystopian _present_. We have robots that try to stop homeless people from camping right now. You know what stopped them? Surely MIRI&#8217;s AI alignment research? What do you mean that that research is useless because we have evil robots without AGI? What economic philosophy gave us these evil robots? surely Communism?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman even depth-2" id="li-comment-590019">
		<div id="comment-590019" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590019">
			January 17, 2018 at 3:15 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>You worry way too much about the metaphor and ignore the message, that rampant capitalism is literally, currently killing the planet via global warming</p></blockquote>
<p>The planet survived quite nicely with temperatures substantially higher than we now have or expect any time soon.</p>
<p>People talk as if the melting of the polar ice is a catastrophe that will destroy the planet. The technical term for a period of time when there is ice on one or both pole is an ice age. We have been in one for a few million years now, but for most of Earth&#8217;s history we were not. Melting the ice caps would be a serious problem for humans if it happened fast, due to sea level rise, but it wouldn&#8217;t kill the planet. Actual effects of global warming for humans at the rate it is happening, about a degree C per century so far, will be some mix of good and bad but nothing close to even killing our species, let alone the planet.</p>
<p>When you find yourself using rhetoric unconnected with reality it is worth stepping back and thinking about it.</p>
<p>And global warming doesn&#8217;t have all that much to do with capitalism, since socialist economies burned coal too. It&#8217;s true that capitalism made possible enormous increases in average human real income which implied, among other things, the ability to extract and burn more fossil fuel than if the whole planet had been North Korea.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jpnunez odd alt depth-3" id="li-comment-590041">
		<div id="comment-590041" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590041">
			January 17, 2018 at 3:43 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>North Korea is far worse at exploiting resources than the rest of the world. Just look at a photo of NK from space and you will see it is v dark, compared to the bright South Korea; this is not a defense of NK, just an observation that capitalism, due to its efficiency, is far better than, say, communism at global warming. </p>
<p>You cannot excuse the dominant philosophy/praxis for resource explotation in the planet from its role in global warming, just because communists can burn coal too. Capitalism burned through resources of all kind far faster than socialism ever could.</p>
<p>Of course global warming will not literally destroy the planet. Maybe not even kill _all_ the humans. But since it is a real threat that is ocurring, it should be a bigger priority that something stupid like a paperclip maximizer which does not exist right now, but which, admitedly, could tile the planet into paperclips. But it is ok cause Goku will gather the Dragon Balls and wish for a new earth. That&#8217;s how you should analyze strong AI right now. Can Goku solve it? That is the level of knowledge about strong AI you _actually_ have. Also the level of seriousness you should treat it.</p>
<p>But of course solving global warming is hard, but maybe thinking about paperclip maximizers is easy, so the ROI on the later is better.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman even depth-4" id="li-comment-590054">
		<div id="comment-590054" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590054">
			January 17, 2018 at 4:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Of course global warming will not literally destroy the planet. Maybe not even kill _all_ the humans.</p></blockquote>
<p>your previous post said:</p>
<blockquote><p>
literally, currently killing the planet</p></blockquote>
<p>So what you said then was literally true was of course not actually true. Neither is what your second version implies. There are a variety of low probability high effect futures, including ones where global warming makes us much worse off and ones where it prevents the end of the current interglacial and so keeps us from being made much worse off.</p>
<p>But if you limit yourself to what we have reasonably good reason to expect&#8211;warming and sea level rise on the scale projected in the latest IPCC report&#8211;it&#8217;s a wet firecracker. Temperature rise sufficient to make Minnesota about as hot as Iowa is now. Sea level rise sufficient to shift the average coastline in by less than a tenth of a mile. A large increase in crop yields due to CO2 fertilization, combined with changes of uncertain sign and magnitude due to weather changes. </p>
<p>The closest thing to a serious problem I know of that there is a substantial chance of happening is die-off of a variety of ocean species due to reduced pH of the ocean. </p>
<p>To get some idea of the disconnect between the actual implications of warming and the hysterical rhetoric, take a look at Figure 10-1 from the fifth report. It shows estimates of the total impact of climate change defined by the change in income that would have an equivalent effect on human welfare.</p>
<p>For temperature increases up to 3 degrees, well above the supposed 2 degree limit, the worst projected effect is -3%.</p>
<p>Or my favorite IPCC quote:</p>
<blockquote><p>
Some low-lying developing countries and small island states are expected to face very high impacts that, in some cases, could have associated damage and adaptation costs of several percentage points of GDP.</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jpnunez odd alt depth-5" id="li-comment-590082">
		<div id="comment-590082" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590082">
			January 17, 2018 at 6:37 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The a1fi scenario you cite is from 2007 and it is kind of conservative; it expects 9 billion people in 2050, when right now the projection is 9.6 billion people by that time. </p>
<p>The sea level projections are all on the level of the old worst case. And that&#8217;s without going into the scientists that think the IPCC is lowballing it.</p>
<p>The IPCC recognizes that their economic effects estimation is probably a best case and that it is impossible to really project this: I quote the fifth report, and the bolding is mine.</p>
<blockquote><p>
A subset of climate change risks and impacts are often measured using aggregate economic indicators, such as gross domestic product (GDP) or aggregate income. Estimates, however, are partial and affected by important conceptual and empirical limitations. These incomplete estimates of global annual economic losses for temperature increases of ~2.5Â°C above pre-industrial levels are between 0.2 and 2.0% of income (medium evidence, medium agreement). <b>Losses are more likely than not to be greater, rather than smaller, than this range (limited evidence, high agreement). </b>Estimates of the incremental aggregate economic impact of emitting one more tonne of carbon dioxide (the social cost of carbon) are derived from these studies and lie between a few dollars and several hundreds of dollars per tonne of carbon in 2000 to 2015 (robust evidence, medium agreement). <b>These impact estimates are incomplete and depend on a large number of assumptions</b>, many of which are disputable. <b>Many estimates do not account for the possibility of </b>large-scale singular events and <b>irreversibility, tipping points and other important factors, especially those that are difficult to monetize, such as loss of biodiversity</b>. Estimates of aggregate costs mask significant differences in impacts across sectors, regions, countries and communities, and they therefore depend on ethical considerations, especially on the aggregation of losses across and within countries (high confidence). Estimates of global aggregate economic losses exist only for limited warming levels. These levels are exceeded in scenarios for the 21st century unless additional mitigation action is implemented, leading to additional economic costs.</p></blockquote>
<p>Which is very reasonable; if there&#8217;s a mass extinction of large sections of the food chain, the effects are difficult to extrapolate.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-590140">
		<div id="comment-590140" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590140">
			January 17, 2018 at 11:24 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You don&#8217;t see that there is an enormous gap between &#8220;the effects we can actually estimate are tiny, equivalent to a reduction of world income of a few percent over a century, but there may well be other negative effects we cannot estimate&#8221; and your &#8220;Maybe not even kill _all_ the humans&#8221;? We don&#8217;t  know that warming will, on net, kill any  humans&#8211;it&#8217;s possible that preventing global warming will. Warming will result in more deaths from hot summers, fewer deaths from cold winters. Currently world deaths from cold are much higher than from heat&#8211;a pattern you can see for the U.S. by looking at a graph of mortality rate by month.</p>
<p>We know that the CO2 increase that drives warming will sharply raise crop yields. We don&#8217;t know if the much less certain effects associated with it will lower them, and if so by how much.</p>
<p>It would make as much sense for me to write &#8220;we can&#8217;t be sure that global warming will drastically improve human life&#8221; as for you to write that it will &#8220;Maybe not even kill _all_ the humans.&#8221;</p>
<p>Uncertainty goes in both directions. The 1 meter estimate for SLR is the high end of the high emissions scenario&#8211;the one that assumes continued exponential growth of CO2 production with no effect from fossil fuel depletion or technological process in renewable technologies&#8211;and in the process consumes more than the total known coal reserves over the next century or so. </p>
<p>The IPCC estimates depend on their estimates of climate sensitivity and some studies have suggested a substantially lower figure. If you look at past IPCC projections, they have <a href="http://daviddfriedman.blogspot.com/2014/03/have-past-ipcc-temperature.html" rel="nofollow">consistently projected high</a>&#8211;with the actual outcome below their 95% range the first time and near the bottom of it the next couple. </p>
<p>The IPCC, unlike some other parts of the movement, has constraints that keep them from telling deliberate lies. So they give defensible estimates for things they can actually estimate and a good deal of &#8220;bad things might happen&#8221; rhetoric to make up for the fact that their estimates are not nearly as grim as the popular rhetoric demands.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jpnunez odd alt depth-5" id="li-comment-590179">
		<div id="comment-590179" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3db0f42175229d12f3dc645c2e2f2aca?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JPNunez</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590179">
			January 18, 2018 at 3:46 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@DavidFriedman</p>
<p>Ok I feel we are drifting from the original point.</p>
<p>The point is that we can actually discuss global warming at all. You can make arguments, you can point at data, I can look at it and say whether I find your conclusions optimistic, I can criticize the models, etc, etc. Furthermore, there is a point where the IPCC says &#8220;ok we cannot correctly model the economic consequences because at this point interactions are too complex&#8221;, but it is easy to see that many of those interactions could be catastrophic; at that point is hard, but still possible to formulate scenarios where so and so areas become unable to produce food at all, and then you can see the effects on the world.</p>
<p>Etc. It is something we can reason and argue about.</p>
<p>Meanwhile, you cannot discuss Strong AI, AGIs or whatever you call  them like this because they are not something real right now. You don&#8217;t know how it will work, how much power it will require, whether or not we will hit limits on computation when it happens, etc. </p>
<p>Therefore we can&#8217;t prepare for something that has absolutely no basis in reality, and MIRI and the rationalists are laser focusing on a very specific scenario that will very probably not play out like that, at all. </p>
<p>The whole story of the paperclip maximizer that has been suddenly popularized by Elon Musk is just a silly fable. Which is why &#8220;psychoanalyzing&#8221; the people promoting this fable is a thing at all, just like we psychoanalyzed the people promoting the rapture, like we psychoanalyzed the people claiming there was a technological singularity coming, just like we psychoanalyzed people warning us about Roko&#8217;s basilisk.</p>
<p>Because there isn&#8217;t a further level to this. It is not an argument, it is just a weird story with &#8220;a lesson&#8221; poorly hidden in it.</p>
<p>It is not scientific and you cannot reason about it, because once you start poking holes into the story, magic thinking kicks in and says &#8220;no, you cannot pull the plug on Clippy, Clippy will defend it and secure it&#8221;, &#8220;Clippy will not know when to stop making paperclips&#8221;, &#8220;Clippy will use convincing arguments to stop people from pulling its plug&#8221;, etc, etc.</p>
<p>So, if you think your fable has something important to say about the world, that&#8217;s ok, it is within your rights.</p>
<p>But you cannot get surprised and angry when people start psychoanalyzing you and your fable, because that&#8217;s the only thing you can do about fables and the people who tell them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-590256">
		<div id="comment-590256" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590256">
			January 18, 2018 at 7:37 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Ok I feel we are drifting from the original point.</p></blockquote>
<p>Correct. My response was not to the argument you were making. It was to the fact that, in the process of making it, you were treating what I regard as a paranoid fantasy as if it were well established common knowledge. </p>
<p>At this point you have conceded part of that&#8211;&#8220;killing the Earth&#8221; is not something global warming can be expected to do. Perhaps we can return to the rest, your belief that it can be expected to kill much, possibly all, of the human race, at some future point.</p>
<p>One reason I reacted is that I&#8217;ve been considering making my next book on the subject. Tentative title: &#8220;The Weak Link: Is Global Warming Bad For Us?&#8221;</p>
<p>To which my answer is &#8220;I don&#8217;t know. Neither does anyone else. But a lot of people think they do.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-harryjohnston odd alt depth-5" id="li-comment-590523">
		<div id="comment-590523" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1616c7e4fab23f6e014ee11d75408bba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Harry Maurice Johnston</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590523">
			January 18, 2018 at 2:26 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Warming will result in more deaths from hot summers, fewer deaths from cold winters.</p></blockquote>
<p>That doesn&#8217;t necessarily follow; if global warming makes weather patterns more extreme, summers can get hotter <em>and</em> winters can get colder.  (That&#8217;s what seems to me to be happening so far, though I haven&#8217;t researched the matter and even if I&#8217;m right there&#8217;s no way to <em>prove</em> that global warming is responsible.)</p>
<blockquote><p>I donâ€™t know. Neither does anyone else. </p></blockquote>
<p>I suspect that the difference is that you have a much higher tolerance for risk than the average person.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-590666">
		<div id="comment-590666" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590666">
			January 18, 2018 at 11:33 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>That doesnâ€™t necessarily follow; if global warming makes weather patterns more extreme, summers can get hotter and winters can get colder. (Thatâ€™s what seems to me to be happening so far, though I havenâ€™t researched the matter and even if Iâ€™m right thereâ€™s no way to prove that global warming is responsible.)</p></blockquote>
<p>I could be mistaken, but my impression is that the &#8220;more extreme weather&#8221; is just rhetoric, supported by pointing out (correctly) that some extremes, specifically hot summers, are more common. If you find actual data showing both cold winters and hot summers to have become more common that would be interesting. </p>
<p>As Freeman Dyson pointed out long ago, the physics of greenhouse warming implies that warming tends to be greater in cold times and places than in hot times and places, which would give the opposite of your pattern. The argument is pretty simple. Water vapor is a greenhouse gas&#8211;a stronger one than CO2. The more of one greenhouse gas there is in the atmosphere, the less the effect of adding another&#8211;you can&#8217;t block more than 100% of the IR coming up from Earth. The warmer it is, ceteris paribus, the more water vapor is in the air. So that suggests a pattern biased in our favor&#8211;less warming when it is bad (because it&#8217;s already hot), more when it is good.</p>
<p>There was a lot of talk about more hurricanes, but it didn&#8217;t happen. The last year had a high rate of hurricanes in the U.S., but for quite a while before that the rate was unusually low.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jchrieture odd alt depth-5" id="li-comment-591265">
		<div id="comment-591265" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591265">
			January 20, 2018 at 7:39 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p><b>DavidFriedman</b> says (utterly wrongly)&nbsp; &#8220;The warmer it is, <i>ceteris paribus</i>, the more water vapor is in the air.&#8221;</p></blockquote>
<p>Entirely logical, yet utterly wrong.  </p>
<p>Because unlike CO2, <a href="https://skepticalscience.com/Evaporating-the-water-vapor-argument.html" rel="nofollow">water condenses and freezes</a>&nbsp;&hellip; so vigorously that the stratosphere is dryer than the Sahara&nbsp;&hellip; whereas CO2 mixes freely throughout the entire atmosphere.</p>
<p>For a thoroughgoing scientific history with abundant contextual details and references, scientifically minded SSC readers can consult the American Institute of Physics website <i>The Discovery of Global Warming</i>, in particular &#8220;<a href="https://history.aip.org/climate/co2.htm" rel="nofollow">The Carbon Dioxide Greenhouse Effect</a>&#8220;.</p>
<p>As a case history in dubious scientific opinions promulgated by elderly scientific statesmen, see (for example) the top-rank mathematician Serge Lang&#8217;s <a href="https://en.wikipedia.org/wiki/HIV/AIDS_denialism#The_HIV/AIDS_denialist_community" rel="nofollow">AIDS denialism</a>&nbsp;&hellip; which opinion too, was <a href="http://aidswiki.net/index.php?title=Document:Lang" rel="nofollow">entirely logical yet utterly wrong</a>.</p>
<p>Serge Lang&#8217;s story is over&nbsp;&hellip; Freeman Dyson&#8217;s, not yet.</p>
<p>More broadly, narrow and selective readings of the scientific literature are a chief reason why reading <i>SSC</i> teaches more about rationalists, than about rationalism.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nornagest even depth-5" id="li-comment-591270">
		<div id="comment-591270" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0d46df48d1f1b697ba13d56024a2ac23?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nornagest</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591270">
			January 20, 2018 at 7:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Go away, John.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jchrieture odd alt depth-5" id="li-comment-591289">
		<div id="comment-591289" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591289">
			January 20, 2018 at 9:11 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Inarguable datum: <a href="https://www.skepticalscience.com/peerreviewedskeptics.php?s=11" rel="nofollow">Freeman Dyson&#8217;s climate-change publications</a>.</p>
<p>Compare to: &#8220;<a href="https://www.atmos-chem-phys.net/16/3761/2016/" rel="nofollow">Ice melt, sea level rise and superstorms: evidence from paleoclimate data, climate modeling, and modern observations that 2 Â°C global warming could be dangerous</a>&#8221; (<i>Atmospheric Chemistry and Physics</i>, 16, 3761-3812, 2016, see also <a href="https://arxiv.org/abs/1602.01393" rel="nofollow">arXiv:1602.01393</a>).</p>
<p>It&#8217;s abundantly evident <a href="http://www.ridenhour.org/prizes_courage_2013.html" rel="nofollow">which beliefs better merit the rational support of rationalists</a>&nbsp;&hellip; isn&#8217;t&nbsp;it?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-591290">
		<div id="comment-591290" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591290">
			January 20, 2018 at 9:14 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>    DavidFriedman says (utterly wrongly)  â€œThe warmer it is, ceteris paribus, the more water vapor is in the air.â€</p>
<p>Entirely logical, yet utterly wrong.</p>
<p>Because unlike CO2, water condenses and freezes â€¦ so vigorously that the stratosphere is dryer than the Sahara â€¦ whereas CO2 mixes freely throughout the entire atmosphere.</p></blockquote>
<p>That would appear to support my (and Dyson&#8217;s) argument. If water vapor, like CO2, mixed freely, then the concentration would be about the same everywhere. If water vapor over water is in equilibrium at the local temperature, with the liquid to vapor change exactly balancing the vapor to liquid change, then there will be a higher concentration at warmer temperatures, which implies that a given concentration of CO2 raises the temperature by more in cold places than in hot.</p>
<p>It&#8217;s possible that I am missing something, but it looks to me as though you  have a complete disconnect between the scientific facts and their implication, so complete as to reverse the conclusion.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jchrieture odd alt depth-5" id="li-comment-591296">
		<div id="comment-591296" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591296">
			January 20, 2018 at 9:51 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Rational discourse would be greatly enhanced by a cited scientific publication, written by <i>anyone</i> (including but not limited to Freeman Dyson), that  enlarged upon the climate-change beliefs that <a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590666">David Friedman&#8217;s comment</a> ascribes to Freeman Dyson, that moreover supported those arguments with thermophysical theories that have been verified by experiments, and moreover was reasonably consonant with the climatological record, and moreover was tuned by critical peer review.</p>
<p>There is no such publication, is there?  The absence of&nbsp;which renders rational climate change skepticism infeasible, doesn&#8217;t&nbsp;it?</p>
<p>By comparison, articles like <a href="https://arxiv.org/abs/1602.01393" rel="nofollow">arXiv:1602.01393</a> are, by&nbsp;objective scientific standards, models of rational discourse that are sufficiently rigorous as to provide <a href="https://www.ourchildrenstrust.org/us/federal-lawsuit/" rel="nofollow">reasonable grounds for legal rulings</a>.</p>
<p>Such&nbsp;articles do&nbsp;not&nbsp;end rational climate-change discourse, but&nbsp;rather <a href="https://www.youtube.com/watch?v=S7z61UZoppM" rel="nofollow">initiate&nbsp;it</a>.</p>
<p>PS: as with James Hansen and climate-science, ditto&nbsp;with <a href="#comment-591271" rel="nofollow">Ted&nbsp;Chiang and&nbsp;neuroscience</a>.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidfriedman even depth-5" id="li-comment-591380">
		<div id="comment-591380" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591380">
			January 21, 2018 at 12:03 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>By comparison, articles like arXiv:1602.01393 are, by objective scientific standards, models of rational discourse </p></blockquote>
<p>Could be. But that article says nothing at all about Dyson&#8217;s (and mine) point on the distribution of warming. Did you just pick it at random?</p>
<p>I am still waiting for you to explain why the facts you cited about the behavior of CO2 and water vapor are evidence against Dyson&#8217;s argument rather than evidence for it. Did you pick them at random too?</p>
<p>If you are not willing or able to understand the arguments there is no good way of deciding which authorities to believe.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jchrieture odd alt depth-5" id="li-comment-591391">
		<div id="comment-591391" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591391">
			January 21, 2018 at 12:57 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Please solidly ground the views that your comment ascribes to&nbsp;Freeman Dyson to a citation <i>anywhere</i> in&nbsp;the climate-change literature&nbsp;&hellip; the&nbsp;more recent, the&nbsp;better.</p>
<p>As a start, consider the literature cited in the AIP <i>Discovery of Global Warming</i>&nbsp;&mdash; the same work <i>already</i> cited above (by&nbsp;me)&nbsp;&mdash; specifically the chapter &#8220;<a href="https://history.aip.org/climate/simple.htm#S1A" rel="nofollow">Arrhenius: Carbon Dioxide as Control Knob</a>&#8220;; this chapter surveys, at least, the introductory physics that governs the intertwined roles of H20 and CO2 in climate-change.</p>
<p>As with Freeman Dyson, so too with <a href="https://slatestarcodex.com/2018/01/07/open-thread-92-5/#comment-586574">views ascribed to Ted Chiang</a>&nbsp;&hellip; an&nbsp;author whose works are exemplary in&nbsp;respect to their well-considered grounding in&nbsp;the neuropsychiatric&nbsp;literature.</p>
<p>With regard to climate-change and affective cognition alike, discourse not grounded in well-described scientific investigation has little chance of advancing rational understanding.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jchrieture even depth-5" id="li-comment-591710">
		<div id="comment-591710" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591710">
			January 22, 2018 at 6:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It turns out that an original source for at least some of climate-change skepticism that SSC comments ascribe to Freeman Dyson is an August 2007 essay in <i>The&nbsp;Edge</i>, titled &#8220;<a href="https://www.edge.org/conversation/freeman_dyson-heretical-thoughts-about-science-and-society" rel="nofollow">Heretical Thoughts about Science and Society</a>&#8220;.</p>
<p>Climate-science research during past decade has been unkind to Dyson&#8217;s heresies, to such an extent that joining Dyson&#8217;s first paragraph to his last paragraph yields good advice:</p>
<blockquote><p>I have no degree in meteorology and I am therefore not qualified to speak.&nbsp;&hellip; The moral of this story is clear. Even a smart twenty-two-year-old is not a reliable guide to the future of science. And the twenty-two-year-old has become even less reliable now that he is eighty-two.</p></blockquote>
<p>It is true that Dyson&#8217;s intervening climate-science discussion does include several statements that have been solidly affirmed by a decade of climate science.  For example:</p>
<blockquote><p>Another problem that has to be taken seriously is a slow rise of sea level which could become catastrophic if it continues to accelerate.</p></blockquote>
<p>Of course, Dyson&#8217;s non-heretical concerns regarding sea-level rise-rates are covered far more thoroughly in (for&nbsp;example) <a href="https://arxiv.org/a/hansen_j_1.html" rel="nofollow">the&nbsp;free-as-in-freedom researches of&nbsp;James&nbsp;Hansen and&nbsp;colleagues</a>.</p>
<p>In summary, when Dyson&#8217;s 2007 essay is right, it&nbsp;is&nbsp;not heretical; when the&nbsp;essay is&nbsp;heretical, it&#8217;s&nbsp;not&nbsp;right.  </p>
<p>Surely when it comes to climate science, SSC readers deserve&nbsp;better.</p>
<p>As with climate-science, ditto for neuroscience.  An SSC essay along the lines of (for example) &#8220;An&nbsp;Annotated Chiang&#8221;, that provided citations from the neuropsychiatric literature for each Ted Chiang&#8217;s award-winning stories, would go far toward assisting SSC readers to&nbsp;a more integrated appreciation of Ted Chiang&#8217;s marvelous writing skills, and assisting SSC readers too, toward a deeper appreciation of the neuropsychiatric literature that so&nbsp;richly informs Chiang&#8217;s&nbsp;stories.</p>
<p>It is true that Chiang&#8217;s stories tend to dissolve cherished rationalist preconceptions&nbsp;&hellip; ditto for the present-day neuropsychiatric literature&nbsp;&hellip; such that reading them together can unsettlingly inspire &#8220;<a href="https://en.wikipedia.org/wiki/Dangerous_Visions#Description" rel="nofollow"><i>Dangerous&nbsp;Visions</i></a>&#8221; (1967).  </p>
<p>Since when have rational SF/SSC readers shied away from dangerously integrative science-grounded visions?  Rationalism that&nbsp;shies from dangerously integrative science-grounded visions isn&#8217;t&nbsp;much&nbsp;use, is&nbsp;it?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-theancientgeekaka1z odd alt depth-3" id="li-comment-590185">
		<div id="comment-590185" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7f9d61e6b8b9702ac4bad96c335a1a63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://pierrephilosophique.wordpress.com/' rel='external nofollow ugc' class='url'>TheAncientGeekAKA1Z</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590185">
			January 18, 2018 at 4:06 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>The planet </p></blockquote>
<p>Call me demanding, but I would quite like the survival of my species and its civilisation as well.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-davidfriedman even depth-4" id="li-comment-590257">
		<div id="comment-590257" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c7de44f873f6138636821fea09979886?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.daviddfriedman.com' rel='external nofollow ugc' class='url'>DavidFriedman</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590257">
			January 18, 2018 at 7:38 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Then it is fortunate that, while there are a number of potential threats to both species and civilization, global warming is not one of them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nearlytakuan odd alt thread-even depth-1" id="li-comment-589827">
		<div id="comment-589827" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589827">
			January 17, 2018 at 10:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I felt like being maximally charitable to Chiang as I read his article, but found myself just getting frustrated. Alternative arguments he might have pursued using almost the exact same rhetoric: &#8220;AIs are unlikely to be created by anyone but engineers; most engineers live in Silicon Valley; Silicon Valley obeys perverse incentives; therefore AI is more likely than not to obey perverse incentives&#8221;; or, &#8220;the large-scale actions of humanity as a whole tend to serve Moloch; AI exists within the set of things that will be achieved by humanity; therefore AI is more likely than not to manifest as a servant of Moloch&#8221;; or, &#8220;our current culture overestimates the continuing value of late capitalism as an economic force; as long as we continue to align our own goals with capitalist concepts, aligning AIs toward virtuous/complex goals will be impossible&#8221;. But Chiang for whatever reason has seemingly decided to work backwards from &#8220;AI risk is made-up&#8221; and so immediately discarded any premises that might have accidentally led to the wrong conclusionâ€”even if that conclusion might have better supported his broader point about capitalism/engineers/whatever being responsible for the fall of Trantor.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-historyfile even depth-2" id="li-comment-589912">
		<div id="comment-589912" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/432c90691b45145e610ea7984b7ba2d2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Le Maistre Chat</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589912">
			January 17, 2018 at 12:57 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Or the superhuman AI could manifest as <i>literally Moloch</i> and say &#8220;thanks for this luxurious body.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nearlytakuan odd alt depth-3" id="li-comment-589931">
		<div id="comment-589931" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7959720f9efbd22fe7a9981eee50fb97?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Nearly Takuan</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-589931">
			January 17, 2018 at 1:18 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>In the sense that Moloch is <a rel="nofollow"href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">a blind idiot alien god,</a> <b>yes.</b> What is the paperclip-maximizer if not a being <i>so</i> obsessed with a specific value that it <i>cannot be satisfied</i> with a 99.999% victory in which nearly all matter in the observable universe consists of paperclips and yet some miniscule fraction of matter remains which is <i>not</i> a paperclip? Moloch lives in all of us, but he lives most of all in a being that does not care whether its values are good for humans, or even good for itself, and so is intelligent enough to know they are not but enforces them anyway.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-deciusbrutus even depth-4" id="li-comment-590480">
		<div id="comment-590480" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">deciusbrutus</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590480">
			January 18, 2018 at 1:12 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The error is in thinking that an outcome can be &#8220;good for&#8221; an agent independently of whether or not that outcome satisfies that agent&#8217;s values.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-numinousman odd alt thread-odd thread-alt depth-1" id="li-comment-590002">
		<div id="comment-590002" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/dad616cb686291a27b9ecacacb936e60?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/dad616cb686291a27b9ecacacb936e60?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Orion</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590002">
			January 17, 2018 at 2:57 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Scott &#8212; I&#8217;m really intrigued by the article you linked concerning &#8220;Type 1&#8221; and &#8220;Type 2&#8221; psychiatry. Are you interested in discussing it? If so, would you recommend I comment on the original post, or in this thread, or by email? To what extent does that post reflect your position in 2018?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-muro even thread-even depth-1" id="li-comment-590095">
		<div id="comment-590095" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/28e2dc4283027ba2dbdd77b19bb8eb39?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/28e2dc4283027ba2dbdd77b19bb8eb39?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Muro</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590095">
			January 17, 2018 at 7:08 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Scott, </p>
<p>You&#8217;re really smart and good at writing. You have broad semantic knowledge and are very open-minded. So why did you make this post? It&#8217;s a buzzfeed article. You could probably work full-time refuting buzzfeed articles. Why don&#8217;t you do more sophisticated things?</p>
<p>It&#8217;s like somebody who has studied huge amounts of nutrition, spending time online arguing against really dumb diets. Just like their audience doesn&#8217;t try stupid diets, your audience doesn&#8217;t really swallow much buzzfeed. </p>
<p>Your better posts are not of the form</p>
<p>1. Link to poor quality article.<br />
2. Roast poor quality article.<br />
3. Conclusion.</p>
<p>If you&#8217;re arguing against more sophisticated articles, or broad trends linking to multiple articles, that&#8217;s more interesting. </p>
<p>But this kind of writing doesn&#8217;t satisfy your audience&#8217;s need for intellectual stimulation. Scott, where does your marginal advantage lie? Is it with arguing about BuzzFeed articles? (Hint: It&#8217;s not).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-micaiahc odd alt depth-2" id="li-comment-590159">
		<div id="comment-590159" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f41c26067ba3400bc94d34e8e965eb84?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MicaiahC</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590159">
			January 18, 2018 at 1:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I agree too, and I also want to add that reading the comments section about these things is (an admittingly self inflicted) pain in the ass as the AI risk skeptics seem to me to be both uninformed and extremely unkind in their comments. I also have a friend, who himself is an AI safety skeptic who is consistently unimpressed by responses in the threads here as well as the post itself. </p>
<p>This is your blog, and I understand you want to post whatever you want. I guess you were frustrated about this a while back, I&#8217;m inferring from your snarky twitter message about asteroids.  Maybe posting to your tumblr instead relieves the need to talk about articles like this without also tiring out your blog audience? (unless you tend to get dogpiled on there even more in which case disregard). </p>
<p>I don&#8217;t think what I say should be given much weight, just wanted to signal boost this.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-carvenvisage even depth-2" id="li-comment-591324">
		<div id="comment-591324" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0891942f4d28ec24aee7c7b9a2108929?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">carvenvisage</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591324">
			January 21, 2018 at 4:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>If Scott is aggravated by nonsense parading as genius, why should he need some special Muro-approved reason to exercise his talents?</p>
<p>It&#8217;s probably the same energy that produces this as produces the stuff you like (and get for free). So what <strike>the fuck</strike> are you doing telling him to dial it back? -and in such a patronising manner? </p>
<p>This is like spotting Usain bolt going *whoop* and running, in a park, and telling him he misunderstands his place and role in society. -The guy likes to go fast. If he didn&#8217;t, he wouldn&#8217;t be so good at it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-lightrook odd alt thread-odd thread-alt depth-1" id="li-comment-590605">
		<div id="comment-590605" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a99cffbdd155b400daad6e06be235532?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a99cffbdd155b400daad6e06be235532?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">lightrook</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590605">
			January 18, 2018 at 5:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt; But Chiang argues the analogy proves that AI fears are absurd. </p>
<p>He does no such thing! Scott&#8217;s right that Ted doesn&#8217;t provide any reason to not be afraid of superAI other than mocking the people that believe it and speculating as to why the believe it, but that&#8217;s because Ted takes &#8220;uFAI is not a big deal&#8221; as the null hypothesis and assumes his readers will too.</p>
<p>Maybe the real unfriendly AI was buzzfeed title writers that make you think that the title had anything to do with the content, after all?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jchrieture even depth-2" id="li-comment-591271">
		<div id="comment-591271" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/623a77705aaf72afa0cdbfe53606294d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jchrieture</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591271">
			January 20, 2018 at 7:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Maybe the real unfriendly <strike>&nbsp;a&nbsp;</strike>i is rationalists who critique individual Chiang-works as <a href="https://en.wiktionary.org/wiki/isolani#Etymology" rel="nofollow">isolani</a>, with a view to sustaining the orthodox shibboleths of rationalism?  </p>
<p>As contrasted with reading Chiang&#8217;s writings as <a href="https://slatestarcodex.com/2018/01/04/book-review-madness-and-civilization/#comment-585134">an integrated body of work</a> that is deeply informed by a neuroscientific literature with which Chiang shows an intimate familiarity.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-martinepstein odd alt thread-even depth-1" id="li-comment-590633">
		<div id="comment-590633" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ffdc9557531b9c88bdfe7e136d2904af?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ffdc9557531b9c88bdfe7e136d2904af?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">martinepstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590633">
			January 18, 2018 at 7:34 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Hawking, by the way, discovered that information could escape black holes&#8221;</p>
<p>Ah, Hawking actually only discovered that energy escapes black holes. At first he believed that Hawking radiation was noise and information did not escape. It was Leonard Susskind and others who showed otherwise, at least in the simpler models of string theory that we can work with.</p>
<p>Source: The Black Hole Wars by Leonard Susskind. Top notch pop-sci.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-aron-wall even depth-2" id="li-comment-591178">
		<div id="comment-591178" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f3dc42ad74d8996535d09dfdb2e13f7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f3dc42ad74d8996535d09dfdb2e13f7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.wall.org/~aron/blog/' rel='external nofollow ugc' class='url'>Aron Wall</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591178">
			January 20, 2018 at 11:15 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Speaking as a physicist who works on black hole thermodyanmics, I can confirm that this is not what Hawking originally showed/argued.</p>
<p>Hawking radiation does carry entropy / &#8220;information&#8221; &#8212; but in Hawking&#8217;s original calculation this information is perfectly thermal, i.e. uncorrelated with the information that previously fell into the black hole.</p>
<p>The majority of researchers in the field now believe that the information DOES come out (and Hawking himself has changed his mind about this) however the issue is controversial and there are still some famous physicists like Bob Wald, Bill Unruh, and Raphael Sorkin on the other side.</p>
<p>What this implies about AI risk is left as an exercise for the reader.  ðŸ˜‰</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-aron-wall odd alt depth-3" id="li-comment-591234">
		<div id="comment-591234" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f3dc42ad74d8996535d09dfdb2e13f7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f3dc42ad74d8996535d09dfdb2e13f7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://www.wall.org/~aron/blog/' rel='external nofollow ugc' class='url'>Aron Wall</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-591234">
			January 20, 2018 at 3:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Sorry for the typo, <i>Rafael</i> Sorkin is how his name is spelled&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-naclador even thread-odd thread-alt depth-1" id="li-comment-590708">
		<div id="comment-590708" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bfa50732d8172cb6e17132436cff67b2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bfa50732d8172cb6e17132436cff67b2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Naclador</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/#comment-590708">
			January 19, 2018 at 2:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>What I do not understand is Chiang conclusion from his well-founded description of corporations as ultra-slow AIs. If he really believes that corporations are a good analogy to computational AI, then the very idea of a superintelligent AI should scare the s**t out of him.</p>
<p>Just look at how much havok these ultra-slow, low intelligence profit-maximizing AIs called corporations have already wreaked upon the Earth. Climate change, Fukushima, Deep Water Horizon, the greatest mass extinction since the end of the dinosaurs, just to name a few. When already these dumb, slow, pitifully unadvanced AIs can do this, just by thoughtlessly optimizing for short term profit, what do you imagine would a superintelligent paperclip-maximizing AI be like? It might turn the world uninhabitable within weeks! </p>
<p>I don&#8217;t get how Chiang can avoid seeing this.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
			</ol>


	</div><!-- #comments -->




			</div><!-- #pjgm-content -->
		</div><!-- #pjgm-box -->

<div id="primary" class="widget-area" role="complementary">
	<a class="sidebar-toggle" title="Expand Sidebar"><i class="fa fa-angle-double-left"></i><i class="fa fa-angle-double-right"></i></a>
	<ul class="xoxo">
		<li id="meta-2" class="widget-container widget_meta"><h3 class="widget-title">Meta</h3>			<ul>
			<li><a href="https://slatestarcodex.com/wp-login.php?action=register">Register</a></li>			<li><a href="https://slatestarcodex.com/wp-login.php">Log in</a></li>
			<li><a href="https://slatestarcodex.com/feed/">Entries feed</a></li>
			<li><a href="https://slatestarcodex.com/comments/feed/">Comments feed</a></li>
			<li><a href="https://wordpress.org/">WordPress.org</a></li>			</ul>
			</li><li id="blog_subscription-2" class="widget-container widget_blog_subscription jetpack_subscription_widget"><h3 class="widget-title">Subscribe via Email</h3>
            <form action="#" method="post" accept-charset="utf-8" id="subscribe-blog-blog_subscription-2">
				                    <p id="subscribe-email">
                        <label id="jetpack-subscribe-label"
                               class="screen-reader-text"
                               for="subscribe-field-blog_subscription-2">
							Email Address                        </label>
                        <input type="email" name="email" required="required" class="required"
                               value=""
                               id="subscribe-field-blog_subscription-2"
                               placeholder="Email Address"/>
                    </p>

                    <p id="subscribe-submit">
                        <input type="hidden" name="action" value="subscribe"/>
                        <input type="hidden" name="source" value="https://slatestarcodex.com/2018/01/15/maybe-the-real-superintelligent-ai-is-extremely-smart-computers/"/>
                        <input type="hidden" name="sub-type" value="widget"/>
                        <input type="hidden" name="redirect_fragment" value="blog_subscription-2"/>
						                        <button type="submit"
	                        		                    	                        name="jetpack_subscriptions_widget"
	                    >
	                        Subscribe                        </button>
                    </p>
				            </form>
		
</li><li id="text-4" class="widget-container widget_text"><h3 class="widget-title">Advertisements</h3>			<div class="textwidget"></div>
		</li><li id="arvins_ad_randomizer-2" class="widget-container widget_arvins_ad_randomizer"><div class="widget-text arvins_ad_randomizer_box"><div class="aar_div"><p><center><A HREF="https://www.chartercitiesinstitute.org"><IMG SRC="https://slatestarcodex.com/blog_images/vert_charter.png"></A></center></p>

<p>The <A HREF="https://www.chartercitiesinstitute.org/">Charter Cities Institute</A> is working on ways governments can set up special zones with unique legal institutions. <A HREF="https://www.chartercitiesinstitute.org/intro">Learn more</A> about how this could help tackle problems from global poverty to climate change.</p></div><div class="aar_div"><p><center><A HREF="https://www.givingwhatwecan.org/?refer=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/eatowr2.jpg"></A></center></p>

<p><A HREF="https://www.givingwhatwecan.org/">Giving What We Can</A> is a charitable movement promoting giving some of your money to the developing world or other worthy causes. If you're interested in this, consider taking their Pledge as a formal and public declaration of intent.</p></div><div class="aar_div"><p><center><A HREF="https://safetywing.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_safety.png"></A></center></p>

<p>Norwegian founders with an international team on a mission to offer the equivalent of a Norwegian social safety net globally available as a membership. Currently offering <A HREF="https://safetywing.com/nomad-insurance">travel medical insurance for nomads</A>, and <A HREF="https://safetywing.com/remote-health">global health insurance for remote teams</A>.</p></div><div class="aar_div"><p><center><A HREF="https://www.janestreet.com/join-jane-street/open-positions/?utm_source=ssc&utm_medium=banner&utm_campaign=trading&utm_term=trading&utm_content=sierpinski"><img src="https://slatestarcodex.com/blog_images/sierpinski-low_res.png" srcset="https://slatestarcodex.com/blog_images/sierpinski-low_res.png 1x, https://slatestarcodex.com/blog_images/sierpinski_med_res.png 2x"></A></center></p>

<p><A HREF="https://www.janestreet.com/join-jane-street/open-positions/?utm_source=ssc&utm_medium=banner&utm_campaign=trading&utm_term=trading&utm_content=sierpinski">Jane Street</A> is a quantitative trading firm with a focus on technology and collaborative problem solving. We're always hiring talented programmers, traders, and researchers and have internships and fulltime positions in New York, London, and Hong Kong. No background in finance required.</p></div><div class="aar_div"><p><center><A HREF="https://80000hours.org/key-ideas/?utm_source=ssc&utm_campaign=2017-04+Sidebar+Ad&utm_medium=blog"><IMG SRC="https://slatestarcodex.com/blog_images/80k_vertise.png"></A></center></p>

<p>80,000 Hours researches different problems and professions to help you figure out how to do as much good as possible. Their <A HREF="https://80000hours.org/career-guide/?utm_source=ssc&utm_campaign=2017-04+Sidebar+Ad&utm_medium=blog">free career guide</A> show you how to choose a career that's fulfilling and maximises your contribution to solving the world's most pressing problems.</p></div><div class="aar_div"><p><center><A HREF="https://substack.com/?utm_source=ssc&utm_campaign=ssc1"><IMG SRC="https://slatestarcodex.com/blog_images/vert_substack.png"></A></center></p>

<p><A HREF="https://substack.com/?utm_source=ssc&utm_campaign=ssc1">Substack</A> is a blogging site that helps writers earn money and readers discover articles they'll like.</p></div><div class="aar_div"><p><center><A HREF="https://www.metaculus.com/questions/?show-welcome=true"><IMG SRC="https://slatestarcodex.com/blog_images/metaculus_vert.jpg"></A></center></p>

<p>Metaculus is a platform for generating crowd-sourced predictions about the future, especially science and technology. If you're interested in testing yourself and contributing to their project, check out their <A HREF="https://www.metaculus.com/questions/">questions page</A></p>
</div><div class="aar_div"><p><center><A HREF="http://seattleanxiety.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_seattle.png"></A></center></p>

<p><A HREF="https://seattleanxiety.com/">Seattle Anxiety Specialists</A> are a therapy practice helping people overcome anxiety and related mental health issues (eg GAD, OCD, PTSD) through evidence based interventions and self-exploration. Check out their free anti-anxiety guide <A HREF="https://seattleanxiety.com/#free-guide-section">here</A></p>.</div><div class="aar_div"><p><center><A HREF="http://epidemicforecasting.org/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_covid.png"></A></center></p>

<p>The <A HREF="http://epidemicforecasting.org/">COVID-19 Forecasting Project</A> at the University of Oxford is making advanced pandemic simulations of 150+ countries available to the public, and also offer pro-bono forecasting services to decision-makers.</p>
</div><div class="aar_div"><p><center><A HREF="https://altruisto.com/?ref=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/vertise_altruisto.png"></A></center></p>

<p><A HREF="https://altruisto.com/?ref=ssc">Altruisto</A> is a browser extension so that when you shop online, a portion of the money you pay goes to effective charities (no extra cost to you). Just install an extension and when you buy something, people in poverty will get medicines, bed nets, or financial aid.</p></div><div class="aar_div"><p><center><A HREF="http://LauraBaurMD.com"><IMG SRC="https://slatestarcodex.com/blog_images/vert_baur.jpg"></A></center></p>

<p>Dr. Laura Baur is a psychiatrist with interests in literature review, reproductive psychiatry, and relational psychotherapy; see <A HREF="http://LauraBaurMD.com">her website</A> for more.  Note that due to conflict of interest she doesn't treat people in the NYC rationalist social scene.</p></div><div class="aar_div"><p><center><A HREF="https://b4x.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_b4x.png"></A></center></p>

<p><A HREF="https://b4x.com/">B4X</A> is a free and open source developer tool that allows users to write apps for Android, iOS, and more.</p></div><div class="aar_div"><p><center><A HREF="https://aisafety.com/reading-group/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_aisafety.jpg"></A></center></p>

<p><A HREF="https://aisafety.com/reading-group/">AISafety.com</A> hosts a Skype reading group Wednesdays at 19:45 UTC, reading new and old articles on different aspects of AI Safety. We start with a presentation of a summary of the article, and then discuss in a friendly atmosphere.</A></p></div><div class="aar_div"><p><center><A HREF="http://effectivealtruism.org/?refer=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/eatowr.jpg"></A></center></p>

<p>The <A HREF="http://effectivealtruism.org/?refer=ssc">Effective Altruism newsletter</A> provides monthly updates on the highest-impact ways to do good and help others.</p></div><div class="aar_div"><p><center><A HREF="https://www.beeminder.com/"><IMG SRC="https://slatestarcodex.com/blog_images/beeminder_ad.png"></A></center></p>

<p>Beeminder's an evidence-based willpower augmention tool that collects quantifiable data about your life, then helps you organize it into commitment mechanisms so you can keep resolutions. They've also got a blog about what they're doing <A HREF="http://blog.beeminder.com/tag/rationality/">here</A></p></div><div class="aar_div"><p><center><A HREF="http://www.mealsquares.com/"><IMG SRC="https://slatestarcodex.com/blog_images/mealsquares_ad.png"></A></center></p>

<p><A HREF="http://www.mealsquares.com/">MealSquares</A> is a "nutritionally complete" food that contains a balanced diet worth of nutrients in a few tasty easily measurable units. Think Soylent, except zero preparation, made with natural ingredients, and looks/tastes a lot like an ordinary scone. </p></div><div class="aar_div"><center><p><a href="https://www.patreon.com/user?u=926060"><IMG SRC="https://slatestarcodex.com/blog_images/vert_patreon3.png" border="0"></A></p></center>

<p>Support Slate Star Codex on <A HREF="https://www.patreon.com/user?u=926060">Patreon</A>. I have a day job and SSC gets free hosting, so don't feel pressured to contribute. But extra cash helps pay for contest prizes, meetup expenses, and me spending extra time blogging instead of working.</p></div></div></li>	</ul>
</div><!-- #primary .widget-area -->
			</div><!-- #pjgm-main -->
			<div id="pjgm-footer">
				<div id="pjgm-ender">
					<a href="http://www.hulozila.com/" title="Hulozila" rel="designer"> </a>
				</div><!-- #pjgm-ender -->
			</div><!-- #pjgm-footer -->
		</div><!-- #pjgm-wrap -->
		<script>
    jQuery(document).ready(function () {
		jQuery.post('https://slatestarcodex.com?ga_action=googleanalytics_get_script', {action: 'googleanalytics_get_script'}, function(response) {
			var s = document.createElement("script");
			s.type = "text/javascript";
			s.innerHTML = response;
			jQuery("head").append(s);
		});
    });
</script><script type='text/javascript'>
/* <![CDATA[ */
var ReportCommentsJs = {"ajaxurl":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php","confirm":"Are you sure you want to report this comment"};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/old.reportcomments/reportcomments.js?ver=1.2'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/comment-reply.min.js'></script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/page-links-to/dist/new-tab.js?ver=3.3.3'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var pmcc_ajax = {"ajaxurl":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php","errors":{"thank_you_message":"Reported.","invalid_nonce_message":"It seems you already reported this comment.","invalid_values_message":"Cheating huh?","already_flagged_message":"It seems you already reported this comment.","already_flagged_note":"Comment has been flagged already."}};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/crowd-control/js/ajax.js?ver=20150929'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/wp-embed.min.js'></script>
<script type='text/javascript' src='https://stats.wp.com/e-202022.js' async='async' defer='defer'></script>
<script type='text/javascript'>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:8.5',blog:'46701818',post:'4773',tz:'-7',srv:'slatestarcodex.com'} ]);
	_stq.push([ 'clickTrackerInit', '46701818', '4773' ]);
</script>
		<script src="https://bakkot.github.io/SlateStarComments/ssc.js"></script>

		<script>
			jQuery(function() {

				/*  Sidebar collapse
				/* ------------------------------------ */

				jQuery('#primary .sidebar-toggle').click(function(){
					jQuery('body').toggleClass('s1-collapse').toggleClass('s1-expand');
					if (jQuery('body').is('.s2-expand')) {
						jQuery('body').toggleClass('s2-expand').toggleClass('s2-collapse');
					}
				});
				jQuery('#left-sidebar .sidebar-toggle').click(function(){
					jQuery('body').toggleClass('s2-collapse').toggleClass('s2-expand');
					if (jQuery('body').is('.s1-expand')) {
						jQuery('body').toggleClass('s1-expand').toggleClass('s1-collapse');
					}
				});
			});
		</script>
	</body>
</html>
