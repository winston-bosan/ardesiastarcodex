<!DOCTYPE html>
<html lang="en-US">
	<head>
		<meta charset="UTF-8" />
		<title>A Very Unlikely Chess Game | Slate Star Codex</title>
		<meta name=viewport content="width=device-width, min-width=572, initial-scale=1">
		<script type="text/javascript" src="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/viewport-min-width.js"></script>
		<link rel="profile" href="https://gmpg.org/xfn/11" />
		<link rel="stylesheet" type="text/css" media="all" href="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/style.css" />
		<link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Josefin+Sans' rel='stylesheet' type='text/css'>
		<link rel='stylesheet' id='font-awesome-css'  href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css' type='text/css' media='all' />

		<link rel="pingback" href="https://slatestarcodex.com/xmlrpc.php" />
		<link rel='dns-prefetch' href='//platform-api.sharethis.com' />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; Feed" href="https://slatestarcodex.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; Comments Feed" href="https://slatestarcodex.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Slate Star Codex &raquo; A Very Unlikely Chess Game Comments Feed" href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/feed/" />
<link rel='stylesheet' id='wmsimplecaptcha_style_front-css'  href='https://slatestarcodex.com/wp-content/plugins/wm-simple-captcha/assets/css/wmsimplecaptcha_style.css?ver=5.4.1' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-css'  href='https://c0.wp.com/c/5.4.1/wp-includes/css/dist/block-library/style.min.css' type='text/css' media='all' />
<style id='wp-block-library-inline-css' type='text/css'>
.has-text-align-justify{text-align:justify;}
</style>
<link rel='stylesheet' id='easy_table_style-css'  href='https://slatestarcodex.com/wp-content/plugins/easy-table/themes/default/style.css?ver=1.8' type='text/css' media='all' />
<link rel='stylesheet' id='jetpack_css-css'  href='https://c0.wp.com/p/jetpack/8.5/css/jetpack.css' type='text/css' media='all' />
<script>if (document.location.protocol != "https:") {document.location = document.URL.replace(/^http:/i, "https:");}</script><script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/jquery/jquery.js'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/jquery/jquery-migrate.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var ajax_object = {"ajax_url":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/wm-simple-captcha/assets/js/wmsimplecaptcha_scripts.js?ver=5.4.1'></script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/wp-hide-post/public/js/wp-hide-post-public.js?ver=2.0.10'></script>
<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#product=ga&#038;property=5c350a7dad0b1400119dbb2c'></script>
<link rel='https://api.w.org/' href='https://slatestarcodex.com/wp-json/' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://slatestarcodex.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://slatestarcodex.com/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='Hardball Questions For The Next Debate (2020)' href='https://slatestarcodex.com/2020/01/05/hardball-questions-for-the-next-debate-2020/' />
<link rel='next' title='Open Thread 144.75' href='https://slatestarcodex.com/2020/01/08/open-thread-144-75/' />
<link rel="canonical" href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/" />
<link rel='shortlink' href='https://slatestarcodex.com/?p=5840' />
<link rel="alternate" type="application/json+oembed" href="https://slatestarcodex.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fslatestarcodex.com%2F2020%2F01%2F06%2Fa-very-unlikely-chess-game%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://slatestarcodex.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fslatestarcodex.com%2F2020%2F01%2F06%2Fa-very-unlikely-chess-game%2F&#038;format=xml" />

<link rel='dns-prefetch' href='//c0.wp.com'/>
<style type='text/css'>img#wpstats{display:none}</style>			<style type="text/css">
				.pmcc-comments-report-link {
					font: 10px sans-serif;
					display:block;
					float:right;
					clear: left;
					margin-top: 10px;
				}
				.pmcc-comments-report-link a {
					color: #9C3E3E;
					padding: 2px 5px;
					margin: 2px 0 0 5px;
					border: 1px solid #ddd;
				}
				
				.pmcc-comments-report-link strong {
				    color: white;
				    background: #c0392b;
				    padding-top: 2px;
				    border-radius: 7px;
				    display: block;
				    width: 15px;
				    height: 15px;
				    text-align: center;
				    margin-right: 10px;
				}
			</style>
			
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article" />
<meta property="og:title" content="A Very Unlikely Chess Game" />
<meta property="og:url" content="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/" />
<meta property="og:description" content="Almost 25 years after Kasparov vs. Deep Blue, another seminal man vs. machine matchup: Neither competitor has much to be proud of here. White has a poor opening. Black screws up and loses his queen…" />
<meta property="article:published_time" content="2020-01-07T07:00:29+00:00" />
<meta property="article:modified_time" content="2020-01-07T18:03:08+00:00" />
<meta property="og:site_name" content="Slate Star Codex" />
<meta property="og:image" content="https://slatestarcodex.com/wp-content/themes/two_column_pujugama/images/codex_spotlight.png" />
<meta property="og:locale" content="en_US" />
<meta name="twitter:text:title" content="A Very Unlikely Chess Game" />
<meta name="twitter:card" content="summary" />
<meta property="og:image:width" content="200" />
<meta property="og:image:height" content="200" />
<meta name="twitter:site" content="@slatestarcodex" />

<!-- End Jetpack Open Graph Tags -->
		<style type="text/css" id="wp-custom-css">
			.hentry {
	margin-bottom: 46px
}

#pjgm-content .pjgm-posttitle {
	margin-bottom: 18px;
}
.pjgm-postcontent {
	padding-top:36px; 
}

/* 2019/07/04
   added by Andrew Swift
   mail@andrewswift.com */

@media all and
(max-device-width: 480px)
{ blockquote {
   -webkit-text-size-adjust:
    140% !important; }}		</style>
				<script src="https://polyfill.io/v2/polyfill.min.js?features=IntersectionObserver"></script>
	</head>

	<body data-rsssl=1 class="post-template-default single single-post postid-5840 single-format-standard s1-collapse s2-collapse">
		<div id="pjgm-wrap">
			<div id="pjgm-header">
				<div id="pjgm-menubar">
					<a href="https://slatestarcodex.com/" class="pjgm-home" title="Slate Star Codex" rel="home">Home</a>
					<div class="menu"><ul>
<li class="page_item page-item-2"><a href="https://slatestarcodex.com/about/">About / Top Posts</a></li>
<li class="page_item page-item-5559"><a href="https://psychiat-list.slatestarcodex.com/">Psychiat-List</a></li>
<li class="page_item page-item-2091"><a href="https://slatestarcodex.com/archives/">Archives</a></li>
<li class="page_item page-item-4475"><a href="https://www.lesswrong.com/community?filters=SSC">Meetups</a></li>
<li class="page_item page-item-3837"><a href="https://slatestarcodex.com/mistakes/">Mistakes</a></li>
<li class="page_item page-item-1745"><a href="https://slatestarcodex.com/comments/">Comments</a></li>
<li class="page_item page-item-3942"><a href="https://slatestarcodex.com/advertise/">Advertise</a></li>
<li class="page_item page-item-3989"><a href="/tag/open/?latest">Open Thread</a></li>
</ul></div>
					<a href="https://slatestarcodex.com/comments/feed/" class="pjgm-feed">Comments Feed</a>
					<a href="https://slatestarcodex.com/feed/" class="pjgm-feed">RSS Feed</a>
				</div><!-- #pjgm-menubar -->

				<div id="pjgm-bigtitle">
										<div id="pjgm-title">
						<img src="https://slatestarcodex.com/wp-content/themes/responsive-pujugama-v3/images/codex.png" alt="codex" class="codex" />
						<span>
							<a href="https://slatestarcodex.com/" title="Slate Star Codex" rel="home">Slate Star Codex</a>
						</span>
						</div>
						<div id="pjgm-description">SELF-RECOMMENDING!</div>
			</div><!-- #pjgm-bigtitle -->
		</div><!-- #pjgm-header -->

		<div id="pjgm-main">
<div id="left-sidebar" class="widget-area" role="complementary">
	<a class="sidebar-toggle" title="Expand Sidebar"><i class="fa fa-angle-double-left"></i><i class="fa fa-angle-double-right"></i></a>
	<ul class="xoxo">
				<li id="recent-posts-2" class="widget-container widget_recent_entries">		<h3 class="widget-title">Recent Posts</h3>		<ul>
											<li>
					<a href="https://slatestarcodex.com/2020/05/18/coronalinks-5-18-20-when-all-you-have-is-a-hammer-everything-starts-looking-like-a-dance/">Coronalinks 5/18/20: When All You Have Is A Hammer, Everything Starts Looking Like A Dance</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/17/open-thread-154/">Open Thread 154</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/13/open-thread-153-75/">Open Thread 153.75</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/12/studies-on-slack/">Studies On Slack</a>
									</li>
											<li>
					<a href="https://slatestarcodex.com/2020/05/10/open-thread-153-5/">Open Thread 153.5</a>
									</li>
					</ul>
		</li><li id="text-5" class="widget-container widget_text"><h3 class="widget-title">Upcoming Meetups</h3>			<div class="textwidget"><p>Cancelled due to pandemic, sorry.</p>
</div>
		</li><li id="text-3" class="widget-container widget_text"><h3 class="widget-title">Blogroll</h3>			<div class="textwidget"></div>
		</li><li id="linkcat-100" class="widget-container widget_links"><h3 class="widget-title">Embalmed Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://blog.jaibot.com/">ANOIEAEIB</a></li>
<li><a href="http://commonsenseatheism.com/">Common Sense Atheism</a></li>
<li><a href="http://lesswrong.com">Less Wrong</a></li>
<li><a href="http://thelastpsychiatrist.com/">The Last Psychiatrist</a></li>

	</ul>
</li>
<li id="linkcat-95" class="widget-container widget_links"><h3 class="widget-title">Fabulous Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://alicorn.elcenia.com/board/index.php">Alicornutopia</a></li>
<li><a href="http://unsongbook.com">Unsong</a></li>
<li><a href="https://parahumans.wordpress.com/">Worm</a></li>

	</ul>
</li>
<li id="linkcat-98" class="widget-container widget_links"><h3 class="widget-title">Innumerable Ones</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://www.gwern.net/">Gwern</a></li>
<li><a href="https://golem.ph.utexas.edu/category/">n-Category Cafe</a></li>
<li><a href="http://putanumonit.com/">Put A Number On It</a></li>
<li><a href="https://randomcriticalanalysis.wordpress.com">Random Critical Analysis</a></li>
<li><a href="http://www.scottaaronson.com/blog/">Shtetl-Optimized</a></li>
<li><a href="http://andrewgelman.com/">Statistical Modeling</a></li>
<li><a href="http://unenumerated.blogspot.com/">Unenumerated</a></li>

	</ul>
</li>
<li id="linkcat-94" class="widget-container widget_links"><h3 class="widget-title">Mermaids</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://intelligence.org/blog/">MIRI</a></li>
<li><a href="http://freethoughtblogs.com/brutereason/">Miri</a></li>
<li><a href="http://nothingismere.com/">Nothing Is Mere</a></li>
<li><a href="https://themerelyreal.wordpress.com/">The Merely Real</a></li>

	</ul>
</li>
<li id="linkcat-96" class="widget-container widget_links"><h3 class="widget-title">Stray Dogs</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://anonymousmugwump.blogspot.co.uk">Anonymous Mugwump</a></li>
<li><a href="http://followthesquirrel.blogspot.com/">Follow The Squirrel</a></li>
<li><a href="http://marginalrevolution.com/">Marginal Revolution</a></li>
<li><a href="https://nintil.com/">Nintil</a></li>
<li><a href="https://pseudoerasmus.com/">Pseudoerasmus</a></li>
<li><a href="http://www.themoneyillusion.com/">The Money Illusion</a></li>

	</ul>
</li>
<li id="linkcat-101" class="widget-container widget_links"><h3 class="widget-title">Suckling Pigs</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://fredrikdeboer.com/">Fredrik deBoer</a></li>
<li><a href="http://unqualifiedrestaurants.tumblr.com/">Unqualified Restaurant Reservations</a></li>
<li><a href="http://wholehealthsource.blogspot.com/">Whole Health Source</a></li>

	</ul>
</li>
<li id="linkcat-91" class="widget-container widget_links"><h3 class="widget-title">Those Drawn With A Very Fine Camel Hair Brush</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://existentialcomics.com/">Existential Comics</a></li>
<li><a href="http://www.smbc-comics.com/">Saturday Morning Breakfast Cereal</a></li>

	</ul>
</li>
<li id="linkcat-89" class="widget-container widget_links"><h3 class="widget-title">Those That Are Included In This Classification</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://www.reddit.com/r/slatestarcodex/">r/slatestarcodex</a></li>
<li><a href="https://discord.gg/kAVSf9U" rel="nofollow">SSC Discord Server</a></li>
<li><a href="http://sscpodcast.libsyn.com/rss">SSC Podcast</a></li>

	</ul>
</li>
<li id="linkcat-93" class="widget-container widget_links"><h3 class="widget-title">Those That Are Trained</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://80000hours.org/blog/">80000 Hours Blog</a></li>
<li><a href="http://aiimpacts.org/">AI Impacts</a></li>
<li><a href="http://www.effective-altruism.com/">Effective Altruism Forum</a></li>
<li><a href="http://blog.givewell.org/">GiveWell Blog</a></li>
<li><a href="http://www.jefftk.com/index">Jeff Kaufman</a></li>
<li><a href="http://lukemuehlhauser.com/">Luke Muehlhauser</a></li>
<li><a href="http://theunitofcaring.tumblr.com/">The Unit of Caring</a></li>
<li><a href="https://thewholesky.wordpress.com/">The Whole Sky</a></li>

	</ul>
</li>
<li id="linkcat-102" class="widget-container widget_links"><h3 class="widget-title">Those That At A Distance Resemble Flies</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://agentyduck.blogspot.com/">Agenty Duck</a></li>
<li><a href="https://www.beeminder.com/">Beeminder</a></li>
<li><a href="http://mindingourway.com/">Nate Soares</a></li>

	</ul>
</li>
<li id="linkcat-99" class="widget-container widget_links"><h3 class="widget-title">Those That Belong To The Emperor</h3>
	<ul class='xoxo blogroll'>
<li><a href="https://samzdat.com">Sam[]zdat</a></li>
<li><a href="http://www.xenosystems.net/">Xenosystems</a></li>

	</ul>
</li>
<li id="linkcat-97" class="widget-container widget_links"><h3 class="widget-title">Those That Have Just Broken The Flower Vase</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://esr.ibiblio.org/">Armed and Dangerous</a></li>
<li><a href="https://www.econlib.org/author/bcaplan/">Bryan Caplan</a></li>
<li><a href="http://daviddfriedman.blogspot.com/">David Friedman</a></li>
<li><a href="https://thezvi.wordpress.com/">Don&#039;t Worry About The Vase</a></li>
<li><a href="http://www.overcomingbias.com/">Overcoming Bias</a></li>
<li><a href="http://www.popehat.com/">Popehat</a></li>
<li><a href="http://sci-hub.tw/">Sci-Hub</a></li>

	</ul>
</li>
<li id="linkcat-90" class="widget-container widget_links"><h3 class="widget-title">Those That Tremble As Though They Are Mad</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://1boringoldman.com/">1 Boring Old Man</a></li>
<li><a href="http://acesounderglass.com/">Aceso Under Glass</a></li>
<li><a href="http://cognitionandevolution.blogspot.com/">Cognition and Evolution</a></li>
<li><a href="https://crazymeds.net/pmwiki/pmwiki.php">Crazy Meds</a></li>
<li><a href="https://www.erikandersontherapy.com/blog/">Erik Anderson Therapy</a></li>
<li><a href="http://gruntledandhinged.wordpress.com/">Gruntled and Hinged</a></li>
<li><a href="http://real-psychiatry.blogspot.com/">Real Psychiatry</a></li>
<li><a href="http://psychiatrist-blog.blogspot.com/">Shrink Rap</a></li>

	</ul>
</li>
<li id="linkcat-92" class="widget-container widget_links"><h3 class="widget-title">Various Others</h3>
	<ul class='xoxo blogroll'>
<li><a href="http://zackmdavis.net/blog/">An Algorithmic Lucidity</a></li>
<li><a href="https://medium.com/@sumdepony">De Pony Sun</a></li>
<li><a href="https://www.gnxp.com/">Gene Expression</a></li>
<li><a href="http://infoproc.blogspot.com/">Information Processing</a></li>
<li><a href="http://www.meltingasphalt.com/">Melting Asphalt</a></li>
<li><a href="https://meteuphoric.wordpress.com/">Meteuphoric</a></li>
<li><a href="https://srconstantin.wordpress.com/">Otium</a></li>
<li><a href="http://www.ribbonfarm.com/">Ribbonfarm</a></li>
<li><a href="http://rationalconspiracy.com/">The Rationalist Conspiracy</a></li>
<li><a href="https://sideways-view.com/">The Sideways View</a></li>
<li><a href="http://thingofthings.wordpress.com/">Thing of Things</a></li>
<li><a href="https://westhunt.wordpress.com/">West Hunter</a></li>

	</ul>
</li>
<li id="archives-2" class="widget-container widget_archive"><h3 class="widget-title">Archives</h3>		<ul>
				<li><a href='https://slatestarcodex.com/2020/05/'>May 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/04/'>April 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/03/'>March 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/02/'>February 2020</a></li>
	<li><a href='https://slatestarcodex.com/2020/01/'>January 2020</a></li>
	<li><a href='https://slatestarcodex.com/2019/12/'>December 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/11/'>November 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/10/'>October 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/09/'>September 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/08/'>August 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/07/'>July 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/06/'>June 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/05/'>May 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/04/'>April 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/03/'>March 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/02/'>February 2019</a></li>
	<li><a href='https://slatestarcodex.com/2019/01/'>January 2019</a></li>
	<li><a href='https://slatestarcodex.com/2018/12/'>December 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/11/'>November 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/10/'>October 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/09/'>September 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/08/'>August 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/07/'>July 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/06/'>June 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/05/'>May 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/04/'>April 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/03/'>March 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/02/'>February 2018</a></li>
	<li><a href='https://slatestarcodex.com/2018/01/'>January 2018</a></li>
	<li><a href='https://slatestarcodex.com/2017/12/'>December 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/11/'>November 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/10/'>October 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/09/'>September 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/08/'>August 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/07/'>July 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/06/'>June 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/05/'>May 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/04/'>April 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/03/'>March 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/02/'>February 2017</a></li>
	<li><a href='https://slatestarcodex.com/2017/01/'>January 2017</a></li>
	<li><a href='https://slatestarcodex.com/2016/12/'>December 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/11/'>November 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/10/'>October 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/09/'>September 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/08/'>August 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/07/'>July 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/06/'>June 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/05/'>May 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/04/'>April 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/03/'>March 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/02/'>February 2016</a></li>
	<li><a href='https://slatestarcodex.com/2016/01/'>January 2016</a></li>
	<li><a href='https://slatestarcodex.com/2015/12/'>December 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/11/'>November 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/10/'>October 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/09/'>September 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/08/'>August 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/07/'>July 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/06/'>June 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/05/'>May 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/04/'>April 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/03/'>March 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/02/'>February 2015</a></li>
	<li><a href='https://slatestarcodex.com/2015/01/'>January 2015</a></li>
	<li><a href='https://slatestarcodex.com/2014/12/'>December 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/11/'>November 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/10/'>October 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/09/'>September 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/08/'>August 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/07/'>July 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/06/'>June 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/05/'>May 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/04/'>April 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/03/'>March 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/02/'>February 2014</a></li>
	<li><a href='https://slatestarcodex.com/2014/01/'>January 2014</a></li>
	<li><a href='https://slatestarcodex.com/2013/12/'>December 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/11/'>November 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/10/'>October 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/09/'>September 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/08/'>August 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/07/'>July 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/06/'>June 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/05/'>May 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/04/'>April 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/03/'>March 2013</a></li>
	<li><a href='https://slatestarcodex.com/2013/02/'>February 2013</a></li>
		</ul>
			</li><li id="nav_menu-3" class="widget-container widget_nav_menu"><div class="menu-full-archives-link-for-widget-area-container"><ul id="menu-full-archives-link-for-widget-area" class="menu"><li id="menu-item-2103" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2103"><a href="https://slatestarcodex.com/archives/">Full Archives</a></li>
</ul></div></li>	</ul>
</div>

		<div id="pjgm-box">
			<div id="pjgm-content">


				<div id="post-5840" class="post-5840 post type-post status-publish format-standard hentry category-uncategorized tag-ai">
					<h1 class="pjgm-posttitle">A Very Unlikely Chess Game</h1>

					<div class="pjgm-postmeta">
						<span class="meta-prep meta-prep-author">Posted on</span> <a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/" title="11:00 pm" rel="bookmark"><span class="entry-date">January 6, 2020</span></a> <span class="meta-sep">by</span> <span class="author vcard"><a class="url fn n" href="https://slatestarcodex.com/author/admin/" title="View all posts by Scott Alexander">Scott Alexander</a></span>					</div><!-- .pjgm-postmeta -->

					<div class="pjgm-postcontent">
						<p>Almost 25 years after Kasparov vs. Deep Blue, another seminal man vs. machine matchup:</p>
<p><center><IMG SRC="https://slatestarcodex.com/blog_images/chessgame2.gif"></center></p>
<p>Neither competitor has much to be proud of here. White has a poor opening. Black screws up and loses his queen for no reason. A few moves later, white screws up and loses his rook for no reason. Better players will no doubt spot other humiliating mistakes. But white does eventually eke out a victory. And black does hold his own through most of the game.</p>
<p>White is me. My excuse is that I only play chess once every couple of years, plus I&#8217;m entering moves on an ASCII board I can barely read.</p>
<p>Black is GPT-2. Its excuse is that it&#8217;s a text prediction program with no concept of chess. As far as it knows, it&#8217;s trying to predict short alphanumeric strings like &#8220;e2e4&#8221; or &#8220;Nb7&#8221;. Nobody told it this represents a board game. It doesn&#8217;t even have a concept of 2D space that it could use to understand such a claim. But it still captured my rook! Embarrassing!</p>
<p>Backing up: last year, I wrote <A HREF="https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/">GPT-2 As Step Toward General Intelligence</A>, where I argued that the program wasn&#8217;t just an essay generator, it was also kind a general pattern-recognition program with text-based input and output channels. Figure out how to reduce a problem to text, and you can make it do all kinds of unexpected things.</p>
<p>Friend-of-the-blog Gwern Branwen has been testing the limits of this idea. First he taught GPT-2 <A HREF="https://slatestarcodex.com/2019/03/14/gwerns-ai-generated-poetry/">to write poetry</A>. Some of it was pretty good:</p>
<blockquote><p>Fair is the Lake, and bright the wood,<br />
With many a flower-full glamour hung:<br />
Fair are the banks; and soft the flood<br />
With golden laughter of our tongue.</p></blockquote>
<p>For his next trick, he found a corpus of music in &#8220;ABC notation&#8221;, a way of representing musical scores as text. He fed it to GPT-2 and got it to <A HREF="https://www.gwern.net/GPT-2-music">write folk songs</A> for him. I&#8217;m a fan:</p>
<p><center><audio controls loop preload="metadata" src="https://www.gwern.net/docs/ai/music/2019-12-04-gpt2-combinedabc-invereshieshouse.mp3"></audio></p>
<p><audio controls loop preload="metadata" src="https://www.gwern.net/docs/ai/music/2019-11-14-gwern-gpt2-127512.mp3"></audio></center></p>
<p>Last month, I asked him if he thought GPT-2 could play chess. I wondered if he could train it on a corpus of chess games written in standard notation (where, for example, e2e4 means &#8220;move the pawn at square e2 to square e4&#8221;). There are literally millions of games written up like this. GPT-2 would learn to predict the next string of text, which would correspond to the next move in the chess game. Then you would prompt it with a chessboard up to a certain point, and it would predict how the chess masters who had produced its training data would continue the game &#8211; ie make its next move using the same heuristics they would.</p>
<p>Gwern handed the idea to his collaborator <A HREF="https://twitter.com/theshawwn?lang=en">Shawn Presser</A>, who had a working GPT-2 chess engine running <i>within a week</i>:</p>
<p><center></p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">GPT-2 chess is promising. After an hour of training, 1.5B is pretty good at opening theory.</p>
<p>Longer sequences tend to fail due to invalid moves, but this shows it&#39;s possible in principle to make a GPT-2 chess engine.</p>
<p>And maybe after more training it&#39;ll make fewer invalid moves. <a href="https://t.co/DqC4WiPfHV">pic.twitter.com/DqC4WiPfHV</a></p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1212272510470959105?ref_src=twsrc%5Etfw">January 1, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<blockquote class="twitter-tweet" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">I&#39;ll post some games, up to the point it generates an invalid move (which seems to happen around move 11).</p>
<p>Paste this into <a href="https://t.co/wWGpVu9ko6">https://t.co/wWGpVu9ko6</a></p>
<p>1.e4 c5 2.Nf3 e6 3.d4 cxd4 4.Nxd4 a6 5.Bd3 Nf6 6.Nc3 d6 7.O-O Be7 8.f4 O-O 9.Kh1 Nbd7 <a href="https://t.co/8Bl2ijZiCZ">pic.twitter.com/8Bl2ijZiCZ</a></p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1212277698598453249?ref_src=twsrc%5Etfw">January 1, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<blockquote class="twitter-tweet" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">After a day of training (2.4M examples), GPT-2 1.5B can reach move 14 with no invalid moves.</p>
<p>1.e4 e5 2.Nf3 d6 3.d4 exd4 4.Qxd4 a6 5.Be2 Nf6 6.O-O Be7 7.Re1 O-O 8.c3 b5 9.a4 Bb7 10.axb5 axb5 11.Nbd2 Re8 12.h3 g6 13.Ra5 Qd7 14.Ng5 c5 <a href="https://t.co/2XuH6iLaD5">pic.twitter.com/2XuH6iLaD5</a></p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1212619327347871744?ref_src=twsrc%5Etfw">January 2, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<blockquote class="twitter-tweet" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">It can reach midgame by removing invalid moves.</p>
<p>1.e4 c5 2.Nf3 d6 3.Bb5+ Nd7 4.O-O a6 5.Be2 b6 6.a4 e6 7.d4 Be7 8.c3 9.Nbd2 Ne5 10.Nxe5 dxe5 11.12.13.f4 Bb7 14.Bd3 g6 15.Nf3 16.17.Re1 18.Qe2 Bf8 19.Bd2 20.Qf2 Qxd4 21.22.23.Rf1 Qxc3 24.Qxc5 Bd6 25.Qc7 26.Qd8+ 27.Qd6 Rd8 <a href="https://t.co/3uyPaP9LHt">pic.twitter.com/3uyPaP9LHt</a></p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1212619328891314177?ref_src=twsrc%5Etfw">January 2, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<blockquote class="twitter-tweet" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">GPT2 Chess update: I wrote some code to calculate the probability of all valid chess moves. It can reach endgame now. <a href="https://t.co/QQzhZJmgQ9">https://t.co/QQzhZJmgQ9</a></p>
<p>It starts to blunder every game at around move 13. We suspect it’s losing track of board state. (It’s trained solely on PGN notation.)</p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1213559429293060099?ref_src=twsrc%5Etfw">January 4, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">I am preparing to release a notebook where you can play chess vs GPT-2. If anyone wants to help beta test it:</p>
<p>1. visit <a href="https://t.co/CpWrFvtnY2">https://t.co/CpWrFvtnY2</a><br />2. open in playground mode<br />3. click Runtime -&gt; Run All<br />4. Scroll to the bottommost cell and wait 6 minutes</p>
<p>If you get stuck, tell me.</p>
<p>&mdash; Shawn Presser (@theshawwn) <a href="https://twitter.com/theshawwn/status/1214013710173425665?ref_src=twsrc%5Etfw">January 6, 2020</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></center></p>
<p>You can play against GPT-2 yourself by following the directions in the last tweet, though it won&#8217;t be much of a challenge for anyone better than I am.</p>
<p>This training explains the program&#8217;s strengths (good at openings) and weaknesses (bad when play deviates from its expectations). For example, ggreer <A HREF="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838464">analyzes why</A> GPT-2 lost its queen in the game above. By coincidence, my amateurish flailing <A HREF="https://lichess.org/sTuSsGYB">resembled</A> a standard opening called the Indian Game. GPT-2 noticed the pattern and played a standard response to it. But the resemblance wasn&#8217;t perfect, so one of GPT-2&#8217;s moves which would have worked well in a real Indian Game brought its queen where I could easily capture it. I don&#8217;t want to conjecture on how far &#8220;mere pattern-matching&#8221; can take you &#8211; but you will at least need to be a better pattern-matcher than this to get very far.</p>
<p>But this is just what a friend of a friend managed to accomplish in a few days of work. Gwern stresses that there are easy ways to make it much better:</p>
<blockquote><p>Obviously, training on just moves with the implicit game state having to be built up from scratch from the history every time is very difficult &#8211; even <A HREF="https://arxiv.org/abs/1911.08265">MuZero</A> at least gets to see the entire game state at every move when it&#8217;s trying to predict legal &#038; good next moves, and depends heavily on having a recurrent state summarizing the game state. Maybe rewriting games to provide (state,action) pairs will make GPT-2 work much better.</p></blockquote>
<p>What does this imply? I&#8217;m not sure (and maybe it will imply more if someone manages to make it actually good). It was already weird to see something with no auditory qualia learn passable poetic meter. It&#8217;s even weirder to see something with no concept of space learn to play chess. Is any of this <A HREF="https://slatestarcodex.com/2019/02/28/meaningful/">meaningful</A>? How impressed should we be that the same AI can write poems, compose music, and play chess, without having been designed for any of those tasks? I still don&#8217;t know.</p>
											</div><!-- .pjgm-postcontent -->


					<div class="pjgm-postutility">
						This entry was posted in <a href="https://slatestarcodex.com/category/uncategorized/" rel="category tag">Uncategorized</a> and tagged <a href="https://slatestarcodex.com/tag/ai/" rel="tag">ai</a>. Bookmark the <a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/" title="Permalink to A Very Unlikely Chess Game" rel="bookmark">permalink</a>.											</div><!-- .pjgm-postutility -->
				</div><!-- #post-## -->

				<div id="pjgm-navbelow" class="pjgm-navigation">
					<div class="pjgm-navpre"><a href="https://slatestarcodex.com/2020/01/05/hardball-questions-for-the-next-debate-2020/" rel="prev"><span class="pjgm-metanav">&larr;</span> Hardball Questions For The Next Debate (2020)</a></div>
					<div class="pjgm-navnex"><a href="https://slatestarcodex.com/2020/01/08/open-thread-144-75/" rel="next">Open Thread 144.75 <span class="pjgm-metanav">&rarr;</span></a></div>
				</div><!-- #pjgm-navbelow -->

				




	<div id="comments">
			<h3 id="comments-title">182 Responses to <em>A Very Unlikely Chess Game</em></h3>

			<div id="comment-order-reverse-button"><a href="?reverseComments=#comments">Reverse order</a></div>


			<ol class="commentlist">
					<li class="comment byuser comment-author-canyon-fern even thread-even depth-1" id="li-comment-838451">
		<div id="comment-838451" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a7b0b2f1a177ac18cc4f07b5fa05c696?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a7b0b2f1a177ac18cc4f07b5fa05c696?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://contact.canyon.fern@gmail.com' rel='external nofollow ugc' class='url'>Canyon Fern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838451">
			January 6, 2020 at 11:21 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wowzer schnauzer. I&#8217;m not particularly into chess, but thank you <i>very</i> much, Scott, for pointing me to Gwern&#8217;s work on GPT-2 poetry generation.</p>
<p>I&#8217;ve been involved in poetry and interactive-fiction for a while now. Seeing active, compelling exploration in AI-based* generation of both those media &#8212; even when it gets incoherent / can&#8217;t maintain state across long distances &#8212; is as stimulating as a hefty splurt of the Cuban-cigar-ash fertilizer Ludovico bought me for Christmas.</p>
<p>* Deliberately non-specific term: I&#8217;m a layplant on &#8220;deep learning&#8221; and such.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gurkenglas odd alt depth-2" id="li-comment-838557">
		<div id="comment-838557" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d2720df344c27d3b2f62d356c2058eeb?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d2720df344c27d3b2f62d356c2058eeb?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Gurkenglas</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838557">
			January 7, 2020 at 7:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Interactive fiction, huh? Try AI Dungeon. There&#8217;s an app.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-eri even depth-3" id="li-comment-838593">
		<div id="comment-838593" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6f2793699eaf267636149ef1b743c5f2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6f2793699eaf267636149ef1b743c5f2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Eri</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838593">
			January 7, 2020 at 8:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I tried it out. It is interesting, but it cannot keep a coherent dialogue for more than several lines. And it sometimes tries to control my character, which goes against the usual rules of GM-driven text adventures.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-moridinamael odd alt depth-4" id="li-comment-838634">
		<div id="comment-838634" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/25830ca7ef21909bfd189e5adbb19792?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/25830ca7ef21909bfd189e5adbb19792?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">moridinamael</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838634">
			January 7, 2020 at 9:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I vastly prefer that it remain &#8220;broken&#8221; in this way, so I can force it to do weird and interesting things it&#8217;s not supposed to do. If it was just a MUD simulator, that would get boring in about an hour.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-mtsowbug even depth-5" id="li-comment-838690">
		<div id="comment-838690" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/14f485ad841a3f32e7bc6caf7c5caf1b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/14f485ad841a3f32e7bc6caf7c5caf1b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MTSowbug</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838690">
			January 7, 2020 at 11:00 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But what if instead of being a MUD simulator, GPT-2 was used as a MUD content generator?</p>
<p>A couple months ago, I used Gwern&#8217;s poetry notes as a guideline to fine-tune GPT-2-124M on a corpus of MUD room descriptions, generating a few thousand novel machine-written rooms. With my collaborator Benamas, we filtered and arranged this content into a 100-room MUD area, with all of the actual writing done by GPT-2. We have a small reddit thread on the project <a rel="nofollow"href="https://www.reddit.com/r/MUD/comments/dq9x94/the_cleft_of_dimensionss_namubumo_submission_the/" rel="nofollow ugc">here</a>.</p>
<p>The next stage, which is mostly complete, is to combine GPT-2&#8217;s writing (scaling up to GPT-2-355M) with other code that filters and arranges the output without our intervention. In this manner, we want to use GPT-2 to autonomously write arbitrary amounts of high-quality MUD content.</p>
<p>Procedural generation is nothing new for games, but something feels special about procedural authorship.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ggreer odd alt thread-odd thread-alt depth-1" id="li-comment-838452">
		<div id="comment-838452" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ggreer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838452">
			January 6, 2020 at 11:21 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Shawn was nice enough to play me on Lichess using GPT-2. I checkmated it in 29 moves: <a rel="nofollow"href="https://lichess.org/BKyeH9ts#57" rel="nofollow ugc">https://lichess.org/BKyeH9ts#57</a></p>
<p>I probably could have ended it sooner, but I played as if I was up against a human opponent. I was not about to try any tricks. I just played nice solid chess and tried not to blunder.</p>
<p>In the next match(<a rel="nofollow"href="https://lichess.org/IHIcBPs4/black#22" rel="nofollow ugc">https://lichess.org/IHIcBPs4/black#22</a>) I played black. I was worse (but not losing), then Shawn&#8217;s TPU instance was pre-empted. By then it was 1:30AM and I wanted to sleep. I offered a draw and he accepted.</p>
<p>I really want to try the bongcloud opening against it (<a rel="nofollow"href="https://www.chess.com/forum/view/chess-openings/bongcloud-opening" rel="nofollow ugc">https://www.chess.com/forum/view/chess-openings/bongcloud-opening</a>). I think if you got it out of the common openings, it would quickly be obliterated.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-admin bypostauthor even depth-2" id="li-comment-838453">
		<div id="comment-838453" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838453">
			January 6, 2020 at 11:24 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Gwern suggested I did better than I expected against it because I&#8217;m so bad that I accidentally made moves outside what it was trained for.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ggreer odd alt depth-3" id="li-comment-838455">
		<div id="comment-838455" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ggreer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838455">
			January 6, 2020 at 11:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That makes sense to me. I think GPT-2 stays competitive by memorizing common (AKA strong) lines.</p>
<p>Do you have the PGN for your game? That would make it easy to import and analyze with an engine. A gif is great for humans, but it&#8217;s not easily turned back into something machine readable.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-admin bypostauthor even depth-4" id="li-comment-838456">
		<div id="comment-838456" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838456">
			January 6, 2020 at 11:58 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>1. d4 Nf6 2. e3 g6 3. Nc3 Bg7 4. f4 d6 5. Nf3 O-O 6. a4 c5 7. dxc5 Qa5 8. Bd3<br />
Qxc5 9. Nd4 Nc6 10. Nxc6 bxc6 11. O-O Bg4 12. Qe1 Nd7 13. Ne4 Qa5 14. Qxa5 c5<br />
15. f5 gxf5 16. Rxf5 Bxf5 17. g4 Be6 18. g5 Ne5 19. Bb5 Rab8 20. Qxa7 Rxb5 21.<br />
axb5 c4 22. Qxe7 Rb8 23. Nxd6 Rxb5 24. Ra8+ Rb8 25. Rxb8+ Bf8 26. Qxf8# 1-0</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-ggreer odd alt depth-5" id="li-comment-838464">
		<div id="comment-838464" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b852702ad437e47be3f1df3922ac7e3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ggreer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838464">
			January 7, 2020 at 1:14 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thanks. Here&#8217;s the game in Lichess with an engine analysis: <a rel="nofollow"href="https://lichess.org/sTuSsGYB" rel="nofollow ugc">https://lichess.org/sTuSsGYB</a></p>
<p>Both sides made mistakes early on, but the game was close until black (GPT-2) blundered a queen. Qa5 is frequently check on the white king, but earlier in the game you moved your queen to e1. Oops. Sorry GPT-2, pattern matching can&#8217;t always substitute for knowledge. That said, it&#8217;s often surprisingly effective.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-admin bypostauthor even depth-5" id="li-comment-838465">
		<div id="comment-838465" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838465">
			January 7, 2020 at 1:21 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Oh, interesting, that helps things make more sense.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mablun odd alt depth-5" id="li-comment-838540">
		<div id="comment-838540" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/55afd0c01884f776128eae8306b9ea95?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/55afd0c01884f776128eae8306b9ea95?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Mablun</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838540">
			January 7, 2020 at 6:50 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The reason why move 3. Nc3 is a mistake is that pawns are the &#8220;soul of chess.&#8221; The pawn structure will dictate where pieces should be placed and what your strategic goals are in the middle game.</p>
<p>2. e3 is a bit passive but probably ok outside of the highest levels (e.g., you probably wouldn&#8217;t ever see it in a world championship match but masters could still play it to try and get opponent in a side line they won&#8217;t be as familiar with). But once you&#8217;ve played 2.e3, the pawn structure is just screaming &#8220;push your c-pawn.&#8221; The e and d pawns are forming a line pointing towards the queen side and so, strategically, you want to grab more space and play on that side of the board. In basically every line you&#8217;re going to want your c-pawn pushed to c4 (or maybe c3 in a few edge situations). </p>
<p>Putting your knight on c3 delays your own strategic plan because now you&#8217;ve blocked the c-pawn with your own knight. Probably, you&#8217;re going to want to do to the c-file what you did with the f-file. Push the pawn to c4 first then put the knight behind it.</p>
<p>With the knight on c3 and if black played well, before too long you&#8217;re going to have finished developing your pieces and then not know what to do or what your plan should be. A lot of good amateurs get to the point where they&#8217;re not really blundering pieces anymore, and they know to develop their pieces and control the center, but will get lost and not know what to do after that and it makes chess less fun. Learning about pawn structures is what gets you up to the next level as after that you&#8217;ll rarely be stuck not knowing what your strategic plan should be in any given opening.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gurkenglas even depth-4" id="li-comment-838560">
		<div id="comment-838560" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d2720df344c27d3b2f62d356c2058eeb?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d2720df344c27d3b2f62d356c2058eeb?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Gurkenglas</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838560">
			January 7, 2020 at 7:37 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s not even trying to be competitive, it&#8217;s just guessing how the game will continue. If you blunder, it might guess that this must be a game between two blundering fools, and play accordingly.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-aerocontrols odd alt depth-5" id="li-comment-838569">
		<div id="comment-838569" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2778c64be86c0bd3d94f85bd41f100df?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2778c64be86c0bd3d94f85bd41f100df?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Matt</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838569">
			January 7, 2020 at 7:50 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I wonder if it would do better if you told it to, as white, only learn from &#8216;white wins&#8217; games, and vice-versa.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zeromh even depth-5" id="li-comment-838574">
		<div id="comment-838574" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838574">
			January 7, 2020 at 8:02 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That&#8217;s a great point! Thanks for pointing that out, because I had been thinking of this more as &#8220;it&#8217;s trying to win,&#8221; and that&#8217;s not the right way to think about it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-doctor-mist odd alt depth-5" id="li-comment-838983">
		<div id="comment-838983" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838983">
			January 8, 2020 at 10:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>It’s not even trying to be competitive, it’s just guessing how the game will continue.</p></blockquote>
<p>An interesting point but I&#8217;m not sure of its relevance.  How would you tell the two apart?  I assume the corpus of games it is trained on are games where both sides were trying to win.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-thisheavenlyconjugation even depth-5" id="li-comment-839162">
		<div id="comment-839162" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839162">
			January 8, 2020 at 1:36 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I assume the corpus of games it is trained on are games where both sides were trying to win.</p></blockquote>
<p>Doubtful, probably many of them involved people playing to draw.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zeromh odd alt depth-5" id="li-comment-839989">
		<div id="comment-839989" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839989">
			January 10, 2020 at 10:05 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Doctor Mist: The difference is that an algorithm that is trying to win (and that has some means to improve), will improve and get better at winning (e.g. AlphaZero).</p>
<p>GPT-2 will always play like the player data it was trained on. It will not get better at winning.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bensheffield even depth-3" id="li-comment-838458">
		<div id="comment-838458" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9f7fba24615327127fcf0a5323710dab?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9f7fba24615327127fcf0a5323710dab?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">MawBTS</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838458">
			January 7, 2020 at 12:07 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>In FPS games like Apex Legends shitty players are sometimes scarier than good players because they try weird stuff you&#8217;re not expecting.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-toastengineer odd alt depth-4" id="li-comment-838494">
		<div id="comment-838494" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838494">
			January 7, 2020 at 4:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s kinda funny, I was thinking last night about how negamax, which as far as I know is still basically the algorithm the best chess engines use*, can&#8217;t think to offer you a mistake and hope you&#8217;ll take it. It always assumes you&#8217;ll make the move it would have and doesn&#8217;t even take what will happen if you take a different move in to account.</p>
<p>Basically,<br />
1. Create a tree, where the nodes (circles) are boards and the edges (lines) are moves. The root is the current board, and edges come out of it representing every valid move, connecting it to the board that would be produced if whoever&#8217;s turn it was took that move. Same goes for every node in the graph; each one is connected by the possible moves to the result of each possible move.</p>
<p>2. For each board in the tree, bottom to top***, assign the board a goodness-for-me value: </p>
<p>2a. If the node is a leaf, a node with no outgoing connections, which in this case would be a board where the game is won**, assign it a goodness-for-me value by applying your evaluation function, i.e. -1 if opponent won, 1 if I won.</p>
<p>2b.  Otherwise, it&#8217;s goodness value is either the maximum or minimum of the values of the nodes it connects to:</p>
<p>2ba. If it&#8217;s my turn in the board we&#8217;re considering, a board&#8217;s goodness value is the largest goodness value of the boards immediately below it &#8211; the move leading to the most good successor board is the move I will take if the game ends up going to that particular board configuration.</p>
<p>2bb. If it&#8217;s my OPPONENT&#8217;s turn in the board we&#8217;re considering, a board&#8217;s goodness value is the SMALLEST goodness value of the boards after it, because I assume my opponent will always take the move that is WORST for me (and therefore best for him, since this is a zero-sum game.) <b>Other possibilities than the worst don&#8217;t enter the calculation at all.</b></p>
<p>3. When actually playing the game, consult this tree and always take the edge (move) leading to the highest goodness-for-me node (board.)</p>
<p>* With a <b>TON</b> of little tricks and optimizations on top of it so you never explore board states that don&#8217;t contain useful information &#8211; the &#8220;evaluation function&#8221; hides all the complexity, negamax is really just a way to translate all the work of determining which boards are advantageous in to actual wins.</p>
<p>** I lied. In Tic-Tac-Toe, maybe, but in chess you can&#8217;t create the whole tree, the leaf nodes would just be where you ran out of time and stopped.</p>
<p>*** The leaves are at the bottom of the tree, and the root at the top, just like with real trees.</p>
<p>However, I suspect you could add &#8220;maybe my opponent is dumb&#8221; functionality by modifying step 2bb to add (sum of non-worst successor values) * 0.01 to the evaluation value, so if it&#8217;s looking at two basically equivalent possibilities, it will take the one that gives the best result if the opponent plays non-optimally. Will have to try that out tonight.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-fishbreath even depth-5" id="li-comment-838536">
		<div id="comment-838536" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5b66cd2c6f3140a243372df7694ca563?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5b66cd2c6f3140a243372df7694ca563?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Fishbreath</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838536">
			January 7, 2020 at 6:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>As someone who follows board game AI relatively closely (I maintain the only extant engine for the hnefatafl family of games: <a rel="nofollow"href="https://git.io/Jvekf" rel="nofollow ugc">https://git.io/Jvekf</a>), I can share that tree search is no longer the top of the pile for chess engines—DeepMind&#8217;s AlphaZero conclusively defeated Stockfish 9 toward the middle of last year.</p>
<p>I think your point still holds for this new breed of AI, too, though—the nature of the question &#8220;what is a generally-optimal way to play?&#8221; doesn&#8217;t admit much room for playing to specific oppponents&#8217; flaws.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-thisheavenlyconjugation odd alt depth-5" id="li-comment-838602">
		<div id="comment-838602" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838602">
			January 7, 2020 at 8:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Fishbreath<br />
AlphaZero still searches trees, no?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-smilerz even depth-5" id="li-comment-838624">
		<div id="comment-838624" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">smilerz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838624">
			January 7, 2020 at 9:21 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>AlphaZero relies on <a rel="nofollow"href="https://medium.com/@umerhasan17/a-summary-of-the-general-reinforcement-learning-game-playing-algorithm-alphazero-755f1de1ce38" rel="nofollow ugc">Monte Carlo tree search</a>:</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-fishbreath odd alt depth-5" id="li-comment-838652">
		<div id="comment-838652" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5b66cd2c6f3140a243372df7694ca563?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5b66cd2c6f3140a243372df7694ca563?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Fishbreath</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838652">
			January 7, 2020 at 10:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That&#8217;s correct—I suppose I should have said that minimax-descended tree searches no longer rule the roost.</p>
<p>e: I seem to recall, in one of the original AlphaGo papers, a note that it played quite well without using the tree search at all, picking moves based solely on the move ordering neural network.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-akhorahil even depth-4" id="li-comment-838499">
		<div id="comment-838499" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Akhorahil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838499">
			January 7, 2020 at 5:05 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It was said by actual expert duelists that it was safer to duel someone with a little training than someone completely without. The one with a little training is predictable &#8211; the one with none might do anything!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-darktigger odd alt depth-4" id="li-comment-838886">
		<div id="comment-838886" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c449b5485b06afd9103a2cf8cd1bb76f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c449b5485b06afd9103a2cf8cd1bb76f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">DarkTigger</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838886">
			January 8, 2020 at 5:49 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>From &#8220;Murphy Laws of Warfare&#8221;:<br />
&#8220;Professional soldiers are predictable; the world is full of dangerous amateurs.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-closed-to-third-cause even depth-4" id="li-comment-838964">
		<div id="comment-838964" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/98040bee9094d5997e0c34bc4c216e17?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/98040bee9094d5997e0c34bc4c216e17?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">closed to third cause</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838964">
			January 8, 2020 at 9:26 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is also true in BJJ. White belts often make completely wrong moves that aren&#8217;t supposed to work. Except sometimes they do work. When you have trained yourself for a set of expected reactions, an unexpected reaction catches you by surprise and stalls your brain for a few milliseconds. Sometimes that is enough. Then it&#8217;s really hard to explain to someone that what they did was wrong.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ketil odd alt depth-3" id="li-comment-838462">
		<div id="comment-838462" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5379fcafbd2181f5e3fefe398a29d5f0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Ketil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838462">
			January 7, 2020 at 12:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think this is a general weakness of deep learning systems &#8211; they depend heavily on data being from the expected distribution it was trained for.  I recently saw the AlphaGo movie, and while there is much antrophomorphizing about how the system &#8220;lost it&#8221; after an unexpected move by Lee Sedol, my interpretation is that the game state simply entered into territory which AlphaGo hadn&#8217;t explored much.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-lambert even depth-4" id="li-comment-838483">
		<div id="comment-838483" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Lambert</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838483">
			January 7, 2020 at 3:54 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Dystopian future in which only massive weirdoes are able to overthrow our machine overlords, anyone?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-holomanga odd alt depth-5" id="li-comment-838525">
		<div id="comment-838525" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/84a89f1e4e71aac0b53bd1e1f900a861?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/84a89f1e4e71aac0b53bd1e1f900a861?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">holomanga</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838525">
			January 7, 2020 at 6:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Makes for an interesting twist on the &#8220;robots are coldly rational, they can&#8217;t understand the power of human emotion&#8221; trope &#8211; a story where dealing with human emotion takes them off the training distribution!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-lambert even depth-5" id="li-comment-838645">
		<div id="comment-838645" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f2c83b354c86ffef81a27ed82e83f412?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Lambert</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838645">
			January 7, 2020 at 9:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Seeing what people say about fencers and martial artists as well, it sounds like being crazy like a fox (mumble mumble 4d chess?) is a useful skill to cultivate, even against humans.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-lunawarrior odd alt depth-4" id="li-comment-838496">
		<div id="comment-838496" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/05119b2d18007c8505127a436ffb1d63?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/05119b2d18007c8505127a436ffb1d63?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">lunawarrior</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838496">
			January 7, 2020 at 4:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is true of Humans too. Ask any experienced Martial Artist if they want to spar with someone with a year of training or none.<br />
Naively you would think a year of training would make you harder to fight, but the new guy is more likely to do something wired that you won&#8217;t have a practiced reaction to.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gbdub even depth-5" id="li-comment-838542">
		<div id="comment-838542" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">gbdub</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838542">
			January 7, 2020 at 7:00 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I feel like this is in some sense true but also overstated. Untrained fighters are not random, they just behave very differently than people with a little training so if you expect them to behave like a trainee, you are going to have a bad time. </p>
<p>If you hand a sword to a random novice, they are probably going to use it (badly) like most every other novice. The danger in a fight would, I suppose, be that they are much more likely to unknowingly do something suicidal for themselves but hard to defend against.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zeromh odd alt depth-5" id="li-comment-838583">
		<div id="comment-838583" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838583">
			January 7, 2020 at 8:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I take issue with the idea of an &#8220;experienced&#8221; martial artist who has never sparred with beginners or new trainees. I wouldn&#8217;t call that person experienced.</p>
<p>Irrespective of that example, I think the principle that lunawarrior is describing is &#8220;an intelligence deals poorly with things that are dissimilar from its training data.&#8221; Which is true for AI and for humans. (Though you should keep in mind that &#8220;dissimilar&#8221; means &#8220;dissimilar according to the feature representation that the intelligence is using.&#8221;)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-pogtastic even depth-5" id="li-comment-838625">
		<div id="comment-838625" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/aee6743013fd0d0055f50fe1feb5de59?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/aee6743013fd0d0055f50fe1feb5de59?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">POGtastic</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838625">
			January 7, 2020 at 9:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I haven&#8217;t done much martial arts aside from a little bit of BJJ, but I wrestled for six years in grade school. In both, people with no training got rocked because they simply didn&#8217;t have the reflexes to react to anything. Maybe they&#8217;d do something weird if I gave them the chance, but I didn&#8217;t give them the chance because I was trained to shoot on their legs as quickly as possible. Aggression requires technique to respond properly, and untrained people simply don&#8217;t have it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-auric-ulvin odd alt depth-5" id="li-comment-838784">
		<div id="comment-838784" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2df08cb18a2244dd57f0d03144bf5ecc?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2df08cb18a2244dd57f0d03144bf5ecc?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Auric Ulvin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838784">
			January 7, 2020 at 2:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>In highly stylized sports like fencing, this is a big effect. I&#8217;m a fairly experienced but hopeless fencer and newbies are a big problem. They hold the foil wrong, they have wrong footwork, they do all kind of weird things with the blade. It screws me up because I have the muscle memory for fencing not flailing-around-with-a-sword. </p>
<p>I imagine if we actually practiced swordfighting with killing in mind we&#8217;d blitz a newbie.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-doesntliketocomment even depth-5" id="li-comment-838919">
		<div id="comment-838919" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c1b743ddc486ecb10d412b09f1cdf956?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c1b743ddc486ecb10d412b09f1cdf956?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doesntliketocomment</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838919">
			January 8, 2020 at 7:47 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Auric I think the idea is that you beat a person with little experience 100 out of 100 times, and a person with almost no experience (but good reflexes) 95 out of 100. The times you lose are the times where they do something so flagrantly suicidal and unlikely to work that you just don&#8217;t expect it or fail to recognize it in time. Meanwhile the trainees are executing moves you expect, and poorly to boot.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zeromh odd alt depth-4" id="li-comment-838597">
		<div id="comment-838597" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838597">
			January 7, 2020 at 8:44 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Ketil: Yes, but the point of learning a useful feature representation is that you don&#8217;t have to explore every game state.</p>
<p>AlphaGo arguably has a better feature representation of Go than any human, because AlphaGo usually wins. But it&#8217;s not perfect. I guess there was something about the association between game state (X input) and win probability (Y output) in the game branch that Sedol forced the game into that was different from what AlphaGo had learned on. But, to make a better AlphaGo you wouldn&#8217;t need to train on those game states specifically; you&#8217;d need to train on [some number of] game states that have a relationship between X and Y that is similar to that one.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-whereamigoing even depth-5" id="li-comment-839184">
		<div id="comment-839184" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b661e7dc5cee003761eacb226430922e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b661e7dc5cee003761eacb226430922e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">whereamigoing</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839184">
			January 8, 2020 at 2:22 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The problem is not just distributional shift, but the combination of that and Monte-Carlo tree search. Go programs can fail unexpectedly against &#8220;sharp&#8221; moves where one long sequence yields a good result for the human, but any other sequence leads to the program winning, the paradigm case being &#8220;ladders&#8221;. This is because the tree search effectively models the opponent as having some probability of making a mistake at each move, whereas humans model the whole sequence as a single chunk &#8212; either you start the sequence and play it to the end, or you don&#8217;t start the sequence. I think this is the core problem with applying AlphaZero to math or programming, where one needs long chains of deductive reasoning.</p>
<p>Also, AlphaGo played really poorly for the rest of the game after that move, which I think is also due to the Monte-Carlo tree search. A human player would try to keep the game close to even and wait for their opponent to make a mistake, but AlphaGo saw all moves leading to a small loss and so played semi-randomly.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ganggang3ster odd alt depth-3" id="li-comment-838551">
		<div id="comment-838551" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/517eb8390d1af0ebfbd2e599a3c363da?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/517eb8390d1af0ebfbd2e599a3c363da?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">DragonMilk</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838551">
			January 7, 2020 at 7:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>So it&#8217;s succumb the apocryphal, &#8220;The best swordsman fears not the #2 swordsman but the man who doesn&#8217;t know what he&#8217;s doing&#8221;?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kaakitwitaasota even thread-even depth-1" id="li-comment-838454">
		<div id="comment-838454" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d1f625e8c879f4ac11811d338bd3638e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d1f625e8c879f4ac11811d338bd3638e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">kaakitwitaasota</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838454">
			January 6, 2020 at 11:39 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>GPT2&#8217;s inexplicable competence at something it&#8217;s never been trained to do is somewhat reminiscent of <a rel="nofollow"href="https://twitter.com/dril_gpt2" rel="nofollow ugc">the new GPT2 dril imitator</a>, which&#8211;at least to my mind&#8211;does dril tweets better than dril does.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-robertskmiles odd alt depth-2" id="li-comment-838477">
		<div id="comment-838477" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/70227843ad00eae8b64aefb8024fa460?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/70227843ad00eae8b64aefb8024fa460?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.youtube.com/c/robertmilesai' rel='external nofollow ugc' class='url'>Robert Miles</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838477">
			January 7, 2020 at 2:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a rel="nofollow"href="https://twitter.com/dril_gpt2/status/1212044175270694912" rel="nofollow ugc">https://twitter.com/dril_gpt2/status/1212044175270694912</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-haru even depth-2" id="li-comment-838486">
		<div id="comment-838486" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/248327ae4bdc136e3ae373e95d52679f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/248327ae4bdc136e3ae373e95d52679f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Haru</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838486">
			January 7, 2020 at 4:06 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt; GPT2’s inexplicable competence at something it’s never been trained to do</p>
<p>But it has been trained to play chess, from more games than you will ever see. It has been trained to do language with more sentences than anyone could ever read, and it has been trained to do dril tweets with all dril tweets.</p>
<p>It&#8217;s good at learning, it doesn&#8217;t invent new competences from scratch.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-szaboaron19980805 odd alt depth-3" id="li-comment-838734">
		<div id="comment-838734" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7341bd9cada8e1e97c099dcfe6b84cf7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7341bd9cada8e1e97c099dcfe6b84cf7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Aron Szabo</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838734">
			January 7, 2020 at 12:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The wording &#8220;trained to do&#8221; was badly chosen, but the underlying sentiment is solid. GPT2 doesn&#8217;t invent new competences from scratch in the sense that it can do things that it doesn&#8217;t have a lot of data for, but it does invent new competences in the sense that it can do things it was never designed to do in the first place.</p>
<p>The second is still pretty surprising &#8211; language models aren&#8217;t supposed to be able to play chess. Or compose songs. GPT2 is good at learning significantly more things that was ever intended.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-doesntliketocomment even depth-4" id="li-comment-838924">
		<div id="comment-838924" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c1b743ddc486ecb10d412b09f1cdf956?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c1b743ddc486ecb10d412b09f1cdf956?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doesntliketocomment</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838924">
			January 8, 2020 at 7:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think perhaps what is being overlooked is that humans are very good at transposing things into the form of a consistent language. From that standpoint, anything that can mimic language can mimic the sequence of actions it describes. If one looks at English (or any other written language) as a coded system used to describe and transmit the entire range of human experience, then a system that can accurately generate that code should easily be able to generate the much more limited information coded in a chess game.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-watsonians odd alt depth-2" id="li-comment-838501">
		<div id="comment-838501" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a0b29a8b87243ab99f58fa7f27f89566?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a0b29a8b87243ab99f58fa7f27f89566?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://frogperspectives.net' rel='external nofollow ugc' class='url'>Enkidum</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838501">
			January 7, 2020 at 5:22 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is incredible.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-doctor-mist even depth-2" id="li-comment-838992">
		<div id="comment-838992" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/de402e9fff554d839c0f8e4a8c44c431?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doctor Mist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838992">
			January 8, 2020 at 10:18 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The GPT2 dril imitator says the items are &#8220;human-curated&#8221;, which leaves open the question of how much dross the human had to wade through to get the gems. From what I&#8217;ve seen in passing on SSC, the answer might be &#8220;not much at all&#8221; but I can never tell.</p>
<p>I&#8217;m having an interesting experience at the moment, proofreading a novel. To keep myself from falling into a flow state, I randomized the sentences, which means every so often I get a sequence of unrelated sentences that really seem to make a kind of sense, like:</p>
<blockquote><p>That will open the way toward more specialized contracts.<br />
I did not complain.<br />
I didn&#8217;t.<br />
It was unmistakably a balloon—a large one, judging by its position on the horizon.<br />
“Unless that&#8217;s one of the defense satellites.”</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-mugasofer odd alt depth-3" id="li-comment-839758">
		<div id="comment-839758" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839758">
			January 9, 2020 at 4:35 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Check out <a rel="nofollow"href="https://nostalgebraist-autoresponder.tumblr.com/" rel="nofollow ugc">https://nostalgebraist-autoresponder.tumblr.com/</a>, which isn&#8217;t human-curated and posts entirely automatically.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jugemu even thread-odd thread-alt depth-1" id="li-comment-838460">
		<div id="comment-838460" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/007334d3a18759020103c13c98e5556f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Jugemu</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838460">
			January 7, 2020 at 12:53 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s cool that GPT2 is able to do this despite being created for quite a different purpose. What it&#8217;s doing seems to be similar to one component of the original Alpha Go, which was trained on professional Go games to predict the most likely next move.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-michael-watts odd alt depth-2" id="li-comment-838472">
		<div id="comment-838472" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Michael Watts</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838472">
			January 7, 2020 at 2:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>It’s cool that GPT2 is able to do this despite being created for quite a different purpose.</p></blockquote>
<p>But it isn&#8217;t able to do this. Lacking a model of the game, it keeps trying to make invalid moves. (I assume an invalid move involves moving a piece from a square that doesn&#8217;t contain that piece, or capturing a square that doesn&#8217;t contain an enemy piece, or moving onto a square that contains a piece, or the like.) If you&#8217;re teaching a six-year-old to play chess, and their signature move is that they keep capturing your rook &#8212; safe behind its pawns &#8212; with the bishop you captured from them several turns ago&#8230; you would not describe them as &#8220;able to play chess&#8221;.</p>
<p>On the other hand&#8230;</p>
<blockquote><p>Obviously, training on just moves with the implicit game state having to be built up from scratch from the history every time is very difficult – even MuZero at least gets to see the entire game state at every move</p></blockquote>
<p>This quote is not accurate in terms of how humans play chess. Humans do in fact build up the game state from the list of moves that occur; they place comparatively little emphasis on deriving the game state by looking at the board. We know this by the following experiment:</p>
<p>Grandmasters are very good at memorizing the state of a chessboard, given that state occurs in a game they&#8217;re following (usually, a game they&#8217;re playing). It is what passes for a popular party trick in chess.</p>
<p>But grandmasters perform no better than anyone else at memorizing a <i>random</i> chessboard.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gbdub even depth-3" id="li-comment-838539">
		<div id="comment-838539" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">gbdub</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838539">
			January 7, 2020 at 6:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Humans who are playing a full game do build up understanding as the game goes along, but, presented with a board in mid game with no other context, anyone who knows the rules of chess could still complete that game without making invalid moves.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-tohron odd alt depth-4" id="li-comment-838763">
		<div id="comment-838763" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a5465d73db548fa6fb2b0668e524c812?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a5465d73db548fa6fb2b0668e524c812?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">tohron</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838763">
			January 7, 2020 at 1:20 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Well, technically, there would be some board setups where it&#8217;s unclear which sides white and black started on, without which you wouldn&#8217;t know which direction you could legally move the pawns.  If you&#8217;re using chess notation though, that wouldn&#8217;t be a problem.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern even depth-3" id="li-comment-838559">
		<div id="comment-838559" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838559">
			January 7, 2020 at 7:37 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>This quote is not accurate in terms of how humans play chess. Humans do in fact build up the game state from the list of moves that occur; they place comparatively little emphasis on deriving the game state by looking at the board. We know this by the following experiment:</p></blockquote>
<p>Humans obviously do <i>not</i> do that, or else things like &#8216;blindfold chess&#8217; would not exist and need to be learned: they would simply be normal chess which any chess player could do at 100% playing strength the instant they wanted to. (Even if they did, they are still doing so recurrently, using their memory, which is precisely what GPT-2 does not have but other things like MuZero do have, part of why we would expect GPT-2 to fall over after a certain number of moves because a long enough history exhausts its ability to reconstruct the history within a single forward pass while leaving room to do any kind of thinking or planning, and why I brought it up as a contrast.) Your example does not show what you say it does, as it only demonstrates the importance of domain knowledge &amp; chunking; it certainly doesn&#8217;t demonstrate that human players have no need for images of boards and do not rely heavily on its state.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-4" id="li-comment-838581">
		<div id="comment-838581" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838581">
			January 7, 2020 at 8:19 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>(Even if they did, they are still doing so recurrently, using their memory, which is precisely what GPT-2 does not have but other things like MuZero do have, part of why we would expect GPT-2 to fall over after a certain number of moves because a long enough history exhausts its ability to reconstruct the history within a single forward pass while leaving room to do any kind of thinking or planning, and why I brought it up as a contrast.)</p></blockquote>
<p>You can try to swap the Transformer architecture with a LSTM, but I don&#8217;t think it will perform any better. Empirically, transformers outperform LSTMs in almost all natural datasets, even though in theory LSTMs are more expressive.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern even depth-5" id="li-comment-838592">
		<div id="comment-838592" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838592">
			January 7, 2020 at 8:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Inasmuch as DM only just got Transformers working in RL contexts, and MuZero doesn&#8217;t use Transformers, &#8216;almost all natural datasets&#8217; seems like a serious exaggeration here.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-5" id="li-comment-838609">
		<div id="comment-838609" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838609">
			January 7, 2020 at 9:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Transformers are generally more expensive to train on self-generated data than LSTMs, but they are more efficient when the data is fixed and you can use teacher forcing, which is the case here.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern even depth-5" id="li-comment-838672">
		<div id="comment-838672" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838672">
			January 7, 2020 at 10:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You&#8217;re assuming that it&#8217;s pure imitation learning. MuZero is not, and no one expects the best results from imitation learning, and that is why I was suggesting how moving to reinforcement learning would improve it, where your point was irrelevant and recurrency is in fact important. It would be more sensible to suggest that a Transformer with some equivalent of recurrency might be equivalent, and in fact the Compressive Transformer does show good RL performance, but that&#8217;s not what you were claiming.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-5" id="li-comment-838952">
		<div id="comment-838952" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838952">
			January 8, 2020 at 9:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t understand why you are conflating RL with recurrence. There is nothing in the MuZero paper that suggests that in principle it couldn&#8217;t be used with a Transformer architecture. Probably they didn&#8217;t try because it would have been more computationally expensive, or just they didn&#8217;t bother with the implementation.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern even depth-5" id="li-comment-839753">
		<div id="comment-839753" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839753">
			January 9, 2020 at 4:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Now you are backpeddling. My original point was that GPT-2, which has no state or recurrence, cannot even in principle play as well as MuZero can, because it cannot track board state and is not deep enough to infer it over arbitrarily long inputs past the opening.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-5" id="li-comment-839863">
		<div id="comment-839863" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839863">
			January 10, 2020 at 4:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Chess games last typically around <a rel="nofollow"href="https://chess.stackexchange.com/questions/2506/what-is-the-average-length-of-a-game-of-chess" rel="nofollow ugc">70 half-moves</a>, GPT-2 has a context window of 1024 BPE tokens, I don&#8217;t know how many BPE tokens does a half-move use, but I&#8217;m guessing that in the vast majority of games GPT-2 can keep the whole game history in memory, hence this is not a meaningful distinction.</p>
<p>MuZero plays chess better than GPT-2 because it has a convolutional network architecture designed to play chess-like and go-like board games, because it does search at both training and inference time, because it has been trained with self-play rather than with imitation and, of course, because it has been trained on a thousand TPUs rather than whatever Scott could afford. Recurrence vs. self-attention is most likely not a big difference (MuZero searches only up to 5 steps in the future).</p>
<p>I conjecture that even in MuZero the recurrent network state is not isomorphic to the game state: when the model plays blind during search, different sequences of moves that result in the same game state will generally not induce approximately equal states in the RNN, rather the RNN state will be a compressed representation of the game history from the point that the RNN stopped to see the whole board. I don&#8217;t have evidence to back up this claim, but it is plausible given how what we empirically know about RNNs.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-michael-watts even depth-4" id="li-comment-838852">
		<div id="comment-838852" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Michael Watts</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838852">
			January 7, 2020 at 11:16 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Do you not see a difference between &#8220;they place comparatively little emphasis on deriving the game state by looking at the board&#8221; and &#8220;they do not derive the game state by looking at the board&#8221;? Let me be more explicit.</p>
<p>A human playing chess maintains a mental model of the game state, and updates that model move by move (&#8220;building up the game state from the list of moves that occur&#8221;). The better they are at chess, the more they will rely on this model, and the less they will rely on making up for deficits in the mental model by looking at the board, which is how you fill in a lacuna or correct a mistake in the mental model.</p>
<p>By contrast, chess software has a mental model of chess-in-general and evaluates all board states directly against that model. There is no model of the game-in-progress other than the raw board state, as evaluated by the model of chess-in-general. This is unlike the way in which humans play chess, and you&#8217;re proposing to make GPT-2 chess more like chess software and, therefore, less like human chess-playing.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern odd alt depth-5" id="li-comment-838897">
		<div id="comment-838897" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838897">
			January 8, 2020 at 6:30 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It is unclear to me that humans put <i>any</i> emphasis on building up a history of the state and trying to imitate playing blindfold chess instead of, y&#8217;know, <i>looking</i> at the board like a sane person would. You want to compare chess master anecdotes? Consider simultaneous chess games against hundreds of people. The chess master is not building up a state of each of hundreds of games and thinking them through all simultaneously; instead, they go from table to table, looking at the board, and planning from there. Because, after all, the board state represents all that is necessary to know; the history is largely irrelevant. And your chunking example is still irrelevant to the argument you are trying to make.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-itai-bar-natan even depth-5" id="li-comment-838936">
		<div id="comment-838936" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4b4acebb179087af2967fc22d798db3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4b4acebb179087af2967fc22d798db3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://itaibn.wordpress.com' rel='external nofollow ugc' class='url'>Itai Bar-Natan</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838936">
			January 8, 2020 at 8:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@gwern How much experience do you have playing chess? This disagrees with my experience. I can attest that it&#8217;s much easier to learn to play blind chess if you have a lot of experience playing ordinary chess beforehand. (I also recall an anecdote that claims that chess masters <i>do</i> remember the state of their games while playing simul but I don&#8217;t want to look this up so I assert this with low confidence.) </p>
<p>Analyzing a novel board position from scratch is time-consuming. It&#8217;s a lot easier to analyze differences, and see how each move affects your assessment of the position. A lot of features, such as &#8220;this piece is pinned&#8221; or &#8220;I&#8217;m threatening this move&#8221; or &#8220;this piece is badly developed&#8221;, are not immediately obvious from looking at the board but are frequently maintained move-to-move. Perhaps the most obvious example is if you&#8217;ve planned a multimove tactic and your opponent is playing a move that you&#8217;ve already anticipated. You only need to look at the board to make a final verification that you haven&#8217;t missed anything, and then you play the move you planned.</p>
<p>For that matter, I want you to think about what a chess player is doing when they plan moves ahead. They need to imagine what the board is like if a move or multiple moves are played, and they need to imagine many such possibilities. Looking at a hypothetical board is impossible and imagining a new board from scratch in a new position is computationally infeasible for humans. Instead they imagine a new position from its difference to the current position, and for imagining multiple moves have a mental representation of the history of the game from the current position, so they can backtrack effectively.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern odd alt depth-5" id="li-comment-839749">
		<div id="comment-839749" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839749">
			January 9, 2020 at 3:58 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I played plenty of chess as a kid, and I&#8217;ve read a good deal of chess psychology &amp; expertise literature, and accounts of simul chess. Chess masters who do simul exhibitions do say they rely on board state, and aren&#8217;t memorizing all hundreds of games simultaneously. This is part of why they play weaker in simuls, and also why *blindfold* simuls rack up *much* smaller numbers. Regular simuls can go up to 600, while blindfold tops out ~50, checking the latest numbers. Obviously, the board state plays a major role in why one can do 12x the other. Note that chess masters in psych studies can select the most promising moves in a split-second from pure System I processing / heuristics / chunking, and this is consistent with the NN chess/go engines like AlphaZero, which can reach weak-pro-level with a single forward pass (equivalent to &#8216;one look at the board&#8217;) and then become superhuman as they conduct deeper tree search.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-dacyn even depth-3" id="li-comment-838615">
		<div id="comment-838615" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Dacyn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838615">
			January 7, 2020 at 9:09 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The fair comparison would whether a grandmaster can memorize a chessboard state that occurs in a game someone <i>else</i> has been playing: they didn&#8217;t see the moves leading up to it, but it is still a realistic position.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-michael-watts odd alt depth-4" id="li-comment-838853">
		<div id="comment-838853" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d3061c6e143d1184afc1ddcb8a6a61b8?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Michael Watts</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838853">
			January 7, 2020 at 11:31 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That is fair. They perform very well at memorizing realistic positions without seeing the chain of moves that led to them.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vivi_iviv even depth-2" id="li-comment-838523">
		<div id="comment-838523" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838523">
			January 7, 2020 at 6:26 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>It’s cool that GPT2 is able to do this despite being created for quite a different purpose.</p></blockquote>
<p>It&#8217;s not. The version that Scott used has been trained on chess games.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-vivalapanda odd alt depth-3" id="li-comment-839006">
		<div id="comment-839006" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a159086740c239ee2bdfdfeb057a6992?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a159086740c239ee2bdfdfeb057a6992?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">VivaLaPanda</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839006">
			January 8, 2020 at 10:30 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This instance was trained on chess games, but the architecture was built for something totally different.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-smilerz even depth-2" id="li-comment-838633">
		<div id="comment-838633" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">smilerz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838633">
			January 7, 2020 at 9:32 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Actually, I think that it is even more impressive than AlphaZero.  AlphaZero explicitly only allowed valid moves.  Any invalid move had a probability of winning the game &#8211; GPT-2 was able to infer valid moves up to a certain point based purely on pattern recognition.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sniffnoy odd alt thread-even depth-1" id="li-comment-838461">
		<div id="comment-838461" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838461">
			January 7, 2020 at 12:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Editing note, the second tweet is repeated twice at the moment.  (Not sure if the second repetition was supposed to be something else or simply supposed not to exist.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jvdh even thread-odd thread-alt depth-1" id="li-comment-838466">
		<div id="comment-838466" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5c31e197e25b09452cd0e19852207dd5?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5c31e197e25b09452cd0e19852207dd5?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">jvdh</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838466">
			January 7, 2020 at 1:23 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>What does this imply? </p></blockquote>
<p>Relevant prior research and discussion: <a rel="nofollow"href="http://norvig.com/chomsky.html" rel="nofollow ugc">http://norvig.com/chomsky.html</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-sniffnoy odd alt thread-even depth-1" id="li-comment-838468">
		<div id="comment-838468" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3d0837be44b824ac35cfa18a263d2a08?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Sniffnoy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838468">
			January 7, 2020 at 1:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Hm, I tried playing, but midway through my connection to the runtime timed out and I could no longer continue&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-stringhe even thread-odd thread-alt depth-1" id="li-comment-838475">
		<div id="comment-838475" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Stringhe</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838475">
			January 7, 2020 at 2:54 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Reminds me of this famous 2015 post &#8220;The Unreasonable Effectiveness of Recurrent Neural Networks&#8221; <a rel="nofollow"href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="nofollow ugc">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a><br />
Would be interesting to see how much of an improvement different text ML methods are for things like chess, music and so on, and how much they are &#8220;over-fitted&#8221; to language</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-avorobey odd alt thread-even depth-1" id="li-comment-838476">
		<div id="comment-838476" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anatoly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838476">
			January 7, 2020 at 2:57 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Someone did a project, a few years ago, teaching a convolutional neural network to play chess off a database of games, by predicting the next move just based on the similarity of its text to the game so far, without using any win/lose signals &#8211; that&#8217;s very similar to using GPT-2, but with the standard image-recognition-oriented architecture. I remember it learned to play to about a master&#8217;s level, but would still make  invalid moves maybe 0.5% of the time, which I found fascinating. I can&#8217;t find this project now (there&#8217;s a bunch of deep learning chess papers in recent years, but none of them is this particular thing). </p>
<p>I was so impressed that I wrote a short science fiction story, <a rel="nofollow"href='https://docs.google.com/document/d/1IuN_wtQj6vFZ_e7VBzJvq0cbi7dDs_RStVaTeLUetOM/edit#heading=h.iyctulsw7n5e' rel="nofollow ugc">The Weights of the World</a>, in 2018, and put a reference to that project into it. This was written before GPT-2 and rereading my story now is a little uncanny&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-long-disc even depth-2" id="li-comment-838503">
		<div id="comment-838503" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/cebcf13f730560a0bdba3c1dc13e1a69?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/cebcf13f730560a0bdba3c1dc13e1a69?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Long Disc</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838503">
			January 7, 2020 at 5:25 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Anatoly, perhaps now GPT-2 could write an alternative finale for your story?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-toastengineer odd alt depth-2" id="li-comment-838529">
		<div id="comment-838529" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838529">
			January 7, 2020 at 6:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;d be cool to present that story on a web page where, after the end, the site scrolls GPT-2 generated text for as long as the user scrolls down (the implication being he set the AI to write to his log forever as a sort of half-assed immortality.)</p>
<p>I could take a crack at implementing that if you&#8217;re okay with it, but don&#8217;t expect me to actually pull it off.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-avorobey even depth-3" id="li-comment-838629">
		<div id="comment-838629" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anatoly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838629">
			January 7, 2020 at 9:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>(spoiler about the story) Abg fher jurgure lbhe pbzzrag nyyhqrf gb gung, ohg V zrnag gur ernqre gb erpbtavmr gung gur ragver be nyzbfg gur ragver fgbel unf orra jevggra ol gur NV zragvbarq va vg. Gurer&#8217;er pyhrf fgerja guebhtubhg naq zragvbarq va gur fgbel vgfrys nf cbffvoyr NV negvsnpgf (abafrafr punenpgref, vapbafvfgrapvrf nobhg gur fvghngvba). Fb va gung frafr n TCG-2 pbagvahngvba fhpu nf lbh zragvba fubhyqa&#8217;g or arprffnel. Ohg zbfg crbcyr V fubjrq vg gb qvqa&#8217;g frr gur gjvfg ng nyy, fb V guvax V snvyrq va gung erfcrpg. Vs nalbar ernqvat guvf jnf vagrerfgrq rabhtu gb ernq obgu gur fgbel naq guvf EBG13&#8217;q abgr, V&#8217;q or tengrshy sbe n pbzzrag vaqvpngvat lbh qvq/qvq abg frr gur gjvfg.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-toastengineer odd alt depth-4" id="li-comment-838674">
		<div id="comment-838674" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838674">
			January 7, 2020 at 10:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Ah, I did notice that and come up with that hypothesis, but that didn&#8217;t make sense since vs gur svefg &#8220;tyvgpurq&#8221; cnentencu, v.r. gur frpbaq ragel, znexf gur ortvaavat bs gur trarengrq grkg, gura vg&#8217;f njshyyl bqq gung gur trarengbe jbhyq cerqvpg uvz perngvat gur trarengbe. V cebonoyl &#8220;gur gur&#8221;&#8216;q n ybg bs gur gur reebef, naq punyxrq gur barf V fnj hc gb enqvngvba pbeehcgvba. </p>
<p>Hayrff vg npghnyyl _vf_ n uhzna-yriry TNV gelvat gb or yvxr &#8220;V gevrq gb ohvyq na NV ohg vg qvqa&#8217;g jbex un un orggre whfg yrnir guvf fuvc sybngvat va fcnpr naq sbetrg nobhg vg,&#8221; ohg gung qbrfa&#8217;g znxr nal frafr rvgure, orpnhfr jbhyqa&#8217;g vg or orggre gb whfg abg zragvba vg ng nyy gura?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-avorobey even depth-5" id="li-comment-838726">
		<div id="comment-838726" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anatoly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838726">
			January 7, 2020 at 12:19 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thanks, that&#8217;s useful! Zl vqrn jnf gung gur uhzna bevtvanyyl ohvyg gur NV, juvpu jbexrq, naq gura qvrq. Gur NV rvgure jevgrf gur jubyr svyr be pbagvahrf nsgre gur svefg ragel (qbrfa&#8217;g ernyyl znggre, yrg&#8217;f fnl jevgrf gur jubyr svyr), naq fvapr vg&#8217;f onfvpnyyl n arheny arg genvarq hc gb or gur pbafpvbhfarff bs gur uhzna naq gur zrzbel bs gur uhzna (hc hagvy gur ortvaavat bs gur fgbel), vg jevgrf fbzrguvat irel pybfr gb jung gur bevtvany jebgr va gur bevtvany qvnel, zbqhyb jrveq tyvgpurf. Jura vg pbzrf gb genvavat gur NV, ubjrire, gur NV vf abg cbjreshy rabhtu gb fvzhyngr NV-jvguva-NV, naq ng gung cbvag gur ybt qviretrf sebz gur bevtvany, juvpu jr arire trg gb frr. Vg&#8217;f ba zr gung guvf vfa&#8217;g pyrne rabhtu gb gur ernqre, bs pbhefr.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-eggsyntax odd alt depth-4" id="li-comment-838804">
		<div id="comment-838804" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4ccf320bd016b7a6cdd8c75bbba88cab?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4ccf320bd016b7a6cdd8c75bbba88cab?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">eggsyntax</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838804">
			January 7, 2020 at 2:52 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>V qvq frr gur gjvfg, snveyl rneyl. Vg jnf pbashfvat gung arneyl gur jubyr guvat jnf jevggra ol gur NV, orpnhfr gura nf gur ernqre V unq ab vqrn jurgure gur npghny gehgu unq nalguvat gb qb jvgu jung gur NV jnf jevgvat. Sebz zl crefcrpgvir gur fgbel jbhyq or n ovg fgebatre vs gur tyvgpurf fgnegrq, fnl, unysjnl guebhtu.</p>
<p>Sha fgbel!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-eggsyntax even depth-5" id="li-comment-838805">
		<div id="comment-838805" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/4ccf320bd016b7a6cdd8c75bbba88cab?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/4ccf320bd016b7a6cdd8c75bbba88cab?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">eggsyntax</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838805">
			January 7, 2020 at 2:54 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Amusingly, my usual resistance to posting here largely vanishes in ROT-13 😉</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-mugasofer odd alt depth-4" id="li-comment-840182">
		<div id="comment-840182" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6e07249aee9d1dbe4d7bba82a7460a2a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://pseudonymwrites.wordpress.com' rel='external nofollow ugc' class='url'>MugaSofer</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-840182">
			January 10, 2020 at 6:02 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>V svtherq gung jnf cebonoyl gur vagrag bs gur glcbf, lrf. </p>
<p>V qvqa&#8217;g pngpu gur vapbafvfgrapvrf, ohg vs V unq V jbhyq cebonoyl unir nffhzrq gurl jrer npghny zvfgnxrf.</p>
<p>EDIT: V gubhtug gur NV zvtug or ybbcvat guebhtu qvssrerag irefvbaf bs gur fnzr ybt, tvira gur raqvat zveebef gur ortvaavat. r.t. bar ur tvirf hc ba gur NV naq jngpurf gur ZPH (hfvat gur ratvar pbzchgre juvpu vf zber cbjreshy naq fb pna qvfcynl ivqrb, V thrffrq, nygubhtu va ergebfcrpg V thrff gung jnf fhccbfrq gb or n gryyvat pbagenqvpgvba); va nabgure ur nibvqf purpxvat jura ur&#8217;yy eha bhg bs sbbq be jngre.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-stringhe even depth-2" id="li-comment-838747">
		<div id="comment-838747" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Stringhe</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838747">
			January 7, 2020 at 12:50 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I have some experience messing around with chess engines, and I *really* didn&#8217;t think you could reach master level just by &#8220;predicting the next move just based on the similarity&#8221; of the game so far using any database of human games. (while in go doing that same thing is surprisingly easy)</p>
<p>If you could find any information about it I would be very very interested. Maybe you were thinking of giraffe <a rel="nofollow"href="https://www.chessprogramming.org/Giraffe" rel="nofollow ugc">https://www.chessprogramming.org/Giraffe</a> that used a similar strategy, but just for the evaluation function?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein odd alt depth-3" id="li-comment-838757">
		<div id="comment-838757" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838757">
			January 7, 2020 at 1:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Giraffe also uses deep learning for branch choice (deciding which branches are most ”interesting” in any given position, and should be searched further, as well as which branches to discard) and move ordering (determining which moves to search before others) which significantly affects efficiency of searches. </p>
<p>Notably, Giraffe does <i>not</i> depend on board similarity. In fact, IIRC the paper contains a discussion about the disadvantages of considering the board as an image (e.g., small changes in pawn positions lead to radical evaluation changes). The evaluation function works with a long list of hand-crafted features representing the game state. The list even includes threatened squares, I think.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-avorobey even depth-3" id="li-comment-838777">
		<div id="comment-838777" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anatoly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838777">
			January 7, 2020 at 1:50 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a rel="nofollow"href="https://github.com/ashudeep/ConvChess/blob/master/convchess.pdf" rel="nofollow ugc">https://github.com/ashudeep/ConvChess/blob/master/convchess.pdf</a></p>
<p>(I don&#8217;t know why, but this was *really* difficult to find; thanks for prodding me, because I&#8217;d already spent a while earlier today when writing the original comment and given up.)</p>
<p>So yeah, I remembered it incorrectly; it encodes the board representation as an image and runs a convolutional neural network on that. It does predict the next move (there&#8217;s also a version which learns an evaluation function), and the best it can do &#8211; with the version that predicts &#8211; is win ~10% of games against Sunfish. I think that&#8217;s quite below a master level, right? Maybe around 1900 ELO, just guesstimating? If so, I think it&#8217;s still remarkable that it&#8217;s able to get to that level while occasionally making an outright illegal move (see p.39 for the percentages of those). That&#8217;s what captured my attention, originally. </p>
<p>(I think after I read about it I toyed with the idea of using an LSTM architecture to make a move predictor based on just the text  of the game, without board representations, but never actually tried it; that&#8217;s why I remembered it wrong)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-stringhe odd alt depth-4" id="li-comment-838865">
		<div id="comment-838865" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8b718acfcdb1911441066106f8cfbb50?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Stringhe</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838865">
			January 8, 2020 at 2:55 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Thank you so much for finding it!</p>
<p>Sunfish with 1000 nodes is absolutely not 1900 Elo, probably even below 1300, I would be very curious on how these approaches fare against the average human (non chess enthusiast) player on short time controls (playing on &#8220;instincts&#8221;)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kokotajlodgmail-com even thread-odd thread-alt depth-1" id="li-comment-838478">
		<div id="comment-838478" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/79dbef0f04142e9d709518a00df678ef?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/79dbef0f04142e9d709518a00df678ef?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">kokotajlod@gmail.com</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838478">
			January 7, 2020 at 2:58 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>How much of this is due to transfer learning and how much of it is just the architecture? More specific question: Suppose that instead of taking the trained GPT-2 model and fine-tuning it on chess games, you just trained from scratch on chess games. How much worse (if at all) would the result be?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein odd alt depth-2" id="li-comment-838506">
		<div id="comment-838506" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838506">
			January 7, 2020 at 5:32 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8230;but the presence of efficient transfer learning in these domains would be fascinating in itself. </p>
<p>Image exhibit behavior conducive to transfer learning &#8211; lots of generic features such as corners, lines etc. It&#8217;s not at all obvious that anything like this should exist for text-bases chess!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-akhorahil even thread-even depth-1" id="li-comment-838479">
		<div id="comment-838479" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Akhorahil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838479">
			January 7, 2020 at 3:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t believe that poorly mixing and copying what it finds is very impressive &#8211; it still plays chess worse than a human with five minutes of rules briefing (as it does everything else), and &#8220;not breaking the rules until several moves in&#8221; is an exceptionally low bar to set.</p>
<p>GPT-2 is fun, but probably a dead end, as the only thing it does is parrot what others are doing&#8230; poorly.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-googolplexbyte odd alt thread-odd thread-alt depth-1" id="li-comment-838480">
		<div id="comment-838480" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c4d17736f39742e0287148653b7bf61d?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c4d17736f39742e0287148653b7bf61d?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">googolplexbyte</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838480">
			January 7, 2020 at 3:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>The main shortcoming of GPT-2 seems to be its inability to establish a context/structure/memory.</p>
<p>Give GPT-2 a way to organically hold a board state, or track its position in a list, or traits of a character and it seems like it would do a lot better.</p>
<p>Maybe it could do something with commented text.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-toastengineer even depth-2" id="li-comment-838495">
		<div id="comment-838495" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838495">
			January 7, 2020 at 4:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>No- the main ADVANTAGE of GPT-2 is it&#8217;s ABILITY to establish context. It&#8217;s better than anything before it at this, it just happens to suck horribly compared to a human brain.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-jt_peterson odd alt thread-even depth-1" id="li-comment-838481">
		<div id="comment-838481" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JT_Peterson</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838481">
			January 7, 2020 at 3:50 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt;According to evolution by natural selection, an organism that sees reality as it is will never be more fit than an organism of equal complexity that sees none of reality but is just tuned to fitness. Never.</p>
<p><a rel="nofollow"href="https://www.quantamagazine.org/the-evolutionary-argument-against-reality-20160421/" rel="nofollow ugc">https://www.quantamagazine.org/the-evolutionary-argument-against-reality-20160421/</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-watsonians even depth-2" id="li-comment-838502">
		<div id="comment-838502" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/a0b29a8b87243ab99f58fa7f27f89566?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a0b29a8b87243ab99f58fa7f27f89566?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://frogperspectives.net' rel='external nofollow ugc' class='url'>Enkidum</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838502">
			January 7, 2020 at 5:25 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Does this relate to the article somehow?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jt_peterson odd alt depth-3" id="li-comment-838509">
		<div id="comment-838509" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JT_Peterson</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838509">
			January 7, 2020 at 5:46 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Sorry, I should have been more clear. The quote from above was in the article I posted, and when I posted it I was thinking about this part in Scott&#8217;s post.</p>
<blockquote><p>Black is GPT-2. Its excuse is that it’s a text prediction program with no concept of chess. As far as it knows, it’s trying to predict short alphanumeric strings like “e2e4” or “Nb7”. Nobody told it this represents a board game. It doesn’t even have a concept of 2D space that it could use to understand such a claim. But it still captured my rook! Embarrassing!</p></blockquote>
<p>I think the quote from the original article has interesting implications all around.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-dacyn even depth-4" id="li-comment-838635">
		<div id="comment-838635" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Dacyn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838635">
			January 7, 2020 at 9:38 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>But this example is a disproof of the quote, since algorithms that do make use of 2D representations play chess much better than GPT-2.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jt_peterson odd alt depth-5" id="li-comment-838806">
		<div id="comment-838806" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JT_Peterson</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838806">
			January 7, 2020 at 2:54 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I’m not exactly sure how to think about ML algorithms in terms of the theory. But it does seem too apply. </p>
<blockquote><p>
Monte Carlo simulations of evolutionary games demonstrate that perceptions which accurately estimate reality never outcompete perceptions of equal complexity which do not estimate reality but are instead tuned to the relevant fitness functions (Mark et al., 2010; Hoffman et al., 2013; Marion, 2013; Mark, 2013).</p>
<p>The key idea here is the fitness function. What is the fitness conveyed by, say, a piece of raw beef? The answer depends on the organism, its state, and its action. For a hungry cheetah looking to eat, the beef enhances fitness. For a sated cheetah looking to mate, it does not. And for a cow looking to do anything, it does not. Thus a fitness function depends not just on the state of objective reality, but also, and crucially, on the organism, its state and action. Fitness functions, not objective reality, are the coin of the realm in evolutionary competition.</p>
<p>The results of Monte Carlo simulations are now buttressed by the Fitness-Beats-Truth (FBT) Theorem: For an infinitely large class of generically chosen worlds, for generically chosen probabilities of states on the worlds, and for generically chosen fitness functions, an organism that accurately estimates reality is never, in an infinite class of evolutionary games, more fit than an organism of equal complexity that does not estimate objective reality but is instead tuned to the relevant fitness functions.</p>
</blockquote>
<p><a rel="nofollow"href="http://cogsci.uci.edu/~ddhoff/Hoffman-Stevens-Handbook.pdf" rel="nofollow ugc">http://cogsci.uci.edu/~ddhoff/Hoffman-Stevens-Handbook.pdf</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-dacyn even depth-5" id="li-comment-838822">
		<div id="comment-838822" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1bb5e8e87225d61317d613aa853e22e6?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Dacyn</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838822">
			January 7, 2020 at 3:40 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@JT_Peterson: I find myself most suspicious of &#8220;generically chosen fitness functions&#8221; &#8212; the whole point of models is to exploit structure in the environment, so if you instead assume that the environment is random then it&#8217;s not surprising that models don&#8217;t help anymore. I am also not sure exactly what they mean by &#8220;accurately estimate reality&#8221; or whether it lines up with my intuitive notion of an algorithm that makes models of its environment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-protagoras odd alt depth-5" id="li-comment-839165">
		<div id="comment-839165" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/72ea6a53f8da6cff7f43428feccb7c76?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/72ea6a53f8da6cff7f43428feccb7c76?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Protagoras</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839165">
			January 8, 2020 at 1:41 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>So, if I understand this correctly, this person has provided an exciting proof that if two systems have the same amount of information, but one has only relevant information while the other has a mixture of relevant and irrelevant information, the former will outperform the latter. I would never have guessed. Also, apparently if information is relevant, it stops representing reality. Call the Journal of Irreproducible Results!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nadbor even depth-5" id="li-comment-839386">
		<div id="comment-839386" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6ec72219b10a168772644aef2e671d19?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6ec72219b10a168772644aef2e671d19?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">nadbor</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839386">
			January 9, 2020 at 6:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>@Protagoras &#8211; this</p>
<p>The bit about a mathematical proof is pure misdirection. It&#8217;s like a magician saying &#8216;abracadabra&#8217;. It&#8217;s supposed to be the magical part but actually, at this point the sleight of hand has already happened. In this case the sleight of hand is defining &#8216;reality&#8217; in a way that excludes the information about the organism in question.</p>
<p>Scott has already written about the deployment of mathematics in the role of smoke and mirrors and gave it the name of Eulering.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nadbor odd alt depth-2" id="li-comment-838538">
		<div id="comment-838538" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/6ec72219b10a168772644aef2e671d19?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/6ec72219b10a168772644aef2e671d19?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">nadbor</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838538">
			January 7, 2020 at 6:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t understand this guy at all. How can he talk of fitness function as opposed to reality? What is it a function of if not (some aspect of) reality?</p>
<p>I guess his point may be that there is plenty of reality that doesn&#8217;t affect the fitness function therefore it&#8217;s only adaptive to perceive certain aspects of reality and not others. And the number of things we could in principle perceive but don&#8217;t is vastly larger than the the number we do. Like I&#8217;m not constantly aware of the exact number of hairs on my head because it&#8217;s not something worth knowing from evolutionary point of view. But that&#8217;s a rather boring observation and it&#8217;s a stretch to call it &#8216;seeing *none* of reality&#8217;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-jt_peterson even depth-3" id="li-comment-838807">
		<div id="comment-838807" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5716c9e3a32f258d22fc2b1c74e63cad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">JT_Peterson</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838807">
			January 7, 2020 at 2:55 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>See my response above. He claims to have a mathematical proof.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kindly odd alt depth-2" id="li-comment-838612">
		<div id="comment-838612" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/843058514a0fb95771da6c71c547ed84?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/843058514a0fb95771da6c71c547ed84?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Kindly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838612">
			January 7, 2020 at 9:07 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>A related quote by Chesterton, on an old man vs. an actor pretending to be an old man:</p>
<blockquote><p>An old man in poor health, like my rival, could not be expected to be so impressively feeble as a young actor in the prime of life. You see, he really had paralysis, and working within this definite limitation, he couldn’t be so jolly paralytic as I was.</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-murphy even thread-odd thread-alt depth-1" id="li-comment-838482">
		<div id="comment-838482" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Murphy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838482">
			January 7, 2020 at 3:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This may be stupid because I only ever use pretrained models but I remember a post by gwern a while back about improving poetry results by including regular metadata. </p>
<p>With these millions of chess games in standard format it should be pretty trivial to generate compact a text representation of the board after every single move. 64 characters should do it. </p>
<p>How about for training adding the board state to the input before every single move? </p>
<p>Then prompt it with a given board state.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern odd alt depth-2" id="li-comment-838563">
		<div id="comment-838563" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838563">
			January 7, 2020 at 7:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>64 characters actually isn&#8217;t enough because you have stuff like en passant, no repetition, and whatnot to consider&#8230; But yes, using <a rel="nofollow"href="https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation" rel="nofollow ugc">FEN encoding </a>of the full board state is the obvious fix to the hidden state problem, to make it Markovian and much easier for GPT-2 to predict. That&#8217;s what Shawn was working on before he switched over to making a playable Colab notebook for Scott.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-zeromh even depth-3" id="li-comment-838601">
		<div id="comment-838601" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838601">
			January 7, 2020 at 8:55 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>So does the current version take only the previous move as input? (I&#8217;m confused about this from the OP.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern odd alt depth-4" id="li-comment-838670">
		<div id="comment-838670" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838670">
			January 7, 2020 at 10:36 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>As I understand it, at each move, it is simply being fed the full history (that is, a sequence of moves) of the game to date in PGN format. The idea is to reprocess the dataset and dump FENs at every move, so instead of being (random metadata, move 1, move 2, move 3&#8230;) it&#8217;ll be (random metadata, FEN0, move 1, FEN1, move 2, FEN2, move 3&#8230;). The entire game might not fit in the context window, but it doesn&#8217;t need to since the FEN encodes everything necessary to know to predict what move <i>n</i> comes after a specific FEN. Then you simply feed in a FEN and get back out the predicted move.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-zeromh even depth-5" id="li-comment-838683">
		<div id="comment-838683" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838683">
			January 7, 2020 at 10:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Ah, ok thank you. Given that information, it&#8217;s a lot more reasonable that this thing makes passable predictions at all. When I thought it was just using a single move as input, that seemed very surprising.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-murphy odd alt depth-3" id="li-comment-838654">
		<div id="comment-838654" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7e251322e700cb4910ad3f3bcf68eb74?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Murphy</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838654">
			January 7, 2020 at 10:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Cheers for the reply!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-emiliobumachar even depth-3" id="li-comment-839067">
		<div id="comment-839067" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5f8ede664a2d3f2c326dcc2b3d7393ea?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5f8ede664a2d3f2c326dcc2b3d7393ea?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">emiliobumachar</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839067">
			January 8, 2020 at 11:49 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Crackpot idea: feed it a board state compressed with losses, only containing whether a white piece, a black piece or no piece occupies each square. 128 bits or less.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-roryokane odd alt depth-4" id="li-comment-843964">
		<div id="comment-843964" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5b2b185c814bb25f2f95a1152e58f033?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5b2b185c814bb25f2f95a1152e58f033?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://roryokane.com/' rel='external nofollow ugc' class='url'>Rory O’Kane</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-843964">
			January 21, 2020 at 6:15 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Something similar has been tried before: see <i><a rel="nofollow"href="http://sigbovik.org/2019/proceedings.pdf#page=64" rel="nofollow ugc">Color- and Piece-blind Chess</a></i> by Dr. Tom Murphy VII Ph.D., published in the semi-satirical journal SIGBOVIK on April 1, 2019.</p>
<p>The author’s program is different from your idea in that it is not just piece-blind, but also color-blind. Also, the program only uses a neural network for the step of guessing which pieces are where—the step of choosing a good move based on those board positions is done using the chess engine Stockfish. The author mentions near the end that they could have used a neural network for the whole process, but it would have taken too much training time.</p>
<p>If you like that type of research, see also the <a rel="nofollow"href="http://tom7.org/chess/" rel="nofollow ugc">author’s other chess-related works</a>, including <i><a rel="nofollow"href="http://sigbovik.org/2019/proceedings.pdf#page=16" rel="nofollow ugc">Elo World, a framework for benchmarking weak chess engines</a></i> from that same SIGBOVIK issue.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-b_epstein even thread-even depth-1" id="li-comment-838488">
		<div id="comment-838488" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838488">
			January 7, 2020 at 4:11 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>[2000-2100 player here]</p>
<p>After a few games, it seems the natural guesses are correct. Cryochess plays reasonably well in standard openings and positions that arise from them (for a while, at least). For instance, playing a QGD (1. d4 d5 2. c4 e6 3. Nc3 etc),with almost no tactics or forced lines, it survived until move 12 with only a mild disadvantage (and then connection timed out). It was even robust to reasonable deviations (move order, slightly unusual insertions such as a2-a3). However, at the slightest hint of a &#8220;wild&#8221; opening (such as 1. g4, Grob) and pieces outside their usual positions (such as queen traveling to f6 early), the game is basically over by move 10-12. In particular, there&#8217;s no reason for it to move threatened pieces or to avoid moving pieces into threatened squares (outside standard exchanges such as pawns taking each other on d5). I don&#8217;t believe that changing the state representation will do a lot to remedy this crucial disadvantage. Perhaps adding some basic internal info might &#8211; but then we&#8217;re back in standard chess engine territory.</p>
<p>Why does the inability to act outside well-expored areas matter to the general implications of all of this? It&#8217;s worth pointing out that contra Ketil&#8217;s comment &#8211; </p>
<blockquote><p>I think this is a general weakness of deep learning systems – they depend heavily on data being from the expected distribution it was trained for. </p></blockquote>
<p> &#8211; the actual strength of deep learning (particularly in its flagship domain of computer vision) is its <i>generalization</i>, that is, precisely its ability go beyond the already-seen data. Nobody&#8217;s shocked to see a huge ResNet fit the training data. It&#8217;s the lack of overfitting that constitutes the &#8220;deep learning mystery&#8221;, such that it is. As for AlphaGo, it is a complex system much of which is not deep (actually even the &#8220;deep&#8221; parts are fairly shallow), and in any case reinforcement learning struggles with generalization in a way that, e.g., a deep computer vision system does not. </p>
<p>This was a long-winded way of saying that it seems that Cryochess is more like AlphaGo than like an ImageNet-solving ResNet. Possibly the same is true for GPT-2 in general. The distinction seems important &#8211; whatever it means.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-2" id="li-comment-838508">
		<div id="comment-838508" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838508">
			January 7, 2020 at 5:44 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>– the actual strength of deep learning (particularly in its flagship domain of computer vision) is its generalization, that is, precisely its ability go beyond the already-seen data. Nobody’s shocked to see a huge ResNet fit the training data. It’s the lack of overfitting that constitutes the “deep learning mystery”, such that it is. </p></blockquote>
<p>There are two kinds of generalization: in-distribution generalization (interpolation), which is measured on test data which comes form the same probability distribution of the training data (ideally, all samples are i.i.d.), and systematic generalization (extrapolation), which is measured on the test data that comes from a probability distribution different, but related to the training distribution. Deep learning methods excel at the former if the training data is large enough but struggle with the latter.<br />
In the real world of course you almost never find true i.i.d. processes, but for some practical applications (e.g. predicting clicks on ads) you can get close enough to it on the relevant scales that deep learning methods are useful. However, if you want anything approaching true AGI, you need a system that can react appropriately even in situations quite different than anything it has seen in the past. Whether deep learning can do it in principle is the matter of the ongoing <a rel="nofollow"href="https://www.youtube.com/watch?v=EeqwFjqFvJA" rel="nofollow ugc">Bengio-Marcus debate</a> (which is arguably the continuation of the <a rel="nofollow"href="http://norvig.com/chomsky.html" rel="nofollow ugc">Norvig-Chomsky debate</a>). But pretty much everyone agrees that current deep learning methods are can&#8217;t do it at the moment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein even depth-3" id="li-comment-838651">
		<div id="comment-838651" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838651">
			January 7, 2020 at 9:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>All excellent points, but define &#8220;quite different&#8221;. Can a human &#8220;act appropriately even in situations quite different than anything it has seen in the past&#8221;? For some values of &#8220;quite different&#8221; and &#8220;situations&#8221; and even &#8220;it has seen in the past&#8221;. </p>
<p> I&#8217;d be willing to defend the statement that the extent to which deep learning (a sadly vague term, I know) <i>extrapolates </i> is surprising (as in, not well-explained by our intuitions and current level of knowledge). I&#8217;ve seen it do that (in vision, mostly) enough times with scarce enough data not to take the adage &#8220;deep leaning only works with millions of samples from the same distribution&#8221; too seriously.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-4" id="li-comment-838903">
		<div id="comment-838903" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838903">
			January 8, 2020 at 6:55 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>All excellent points, but define “quite different”. Can a human “act appropriately even in situations quite different than anything it has seen in the past”? For some values of “quite different” and “situations” and even “it has seen in the past”. </p></blockquote>
<p>Clearly humans have cognitive limits too, but they can extrapolate better than any ML system on most tasks of practical interest.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein even depth-5" id="li-comment-839039">
		<div id="comment-839039" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839039">
			January 8, 2020 at 11:19 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Wait, so your statement is &#8220;we haven&#8217;t developed an AGI yet&#8221;? That is, well, true, but far less interesting than the preceding discussion. To be clear, my statement isn&#8217;t &#8220;ML extrapolates amazingly well&#8221;. It&#8217;s &#8220;to the extent that deep learning works, extrapolation is actually one of its strongest, not weakest, suits (at least in some domains). Also, on the particular task of solving truly new problems, humans are less impressive than they are in general, so demanding ML or even an AGI to excel at that is unreasonable&#8221;.</p>
<p>ETA I should add that part of the reason behind the claims that DL extrapolates poorly (even relatively) is that it does so differently than we do. So moving everything from, say, a jungle to an office might be confusing for it. But flipping the color channels might confuse it less than it would a human. If we restrict to the kind of &#8220;quite different&#8221; that we humans naturally think of, then my statement becomes untenable &#8211; though less so than might be expected apriori.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-vivi_iviv odd alt depth-5" id="li-comment-839132">
		<div id="comment-839132" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839132">
			January 8, 2020 at 12:42 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>To be clear, my statement isn’t “ML extrapolates amazingly well”. It’s “to the extent that deep learning works, extrapolation is actually one of its strongest, not weakest, suits (at least in some domains).</p></blockquote>
<p>Do you have any example of DL extrapolating well?</p>
<blockquote><p>ETA I should add that part of the reason behind the claims that DL extrapolates poorly (even relatively) is that it does so differently than we do. </p></blockquote>
<p>Yes but it does it in a way that is not useful for actual problems, and can be in fact harmful (e.g. adversarial examples transferring between different models with different architectures).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-anon9999 even thread-odd thread-alt depth-1" id="li-comment-838492">
		<div id="comment-838492" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/267e96ddae24c064a4ea1535da826b2b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/267e96ddae24c064a4ea1535da826b2b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">summerstay</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838492">
			January 7, 2020 at 4:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I wrote a <a rel="nofollow"href="https://www.lesswrong.com/posts/yu628W2EtdgmH8dq3/does-gpt-2-understand-anything-1" rel="nofollow ugc">post on Less Wrong</a> last week about whether GPT-2 understands the meaning of anything. For a functionalist definition of &#8220;understands&#8221; I come down in favor, of at least some things.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-avorobey odd alt depth-2" id="li-comment-838498">
		<div id="comment-838498" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/56bfabc94e6197ec47e7e972bc72995c?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Anatoly</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838498">
			January 7, 2020 at 5:04 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a rel="nofollow"href='https://nostalgebraist.tumblr.com/post/189965935059/human-psycholinguists-a-critical-appraisal' rel="nofollow ugc">This nostalgebraist post</a> about GPT-2 and what it means for linguistics also seems relevant.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-akhorahil even depth-2" id="li-comment-838511">
		<div id="comment-838511" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c2624d82833c8dc8279f061d58a2e93a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Akhorahil</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838511">
			January 7, 2020 at 5:50 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think (with Dennett) that it&#8217;s productive to talk about &#8220;competencies&#8221; in situations like this (&#8220;competence without comprehension&#8221;). &#8220;Understanding&#8221; just muddles the waters.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-ldsgsm odd alt thread-even depth-1" id="li-comment-838510">
		<div id="comment-838510" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/12f925e0340aadecddc25887b615278b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/12f925e0340aadecddc25887b615278b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Joseph Greenwood</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838510">
			January 7, 2020 at 5:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Your folk music example got me wondering&#8230; how do intellectual property laws interact with artificial intelligence? If I used GPT-2 to produce music that was good enough [for whatever purpose], would I be able to copyright it? What about the makers of GPT-2?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-toastengineer even depth-2" id="li-comment-838524">
		<div id="comment-838524" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838524">
			January 7, 2020 at 6:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I-Am-Not-A-Lawyer-But, my understanding is that the current U.S. legal distinction of whether or not something is a copyrightable original works is whether non-trivial decisions were involved in its creation. So <i>curated</i> output would almost definitely be copyrightable by the curator.</p>
<p>Raw, uncurated output&#8230; the court would probably have to decide. We might even end up in Measure Of A Man territory where lawyers have to argue over whether the AI&#8217;s decisions count as &#8220;non trivial decisions.&#8221;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern odd alt depth-2" id="li-comment-838567">
		<div id="comment-838567" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838567">
			January 7, 2020 at 7:45 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You probably would be able to copyright it if you exercise some sort of editorial discretion by selecting it out of a otherwise-uncopyrightable dump: <a rel="nofollow"href="https://www.gwern.net/Faces#faq" rel="nofollow ugc">https://www.gwern.net/Faces#faq</a> The makers of GPT-2 could only have copyright if they had included a requirement to that effect in the original code &amp; model license, but since OA released it under a FLOSS license, that&#8217;s not an issue.</p>
<p>(If anyone is worried about my folk music selections &#8211; all CC-0, so no worries.)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-smilerz even depth-2" id="li-comment-838636">
		<div id="comment-838636" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/869a0101cd65ed1328d45b98f558c790?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">smilerz</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838636">
			January 7, 2020 at 9:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>According to the <a rel="nofollow"href="https://www.copyright.gov/comp3/chap300/ch300-copyrightable-authorship.pdf" rel="nofollow ugc">US Copyright Office</a>:</p>
<blockquote><p>the Office will not register works produced by a machine or mere mechanical process that operates randomly or automatically without any creative input or intervention from a human author.</p></blockquote>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-toastengineer odd alt thread-odd thread-alt depth-1" id="li-comment-838527">
		<div id="comment-838527" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/00a34191d4cd325019288e7ba41c2595?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">toastengineer</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838527">
			January 7, 2020 at 6:30 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p><a rel="nofollow"href="https://www.youtube.com/watch?v=DpXy041BIlA" rel="nofollow ugc">If only this had been around back when Tom 7 was doing Elo World.</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-george3d6 even thread-even depth-1" id="li-comment-838532">
		<div id="comment-838532" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/27a21c12891c306f4701d745a1e08f3f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/27a21c12891c306f4701d745a1e08f3f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">George3d6</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838532">
			January 7, 2020 at 6:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I would say that &#8220;how impressed&#8221; you should be depends on how much you trained the ML algorithm.</p>
<p>For example, protein folding is arguably much more complex than chess in many respects, and it&#8217;s been tackled by neural networks since late 2017 to my knowledge (e.g.: <a rel="nofollow"href="https://www.nature.com/articles/s41467-019-11994-0" rel="nofollow ugc">https://www.nature.com/articles/s41467-019-11994-0</a>).</p>
<p>Most papers use residual CNNs (read: all papers that I read on the subject, including the most famous one from deepmind). I don&#8217;t see any particular reason to believe that residual CNNs are fine-tuned for these sort of problem, the architecture was designed for image classification and people seem to get decent results without much tweaking.</p>
<p>Would one design a residual CNN to play chess ? No&#8230; mainly because it would be very tedious and expensive due to how it&#8217;s inputs and outputs are structured. But could it be done, yes, certainly, it would just be kinda silly to do so when there are better architectures.</p>
<p>Now, if this is a GPT-2 network trained for something completely different, and it required to training whatsoever to play chess, I would call that impressive. However, if it is a pretty trained GPT-2 network that was then additionally trained to play chess and/or one trained from scratch to play chess&#8230;. then it&#8217;s just a very bad choice for training a chess playing model, but the fact that it works is not surprising. Neural networks are general function estimators, the idea that an architecture can generalize to multiple unrelated tasks is at the core of why we like them, it shouldn&#8217;t come as a surprise.</p>
<p>So I think more information as to how it has been trained are required for this article to have any meaning.</p>
<p>As it stands, if the network was indeed trained as a whole to play chess I would call this result expected, boring and somewhat deceitful in the way it&#8217;s presented.</p>
<p>If the Transform network was pre-trained on wiki-text and a chess-playing head was trained on top of it (i.e. a smaller network was attached to GPT-2 and it was the one deciding the actual move based on the &#8220;interpretations&#8221; given by passing the board&#8217;s state or a series of previous movements through GPT-2), the above statement still holds, but depending on training time and ability of the network this finding might be &#8220;interesting&#8221; but certainly not ground-breaking or unexpected.</p>
<p>If this is a pre-trained GPT-2 network that never learned played chess I would say it&#8217;s pretty damn interesting that it&#8217;s able to do this.</p>
<p>But I think this piece of information should be made explicit, I would indeed beg you to do so.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-exa odd alt depth-2" id="li-comment-843485">
		<div id="comment-843485" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/47e64bcea180e1afad9226ec70779d99?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/47e64bcea180e1afad9226ec70779d99?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Exa</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-843485">
			January 20, 2020 at 1:30 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Regarding &#8220;Would one design a residual CNN to play chess ? No… &#8221;</p>
<p>You may be interested in Leela Chess Zero, which is currently either the strongest or second-strongest chess engine depending on which tournament you look at, and which does in fact use a deep residual convolutional network for its evaluation function and to direct its search.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gbdub even thread-odd thread-alt depth-1" id="li-comment-838533">
		<div id="comment-838533" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2f70a9fdb7d9fc387fc42170528bed93?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">gbdub</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838533">
			January 7, 2020 at 6:40 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>So GPT-2 can “play chess” for a definition of “play chess” that is essentially “repeats common opening and mid game lines, as long as somebody who actually knows the rules of chess is holding its hand to sort out the gibberish”. Honestly this makes me downgrade my opinion of GPT-2, because, now that it’s applied to a “simpler” problem than “all of human language”, I feel like I can see what’s really going on&#8230; and it’s a neat trick but only a neat trick. </p>
<p>If you told me that you had a program that sorted through a huge pile of data, looked for patterns, and then responded to a prompt with the next likely step in the pattern, and the “pile of data” you had given it was “games of chess presented in standard text notation”&#8230; this is kind of exactly how I would have predicted it would work (and fail). I’m not sure I understand the shock and awe over this result. </p>
<p>I think the reaction Scott is having is something like “if it got this good at chess in a week, think how good it could be in a month!” But the answer is, “probably about as good as it is now”, because I’m guessing in a week it already processed plenty of data to catch all the common patterns, and it will need larger and larger data sets to see any novel patterns. The scary version of AGI is supposed to learn and improve faster and faster, but GPT-2 is the opposite, because the more things it knows in a domain, the larger the chunk of data it needs to learn the next thing. And the more complex a domain is, the worse this problem gets. </p>
<p>I think GPT-2 is really interesting for what it can teach us about language. Namely, that there  are a lot of subtle rules and patterns in language that may be hard to articulate but are easy to know when they are missing. But “knowing the patterns” is not all it takes to produce coherent text. Then again, being just a little off from expected patterns makes things sound poetic. </p>
<p>But unfortunately the other main thing I feel like I’m learning from the breathless GPT-2 coverage is that lots of people are all aboard the imminent AGI hype train and will latch onto anything that confirms those biases.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-keaswaran odd alt depth-2" id="li-comment-838630">
		<div id="comment-838630" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7fb064c6d944bfa09462747b8149a945?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7fb064c6d944bfa09462747b8149a945?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">keaswaran</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838630">
			January 7, 2020 at 9:29 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>In the poetry case, it really helps that there is a relatively short finite bound to how far back it has to look to make things work. All that matters is keeping the meter of the previous line and rhyming with the line before that. A Markov chain can manage that.</p>
<p>But with chess, it needs to remember what piece is on each square, even if that piece hasn&#8217;t been moved in dozens of turns. There&#8217;s no bound to how far back it might have to remember.</p>
<p>Adding a representation of the board state to each move, so that it can work from the present state, would definitely help. But it would also help the storytelling version of GPT2 if it had a representation of the narrative world to hold onto, to keep track of the Chekhov&#8217;s guns that were set up in scene 1 and the plots that were being hatched.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-eric23 even depth-2" id="li-comment-838857">
		<div id="comment-838857" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ed0b2a6757c7515c4f9c529b2eb08ae3?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ed0b2a6757c7515c4f9c529b2eb08ae3?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">eric23</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838857">
			January 8, 2020 at 12:59 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I agree. This is basically a lookup table for different chess situations. It can tell you what move people have most commonly played in the past in situations like this. It will never be able to supply the least bit of insight for a situation not in its database. It has zero creativity and will never be able to produce anything creative.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-andreyk odd alt thread-even depth-1" id="li-comment-838549">
		<div id="comment-838549" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5ef5c2bdd5eadc3d7e0725c5b9f73c9f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5ef5c2bdd5eadc3d7e0725c5b9f73c9f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">andreyk</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838549">
			January 7, 2020 at 7:20 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>One caveat to know wrt this being impressive/meaningful &#8212; Chess notation seems like a thing that is very easy thing to build a decent language model for (a model that predicts what would make sense to  say next based on data). Was GPT2 really the key here or could we have done this for a long time already? I bet the latter ; you can look back on <a rel="nofollow"href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="nofollow ugc">Andrei Karapathy&#8217;s post on RNNs</a> and see similarly impressive-seeming text generation, and you can go back to using older method , and older NLP models with markov models probably would have worked nicely too. If you&#8217;re fine tuning for it and your model is trained specifically to do this the model is not general, the method is.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-madqualist even thread-odd thread-alt depth-1" id="li-comment-838565">
		<div id="comment-838565" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2490b30292a8b897c3862f61c514441f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2490b30292a8b897c3862f61c514441f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">madqualist</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838565">
			January 7, 2020 at 7:43 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Very cool! Thanks for sharing! I&#8217;m a long time lurker of SSC but my fanaticism for Chess and machine learning encouraged me to finally register and post. Here&#8217;s the fragment of the game I shared with GPT before the machine learning platform had an error. I play white: 1.e4 e5 2. Nc3 Nf6 3. a3 d5 4. exd5 Nxd5 5. Bb5+ c6 6. Ba4 Bd6??</p>
<p>I am a reasonably strong (1800 USCF) chess player, but I intentionally played senseless moves in the opening, assuming the engine will make mistakes as soon as it gets out of book. Unfortunately, this happened sooner than I expected because Bd6?? is a serious mistake, dropping a piece.</p>
<p>My first impression is that GPT2 plays like a novice that has seen some grandmaster games and is trying to make moves that look like master moves without understanding chess principles. For example, it neatly tucks its bishop in the center, where it is full of latent mobility when the pawns shielding it spring forward, as masters often do, not noticing that it just dropped a piece. This is a little more interesting than it sounds at first because it&#8217;s actually not something traditional engines do when you tell them to play as weakly as a novice. Traditional engines will typically instead make a weird combination of reasonable moves and moves that just throw pieces away in a silly way no real person would, such as capturing a clearly protected pawn with a queen. While it&#8217;s cool that someone did make a shallow and humanlike chess GPT-2 implementation, shallow and humanlike is maybe not completely new because Leela Zero can already do this when you tell it to play at low strength.</p>
<p>My initial take is that this doesn&#8217;t change my point of view a whole lot, but it&#8217;s cool that someone did this. If someone asked me, &#8220;They&#8217;re gonna feed PGNs to GPT-2, how well do you think it&#8217;ll play?&#8221; I would probably have guessed at superficial moves. Actually, this reminds me of the flaws in its writing, where it describes physically impossible structures with correct grammar. Its chess playing style is sort of to construct these structures that look competent on the edifice but which are riddled with mistakes as soon as you get closer. For now, I&#8217;m more impressed by whoever had the creativity to think of feeding it PGNs in the first place than the quality of its moves, but we&#8217;ll see if that changes in the future!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-kaznatcheev odd alt thread-even depth-1" id="li-comment-838566">
		<div id="comment-838566" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://egtheory.wordpress.com/' rel='external nofollow ugc' class='url'>Artem Kaznatcheev</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838566">
			January 7, 2020 at 7:44 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>As I commented on Reddit, this is cool stuff but I think it is unreasonable to say that this system has &#8220;no concept of space&#8221; or &#8220;doesn’t even have a concept of 2D space&#8221;. The chess notation used hard-codes a concept of 2D space in how it labels positions. You could test experimentally if this is vital or not: instead of having &#8216;a3&#8217; and &#8216;a7&#8217; share a column and &#8216;a3&#8217; and &#8216;d3&#8217; share a row, just permute the labels of the squares randomly in the training data (and in how the game is processed when the system plays). For example, have a dictionary that sets &#8216;a3&#8217; be &#8216;d2&#8217; for all occurrences, &#8216;a7&#8217; be &#8216;e4&#8217;, and &#8216;d3&#8217; be &#8216;f1&#8217; or any other random relabeling of all squares that breaks the logical structure of the notation. If GPT-2 is really not using the space concept we built into the notation then it should have no more difficulty learning and then playing through this dictionary. I suspect that GPT-2 will struggle much more to play without this good notation. In other words, we need to be mindful of the knowledge that our smart representations encode.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern even depth-2" id="li-comment-838568">
		<div id="comment-838568" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838568">
			January 7, 2020 at 7:50 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>As I understand it, attention is nonlocal. The sequence input labeling doesn&#8217;t enforce any kind of 2D (or 3D, for that matter, or N-D, if you&#8217;re using Transformers on image data or multidimensional data); it merely annotates it with numbers like sin and expects the Transformer to learn how to understand the positional encoding. It&#8217;s <i>because</i> it&#8217;s permutation-invariant that you have to add those positional encoding to make it possible to understand that different positions mean different things&#8230; The dimensionality is not hardwired in the way locality is hardwired in to convolution kernels which can only look at nearby pixels: a Transformer head can unite points from arbitrarily far apart in the input, if it has learned to. So any sense of locality in a 1D sequence, or 2D for that matter (for if FEN board states are added), has to be learned.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-kaznatcheev odd alt depth-3" id="li-comment-838584">
		<div id="comment-838584" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://egtheory.wordpress.com/' rel='external nofollow ugc' class='url'>Artem Kaznatcheev</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838584">
			January 7, 2020 at 8:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t know if we are talking on the same topic or not. </p>
<p>Standard chess notation has 2D space hardcoded into it. This hardcoding works for any learner that thinks that &#8216;a3&#8217; is more like &#8216;a7&#8217; than &#8216;f2&#8217; because &#8216;a3&#8217; and &#8216;a7&#8217; share a character while &#8216;a3&#8217; and &#8216;f2&#8217; do not. GPT-2 is built around the importance of shared characters, so it sees &#8216;a3&#8217; as more similar to &#8216;a7&#8217; than &#8216;f2&#8217;, thus it can easily get the 2D structure of the game from the structure of how the board positions are represented. If we instead force GPT-2 to work in a &#8216;foreign language&#8217; where the square that used to be a3 is now always called &#8216;d5&#8217; and the square that used to be a7 is now called &#8216;e4&#8217;  and f2 is now called &#8216;b6&#8217; then the spatial structure of the encoding is lost, since &#8216;d5&#8217; (a3) and &#8216;e4&#8217; (a7) do not have a character in common to easily reveal that they are on the same column and thus somehow &#8216;more related&#8217; to each other than to &#8216;b6&#8217; (f2).</p>
<p>This has nothing to do with attention. Unless you are making some other point, but then I don&#8217;t understand how it relates to my original comment.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern even depth-4" id="li-comment-838588">
		<div id="comment-838588" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838588">
			January 7, 2020 at 8:34 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yes, but why are &#8216;d&#8217; and &#8216;e&#8217; more closely related than &#8216;a&#8217; and &#8216;z&#8217;? What makes &#8216;a3&#8217; more like &#8216;a7&#8217; than &#8216;f3&#8217;? Those are arbitrary symbols. (By the way, note that it&#8217;s not even clear that they would be encoded as the 2 numbers corresponding to (a,3), because of GPT-2&#8217;s use of BPEs rather than characters. &#8216;a3&#8217; and &#8216;a7&#8217; might be encoded as, say, the integers 23500 and 331. And what a move is encoded as might even change with context, because that&#8217;ll change previous BPEs&#8230; Not a fan of BPEs, they&#8217;re just a crutch for GPT-2&#8217;s limited context window.)</p>
<p>It&#8217;s all arbitrary and has to be learned. Of course, once you learn it, then it&#8217;s fine, but that&#8217;s trivially true of anything with structure: once you learn the structure, you understand the structure. But GPT-2 gets no particular inductive bias from attention like you seem to think it does. Compare with convolutions where locality is baked in and it starts off biased towards finding the locality structure which we know exists in pixel data.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-kaznatcheev odd alt depth-5" id="li-comment-838616">
		<div id="comment-838616" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/7c33a18c2c5a3836ff6661e28f22ee6f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://egtheory.wordpress.com/' rel='external nofollow ugc' class='url'>Artem Kaznatcheev</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838616">
			January 7, 2020 at 9:10 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt;Yes, but why are ‘d’ and ‘e’ more closely related than ‘a’ and ‘z’? What makes ‘a3’ more like ‘a7’ than ‘f3’? </p>
<p>I didn&#8217;t say that &#8216;d&#8217; and &#8216;e&#8217; are more closely related than &#8216;a&#8217; and &#8216;z&#8217; nor that &#8216;1&#8217; and &#8216;2&#8217; are more closely related than &#8216;1&#8217; and &#8216;9&#8217; (of course, it&#8217;d be even more of an advantage if this was also baked in). Most importantly, I didn&#8217;t say that &#8216;a3&#8217; is more like &#8216;a7&#8217; than &#8216;f3&#8217; &#8212; in both cases they share one character in common (and in space, they share one dimension in common, that is the regularity in question); that is why I used the example of &#8216;f2&#8217; (and not &#8216;f3&#8217;) where no character is in common with &#8216;a3&#8217; (and thus no dimension is in common). </p>
<p>But sharing one character in common is recognizes by GPT-2 and that is what encoded row and column structure. My claim is that if that part of the encoding is broken then I expect that GPT-2 will perform significantly worse.</p>
<p>Replacing characters by their ascii or any other single-character level homomorphism does not (significantly) affect this, since &#8216;a3&#8217; and &#8216;a7&#8217; will still map to &#8216;blahFOOB&#8217; and &#8216;blahGLIK&#8217; and the &#8216;blah&#8217; will be shared and reveal that the two points share a dimension. </p>
<p>To break this structure you need to consider a permutation on the tile labeling (i.e. on pairs of characters) that does not preserve row and column structure. By not preserve row and column structure, I mean that in the new unbiased representation: having a character in common in the representation should not (systematically) mean that the two positions have a common dimension (row or column). In such a representation, we can eliminate baking in 2D structure of the board and thus really claim that we didn&#8217;t &#8216;build in&#8217; space.</p>
<p>By the standard chess position representation produces the inductive bias (of easily identifiable common row/column) that I am talking about. And based on this, I would, for example, expect GPT-2 to attempt more illegal moves with bishops than with rooks as it is being trained.</p>
<p>I don&#8217;t understand the part of your comment about attention. It would help me if you clarified more by what you mean there.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-gwern even depth-5" id="li-comment-838673">
		<div id="comment-838673" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838673">
			January 7, 2020 at 10:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>But sharing one character in common is recognizes by GPT-2 and that is what encoded row and column structure. My claim is that if that part of the encoding is broken then I expect that GPT-2 will perform significantly worse.</p></blockquote>
<p>As I said, it is probably not even true that GPT-2 can &#8216;see&#8217; that due to the encoding, and even if it can, I don&#8217;t see how it produces inductive biases like implied.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-tomcullis odd alt thread-odd thread-alt depth-1" id="li-comment-838571">
		<div id="comment-838571" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/90a4277ab790835eb27c70245fa4b6c7?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/90a4277ab790835eb27c70245fa4b6c7?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://sebwassl.blogspot.com' rel='external nofollow ugc' class='url'>baconbits9</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838571">
			January 7, 2020 at 7:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It sounded impressive to me at first until I read the tweets updating the progress, then it reminded me of teaching my kids to play chess which I just started doing.  I actually lost to my 4 year old in her first game, as I was focusing on what she was doing, making sure she made legal moves, and giving her a few choices for good moves when she kept making illegal ones.  In reality I am not good at chess, haven&#8217;t played a game against a person who knows how to play for a decade and was basically putting more effort into her side of the board than mine so I lost.  </p>
<p>If you are adding lines of code to eliminate illegal moves you are basically peaking over to the other side and helping them out, basically playing against a machine + a human every time, and that is a lot less impressive and important.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bbenzon even thread-even depth-1" id="li-comment-838572">
		<div id="comment-838572" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e01704aab56a6abc54ecaa750f98e7b5?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e01704aab56a6abc54ecaa750f98e7b5?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='http://new-savanna.blogspot.com/' rel='external nofollow ugc' class='url'>BBenzon</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838572">
			January 7, 2020 at 7:58 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;How impressed should we be that the same AI can write poems, compose music, and play chess, without having been designed for any of those tasks?&#8221;</p>
<p>Which list is longer: the list of 1) things an AI can do at a some level (sometimes crude, sometimes not so crude) without having been designed for them or 2) the list of simple things humans do well (without having been programmed?) that the most sophisticated AI flops at?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-nikkoupostbox odd alt thread-odd thread-alt depth-1" id="li-comment-838579">
		<div id="comment-838579" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2c8f7ba18675e725351916f7e4f96e3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2c8f7ba18675e725351916f7e4f96e3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Alexander Lyzhov</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838579">
			January 7, 2020 at 8:17 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I really liked earlier posts about GPT-2 but I do not get this post at all.</p>
<p>Neural network is a general function approximator, so of course it would learn to play chess if you train it to play chess with chess data, regardless of how chess moves are encoded. The surprising allure of GPT-2 is that it learns to solve unstated linguistic problems given just the structure of language in the form of unsupervised corpuses, but these experiments do not touch that. The only interesting thing about toy experiments with music and chess would be a gain from transfer learning compared to learning from clean slate with optimal models but I don&#8217;t see this mentioned.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein even depth-2" id="li-comment-838668">
		<div id="comment-838668" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838668">
			January 7, 2020 at 10:31 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Using the fact that DNNs are universal function approximators to explain <i>anything</i>, really, is a pet peeve of mine. Sure, for each (nice enough) function (on a nice enough set) there exists some deep network that approximates it well. This does not imply that this particular architecture is suitable (most universal approximation theory allows the networks to grow extremely fast to reach that goal), that the function in question is nice enough in a relevant sense (deep networks suck at approximating division and matrix inversion &#8211; or anything far from being piecewise linear with a sane amount of pieces, just to name a natural class of problematic functions), that the &#8220;correct&#8221; approximation is reachable with any reasonable training procedure, etc.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-nikkoupostbox odd alt depth-3" id="li-comment-839453">
		<div id="comment-839453" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/2c8f7ba18675e725351916f7e4f96e3e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/2c8f7ba18675e725351916f7e4f96e3e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Alexander Lyzhov</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839453">
			January 9, 2020 at 8:06 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You are right that we need the right inductive bias, the right optimization dynamics, the right data curriculum, etc, to get the desired performance. It&#8217;s just that in this particular case (transformer, SGD, lots of shuffled chess data) I have a strong intuition that the model is practically a near-universal approximator in the sense that it approximates any reasonably structured and easy-to-train-on function (like &#8220;good chess move&#8221; function) with a more-or-less reasonable performance (like the performance that was shown in the post).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-thisheavenlyconjugation even depth-4" id="li-comment-839724">
		<div id="comment-839724" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839724">
			January 9, 2020 at 3:05 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Your intuition is wrong though, because &#8220;good chess move&#8221; is actually incredibly difficult to approximate, and that&#8217;s not what this does anyway.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-thisheavenlyconjugation odd alt thread-even depth-1" id="li-comment-838642">
		<div id="comment-838642" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838642">
			January 7, 2020 at 9:48 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This seems superficially cool, but I&#8217;m not sure if it actually is. Is this doing anything significantly different to &#8220;memorize openings from games, play moves from those if you can, otherwise play a random legal move&#8221;?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-admin bypostauthor even depth-2" id="li-comment-838648">
		<div id="comment-838648" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c66389ad74ef2a291c76e87c981b0391?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Scott Alexander</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838648">
			January 7, 2020 at 9:54 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think so. Before playing GPT-2, I accidentally loaded the notebook wrong and played an earlier version of the code that was just testing the interface and made random moves. It was terrible and I complained to Gwern that GPT-2 couldn&#8217;t play chess at all and the project had been a failure.</p>
<p>When I fixed my error and played the real bot, it felt very different. If I threatened a piece, it would move that piece out of the way. If I blundered and left a piece where it could capture it, it would capture the piece. I can&#8217;t say much more than that because *I&#8217;m* not much better than that, but I played randombot and randombot was definitely worse (including in midgame).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-b_epstein odd alt depth-3" id="li-comment-838675">
		<div id="comment-838675" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8114dd22ae4f87d31afa7110dfa95061?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">B_Epstein</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838675">
			January 7, 2020 at 10:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>And yet every game I had that did not follow a standard path was over a few moves in exactly due to not moving threatened pieces or blundering them away. So &#8220;play typical moves in typical positions whether the position is, in fact, typical or not&#8221; seems an apt description.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-thisheavenlyconjugation even depth-3" id="li-comment-838709">
		<div id="comment-838709" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838709">
			January 7, 2020 at 11:41 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;ve played a game now and remain unconvinced. Look at this game &#8220;1.h3 d5 2.h4 Nf6 3.Rh3 e6 4.Na3 c5 5.Nb5 Nc6 6.Nd6+ Bxd6 7.Ra3 a6 8.d4 cxd4 9.Qxd4 O-O 10.Bd2 b5 11.Ba5 Qc7 12.Bxc7 Bxc7 13.&#8221; where I played a load of nonsense at the start. GPT-2 completely ignored the fact that my rook and queen were vulnerable for several moves and likewise didn&#8217;t notice me threatening its queen. It did recapture when I took its queen though, so I will have to update my hypothesis to something like &#8220;play memorised openings, or a random move that was a response to the last human move in a game I saw, or failing that a totally random move&#8221;.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-broblawsky odd alt depth-4" id="li-comment-838746">
		<div id="comment-838746" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5b447d08bcba1a44c7754c66890a2787?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5b447d08bcba1a44c7754c66890a2787?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">broblawsky</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838746">
			January 7, 2020 at 12:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s more like that GPT-2 compares whatever the board state currently is to its database of known human-run games and picks whatever response gave the best result for that board state. It doesn&#8217;t have the ability to recognize concepts like &#8220;my enemy&#8217;s rook is vulnerable&#8221;; what it can do is recognize that human players made certain moves in board states when an enemy rook is vulnerable and employ those. If a board state with a vulnerable rook didn&#8217;t show up in its database, it won&#8217;t be able to pull out an appropriate response.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-thisheavenlyconjugation even depth-5" id="li-comment-838753">
		<div id="comment-838753" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838753">
			January 7, 2020 at 12:57 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Well kind of, except it&#8217;s not picking &#8220;best&#8221; responses but rather &#8220;most similar to training data&#8221;, and it&#8217;s not considering board state but rather history (and my contention is that considering just the last move rather than the whole history would not significantly change its behaviour (in the sense of my-fake-GPT-2 being distinguishable from the real thing by a human who plays both, not in the sense of producing the exact same moves)).</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zeromh odd alt depth-2" id="li-comment-838692">
		<div id="comment-838692" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838692">
			January 7, 2020 at 11:03 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&#8220;Is this doing anything significantly different to “memorize openings from games, play moves from those if you can, otherwise play a random legal move”?&#8221;</p>
<p>I think it obviously must be. The algo has learned *some kind* of feature representation of the input; it isn&#8217;t going straight from raw game state to final output (as a single-layer neural network would have to).</p>
<p>Even if a given feature is as dumb as &#8220;moving a white pawn after a black knight was moved tends to be followed by black moving its knight some more&#8221;, that&#8217;s still an abstraction of multiple different game states that it trained on. It&#8217;s not a memorized sequence; it&#8217;s a principle learned from sequences it trained on.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-thisheavenlyconjugation even depth-3" id="li-comment-838699">
		<div id="comment-838699" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9bb96d6fa4258ace9cf1c32bf9f4f083?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">thisheavenlyconjugation</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838699">
			January 7, 2020 at 11:14 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>I think it obviously must be.</p></blockquote>
<p>Why? Do you agree that it would be straightforward to train an NN to do what I describe? If so, how do you know that this isn&#8217;t doing that?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-zeromh odd alt depth-4" id="li-comment-838719">
		<div id="comment-838719" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838719">
			January 7, 2020 at 12:07 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I agree that a deep enough NN* could memorize a training set. I don&#8217;t have a great understanding of GPT-2&#8217;s architecture to say that it is too deep or not deep enough to do this, so let me walk back my previous claim. I&#8217;m not sure whether it has learned abstract features or not.</p>
<p>Barring looking at the NN weights, I guess the best way to test this would be to see if GPT-2 ever produces an output to a move/sequence-of-moves that it didn&#8217;t see in training.</p>
<p>Also, we might ask to what extent the engineer controlled for overfitting. I reckon that if the NN memorized the training data, this would have been noticeable when looking at out-of-sample test performance.</p>
<p>* For whatever definition of &#8220;deep&#8221; makes sense given GPT-2&#8217;s architecture</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-honoredb even thread-odd thread-alt depth-1" id="li-comment-838647">
		<div id="comment-838647" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/43694d66c51fbbc57544d7ca18ed160b?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/43694d66c51fbbc57544d7ca18ed160b?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">honoredb</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838647">
			January 7, 2020 at 9:53 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think a key benchmark here is whether GPT-2 can do better than a program like <a rel="nofollow"href="https://codegolf.stackexchange.com/questions/195032/totally-blind-chess/195056" rel="nofollow ugc">the ones in this contest</a> that just emit a series of moves, which a controller filters for legality, without getting any feedback on which ones were legal or what the opponent did. If it can do better even when it gets beyond standard openings, that proves that it&#8217;s able to do something like reacting to the board state. If it can&#8217;t, it&#8217;s really just emitting a series of plausible chess moves and the legality controller is doing all the real work.</p>
<p>Conveniently the king of the hill there is in Python so it might not be too hard to arrange a match.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-drocta odd alt depth-2" id="li-comment-839105">
		<div id="comment-839105" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/9ab8cb34df6b8eab0cf18471915efb5f?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/9ab8cb34df6b8eab0cf18471915efb5f?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">drocta</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839105">
			January 8, 2020 at 12:22 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This seems like quite a good point to me!<br />
Fortunately, the controller for that competition is also in python!</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-rocoulm even thread-even depth-1" id="li-comment-838653">
		<div id="comment-838653" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/48c600fdf753c7ca520ad18a224fd7b0?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/48c600fdf753c7ca520ad18a224fd7b0?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">rocoulm</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838653">
			January 7, 2020 at 10:01 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Speaking of AI-generated music, I&#8217;ve wondered before what an AI would do is trained on something like raw format audio &#8211; training it on individual notes and melodies is cool, but what sort of sound would this have? Completely unintelligible noise? Or fragments of natura-lish acoustic sounds jumbled together? Or something that could actually be called &#8220;music&#8221; (probably not this one)? Speculation is welcome.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern odd alt depth-2" id="li-comment-838678">
		<div id="comment-838678" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838678">
			January 7, 2020 at 10:47 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Yeah, it&#8217;s been done. Look at the various WaveNet and audio synthesis papers. When you train on raw waveforms, you can&#8217;t see large temporal windows because you have to synthesize at the millisecond level, so when you train on, say, classical music corpuses, you get wandering notes. The audio sounds very realistic to me as a non-musician, I definitely can&#8217;t tell between real and fake piano notes, but you won&#8217;t be impressed by the overall musical piece. In comparison, if you train at a higher level on ABC format, for example, you get very clear melodies, progressions, themes, endings, etc, but of course the model can&#8217;t synthesize the raw audio corresponding to the short textual scores. OA&#8217;s MuseNet is somewhat in between: it works on the MIDI level, intermediate between WAV and ABC, and gives intermediate results in terms of raw audio quality vs overall music piece quality.</p>
<p>I don&#8217;t see any particular reason you can&#8217;t have a single model which goes the full range at some point, but it&#8217;ll be expensive to train because it&#8217;ll need to be big and train a ton in order to gradually go from realistic audio up to higher-level long-range music quality.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-axiomata even thread-odd thread-alt depth-1" id="li-comment-838685">
		<div id="comment-838685" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/307754c3361321ab09efdfc37836e369?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/307754c3361321ab09efdfc37836e369?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Axiomata</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838685">
			January 7, 2020 at 10:52 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>&gt; something with no auditory qualia</p>
<p>[citation needed]  😉</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-bugmaster odd alt depth-2" id="li-comment-838826">
		<div id="comment-838826" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Bugmaster</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838826">
			January 7, 2020 at 3:56 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I&#8217;m a human (*), and I don&#8217;t think I have auditory qualia either (because the concept of qualia doesn&#8217;t make sense), so I guess GPT-2 and I are on a level playing field 🙂</p>
<p>(*) Though obviously you only have my word for it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern even depth-3" id="li-comment-838847">
		<div id="comment-838847" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838847">
			January 7, 2020 at 9:37 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>(*) Though obviously you only have my word for it.</p></blockquote>
<p>Indeed, how <i>do</i> we know this comment isn&#8217;t GPT-2 generated?</p>
<p>On the bright side, that question will get even harder to answer once our SubredditSimulator model goes live (1.5b, and trained with even more subreddits than the original SubSim GPT-2 model). We finished training it and sent it off to the SubSim guy a few days ago, so it should go live whenever he has time to hook it up and start generating new comments&#8230;</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-garrett odd alt thread-even depth-1" id="li-comment-838689">
		<div id="comment-838689" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b0e8f7429a6351d367e92a8fed85020e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b0e8f7429a6351d367e92a8fed85020e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Garrett</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838689">
			January 7, 2020 at 10:56 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s impressive because the system is able to generate good outputs despite not being designed specifically to do so. But it only does so because effectively the entire corpus of known existing chess games were fed into the system. A human can learn to play chess (probably not well) by reading a single book and playing a much smaller number of games.</p>
<p>All of these AI systems with impressive outputs are working on data sets which would be impossibly large for a human being to process, ever. Imagine that all of the matches which went into training this AI were printed out in book format. Assuming that you didn&#8217;t actually read the text but merely turned the pages one at a time at the fastest speed reasonable, how long do you think it would take to go through the entirety of the data being processed? These all require a *huge* volume of data.</p>
<p>One of the key reasons that AlphaGo was able to perform so well is because it was able to generate an almost-unlimited set of labelled data by playing itself at computer speed. Repeat over and over and you get better and better quality training data to operate against. But it applies only the cases where the board state and legal move state is well-defined and finite. Google, with all its data, still has trouble <a rel="nofollow"href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/" rel="nofollow ugc">distinguishing black people from gorillas</a>, though current image search appears to be doing better.</p>
<p>I would assume that for most cases the open-ended performance is not exponential improvement, but sub-linear improvement. Sure, for the early phases you get really good and really useful results. In some cases you might be able to get to the point that you&#8217;re better than humans with enough data at specific tasks like <a rel="nofollow"href="https://ai.googleblog.com/2018/12/improving-effectiveness-of-diabetic.html" rel="nofollow ugc">rating diabetic retanopathy</a> on a 1-5 scale. But after initial growth simply throwing more data at the problem gets marginal improvements. This bodes well for AI safety of known (and fascinating) AI methodologies.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-zeromh even depth-2" id="li-comment-838704">
		<div id="comment-838704" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/50cbc2a0797d3d36c77eb9eeaeefc6ad?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Tim Martin</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838704">
			January 7, 2020 at 11:28 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>All of these AI systems with impressive outputs are working on data sets which would be impossibly large for a human being to process, ever.</p></blockquote>
<p>That&#8217;s true. Also true is that all of these AI systems lack the context that humans have which allow us to do well with less data. We are taught that the white pawn on the a-file has the same abilities as the white pawn on the b-file, or as the black pawn on the b-file. We are told the object of the game is checkmate. GPT-2 and AlphaZero are not given that information.</p>
<p>A human reading a chess book is also instructed in useful *features* for our internal algorithms to use, such as &#8220;control the center,&#8221; &#8220;certain pieces are worth more,&#8221; and &#8220;protect your king.&#8221; Even the basic concept of &#8220;control&#8221; is itself a feature &#8211; an abstraction of many game states that AI has to learn entirely through exploration.</p>
<p>I don&#8217;t know how much of AI&#8217;s need for huge training data is explained by the lack of context or prior information, but it&#8217;s a contributing factor for sure. Humans, by the way, do <a rel="nofollow"href="https://rach0012.github.io/humanRL_website/" rel="nofollow ugc">really poorly on games</a> when we don&#8217;t get to use prior information.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-zby odd alt thread-odd thread-alt depth-1" id="li-comment-838733">
		<div id="comment-838733" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/ff3f023495d60960f2db96f696338e71?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/ff3f023495d60960f2db96f696338e71?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://medium.com/@zby' rel='external nofollow ugc' class='url'>zby</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838733">
			January 7, 2020 at 12:28 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>There is a short story by Lem about a computer for typesetting newspapers which started finishing them (and predicting future). I don&#8217;t know if it was ever translated to English professionally &#8211; but I found this amateur translation: <a rel="nofollow"href="https://medium.com/@mwichary/one-hundred-and-thirty-seven-seconds-2a0a3dfbc59e" rel="nofollow ugc">https://medium.com/@mwichary/one-hundred-and-thirty-seven-seconds-2a0a3dfbc59e</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-bugmaster even depth-2" id="li-comment-838825">
		<div id="comment-838825" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Bugmaster</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838825">
			January 7, 2020 at 3:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Lem also wrote a story about a computer who learned to write poetry, and did it so well that it mesmerized the entire country into submission. I haven&#8217;t read the English translation, but the Russian versions of some of its poems are&#8230; superb 🙂</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-blindkungfumaster odd alt thread-even depth-1" id="li-comment-838770">
		<div id="comment-838770" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8d8645e14dcdc4c51bb73e224021ef24?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8d8645e14dcdc4c51bb73e224021ef24?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">BlindKungFuMaster</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838770">
			January 7, 2020 at 1:38 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I thought about training GTP-2 on chess games, glad somebody did it.</p>
<p>My guess is that this would only become really interesting if a big amount of compute would be invested. There are almost 1 billion games of chess available online. I assume this version has not been trained on more than a tiny fraction of them. Probably just on a couple of million games from freely available tournament games. Most of the 1 billion available games are online games, where the range of openings, strategies and level-of-play is much bigger. Maybe this would be enough to actually learn the rules of chess and maybe even learn to update an internal board and consequently stop making illegal moves. </p>
<p>Of course nobody will ever invest 40k of compute just to get a sub-par chess engine, but one of the interesting questions would be whether you could prime it on the rating to get stronger or weaker play. </p>
<p>Adding the game state would only invalidate the experiment as far as I&#8217;m concerned. Without tree search and with an architecture this badly suited to playing chess, you will never get a strong engine anyway.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-blindkungfumaster even thread-odd thread-alt depth-1" id="li-comment-838796">
		<div id="comment-838796" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/8d8645e14dcdc4c51bb73e224021ef24?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/8d8645e14dcdc4c51bb73e224021ef24?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">BlindKungFuMaster</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838796">
			January 7, 2020 at 2:23 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Here is an idea: Learn from games of random moves until it stops making illegal moves. This would probably be a better experiment to answer the question whether GTP-2 can learn a representation of the board. </p>
<p>It would also split the problem into two separate problems: Making legal moves and making moves that resemble good moves.<br />
Once it has mastered the first it can tackle the second.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-bugmaster odd alt thread-even depth-1" id="li-comment-838824">
		<div id="comment-838824" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/bd3feb70a6f6e5f20f761671d4ef386a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Bugmaster</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838824">
			January 7, 2020 at 3:47 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Like I said before, I feel like the poetry problem (and possibly also the music problem) had been solved from both sides. On the one hand, AI got much better at writing poetry. On the other hand, humans have essentially lost the ability to write good poetry, thus making it much easier for the AI to catch up.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-cronodas even thread-odd thread-alt depth-1" id="li-comment-838833">
		<div id="comment-838833" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/27e2e15e1c4001b387b6791a0b394979?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/27e2e15e1c4001b387b6791a0b394979?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Doug S.</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838833">
			January 7, 2020 at 5:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Back in 2005, someone did the same thing with a Bayesian spam filter, training it on strings of text representing chess moves.</p>
<p><a rel="nofollow"href="http://dbacl.sourceforge.net/spam_chess-1.html" rel="nofollow ugc">Can a Bayesian spam filter play chess?</a></p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-hnau odd alt thread-even depth-1" id="li-comment-838835">
		<div id="comment-838835" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/04f7b7665eb1626ff32138d4ccefd35e?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/04f7b7665eb1626ff32138d4ccefd35e?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">hnau</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838835">
			January 7, 2020 at 5:46 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Very cool. Since it&#8217;s biased toward more common sequences, I wonder how much better it gets when playing itself?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-alicrobsontramorgiblecunineyeary even thread-odd thread-alt depth-1" id="li-comment-838839">
		<div id="comment-838839" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/81b6aacd1c4656e00c61e41250011aea?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/81b6aacd1c4656e00c61e41250011aea?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">ALICrOBSonTRAmoRgiblEcunINEyEaRY</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838839">
			January 7, 2020 at 6:34 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You guys are wasting your time. This isn&#8217;t going to get anywhere. These things can&#8217;t even solve the simpler problem of complex multiplication, i.e. ((a, b), (c, d)) -&gt; (ac &#8211; bd, ad + bc). Feed it as many pairs as you want, it won&#8217;t get anywhere. If it can&#8217;t even do something as simple as figure out how to multiply complex numbers with 1.5B parameters then what point is there exploring what else it can do?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-oriscratch odd alt thread-even depth-1" id="li-comment-838840">
		<div id="comment-838840" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/f9a4f57f1f785adcfb62b37a034b0a9a?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/f9a4f57f1f785adcfb62b37a034b0a9a?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">oriscratch</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838840">
			January 7, 2020 at 6:49 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I know very little about the technicalities of ML, but has anyone tried testing GPT-2 on the classic problem of differentiating pictures? Something like getting a bunch of pictures of dogs and cats, translating them into strings of RGB values or something, appending -dog to the ends of dog strings and -cats to the end of cat strings, using that as training data, then giving GPT-2 a string without the -dog or -cat at the end and seeing if it manages to complete it somewhat correctly? (Or maybe just squares and triangles if dogs and cats are too hard). Sorry if this sounds dumb to anyone with more experience.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-gwern even depth-2" id="li-comment-838843">
		<div id="comment-838843" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b240aaab5e1897421d7a1933d0c510f4?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn"><a href='https://www.gwern.net' rel='external nofollow ugc' class='url'>gwern</a></cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838843">
			January 7, 2020 at 7:15 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>That wouldn&#8217;t work too well. GPT-2 can only &#8216;see&#8217; 1024 tokens at a time. So you could encode, say, a 32x32px image. The core technology of attention layers do, however, work <i>really</i> well both in conjunction with convolution layers and on their own for image generation (self-attention in SAGAN and BigGAN, or <a rel="nofollow"href="https://arxiv.org/abs/1912.12180v1" rel="nofollow ugc">https://arxiv.org/abs/1912.12180v1</a> <a rel="nofollow"href="https://openreview.net/forum?id=rkgNKkHtvB" rel="nofollow ugc">https://openreview.net/forum?id=rkgNKkHtvB</a> for autoregressive) and image classification (<a rel="nofollow"href="https://arxiv.org/abs/1904.09925" rel="nofollow ugc">https://arxiv.org/abs/1904.09925</a>). In fact, given the latter result showed improving performance for all-attention image classifiers with increasing data &amp; the &#8216;bitter lesson&#8217;, it would not surprise me if in 2020 we saw SOTA for image classification pass from convolutional neural networks like EfficientNet to self-attention-only NNs. (Maybe attention really is all you need&#8230;)</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-broblawsky odd alt depth-3" id="li-comment-839204">
		<div id="comment-839204" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/5b447d08bcba1a44c7754c66890a2787?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/5b447d08bcba1a44c7754c66890a2787?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">broblawsky</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839204">
			January 8, 2020 at 3:11 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>You could slice a larger picture into chunks, then train individual GPT-2 networks on each chunk, then have each chunk-analyzing GPT-2 network feed into an &#8220;overseer&#8221; GPT-2 network. I suspect that at that point the network starts automatically summoning Xzibit, though.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-error even thread-odd thread-alt depth-1" id="li-comment-838841">
		<div id="comment-838841" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/c2d87b446e48656a8ebe3eeef4cf95fb?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/c2d87b446e48656a8ebe3eeef4cf95fb?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Error</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838841">
			January 7, 2020 at 6:52 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>It&#8217;s not relevant to the post, but I&#8217;m curious: Do any chessplayers here share my strong preference for <a rel="nofollow"href="https://en.wikipedia.org/wiki/Descriptive_notation#Example" rel="nofollow ugc">descriptive notation over algebraic</a>?</p>
<p>It&#8217;s true that algebraic is less ambiguous, but I can read descriptive and keep a pretty good mental image of what&#8217;s going on. Its dying usage frustrates me.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-davidbahry odd alt thread-even depth-1" id="li-comment-838846">
		<div id="comment-838846" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/130b7edc07c924d3cdeb066fe07de2e2?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/130b7edc07c924d3cdeb066fe07de2e2?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">davidbahry</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838846">
			January 7, 2020 at 8:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>reminds me of stuff like <a rel="nofollow"href="https://people.seas.harvard.edu/~jones/cscie129/papers/stanford_info_paper/entropy_of_english_9.htm" rel="nofollow ugc">https://people.seas.harvard.edu/~jones/cscie129/papers/stanford_info_paper/entropy_of_english_9.htm</a>, which also captures statistical patterns (but not actually to the point of sustained coherence)<br />
if GPT-2 eventually cracks chess, I&#8217;d guess that says more about chess than it does about GPT-2</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-brassfjord even thread-odd thread-alt depth-1" id="li-comment-838870">
		<div id="comment-838870" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/b4379331139ad2246b4e7159f9392abb?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/b4379331139ad2246b4e7159f9392abb?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">Brassfjord</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838870">
			January 8, 2020 at 4:07 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I have the distinct feeling that if we ever come close to an AGI, it will come out of a competing and collaborating ecosystem of models like GPT-2. First a bunch of predictive models create a lot of ideas and then evaluating models disqualify those who breaks rules and rank the others. Then they all decide in some democratic way what to do or say, to best fulfill all of the goals (often somewhat contradictory) it has been given.</p>
<p>The reasoning behind the decisions will be fuzzy and sometimes wrong, but that&#8217;s just like us.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-matthewravery odd alt thread-even depth-1" id="li-comment-838893">
		<div id="comment-838893" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/e4372a20186ae32ec058902df9fbbe24?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/e4372a20186ae32ec058902df9fbbe24?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">matthewravery</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838893">
			January 8, 2020 at 6:18 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>This is more interesting in what it says about humans than its potential as &#8220;AI&#8221;. </p>
<p>It&#8217;s literally mimicking inputs. The only reason it &#8220;means&#8221; anything is because we ascribe meaning them. It&#8217;s fundamentally lacking part of the process of intelligence. </p>
<p>In each of the three examples you mentioned (poetry, music, chess moves), you&#8217;ve asked GPT-2 to attempt to mimic the inputs humans generate irrespective of the desired outputs. What you can learn from this is limited to (1) information about how humans generate inputs and (2) information about how humans interpret inputs in these contexts. </p>
<p>Poems are by their nature abstract, and typically have some interesting or novel turns of phrase. This means its easy for us to mistake the nonsense of GPT-2 with interesting or novel phrasing in &#8220;real&#8221; poetry. (Or maybe this means a lot of poetry is indistinguishable from nonsense? But that&#8217;s a commentary on poetry, not AI.)</p>
<p>Music has clear, recognizable patterns that recur and are played with in whatever genre you want to talk about. That That the AI fiddled with inputs and produced a few short (cherry-picked? IDK how representative the clips you selected were) that sound like something a human could have made isn&#8217;t that impressive to me. Can the AI differentiate between which clips it generates that sound &#8220;good&#8221; and which don&#8217;t? If a human has to do this, then I don&#8217;t see what we&#8217;ve gained. </p>
<p>The same is true for chess. This is basically a random move generator with a set of book openings. Where would this GPT-2-based algorithm fall in this set of <a rel="nofollow"href="https://youtu.be/DpXy041BIlA" rel="nofollow ugc">30 weird chess algorithms</a>? This thing doesn&#8217;t &#8220;play chess&#8221;. It dutifully reproduces a set of inputs that *look like* standard chess notation, and most of the time produces legal moves. This is only &#8220;playing chess&#8221; in our minds. This is like &#8220;playing chess&#8221; in the same way that <a rel="nofollow"href="https://en.wikipedia.org/wiki/Cargo_cult#Pacific_cults_of_World_War_II" rel="nofollow ugc">cargo cults</a> were doing air traffic control. In the same way that these cults weren&#8217;t able to produce aircraft dropping off jeeps, this approach won&#8217;t produce general intelligence.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-rachel even thread-odd thread-alt depth-1" id="li-comment-838914">
		<div id="comment-838914" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/151d19d592de984666089518e151c523?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/151d19d592de984666089518e151c523?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">rachel</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838914">
			January 8, 2020 at 7:27 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>On the one hand, this is really incredibly cool. On the other hand, it strikes me that GPT-2 is basically doing imitation learning, which works well in some domains but is generally considered to have serious limitations.</p>
<p><a rel="nofollow"href="https://medium.com/@jonathan_hui/rl-imitation-learning-ac28116c02fc" rel="nofollow ugc">Imitation learning</a> is a type of supervised learning (vs. unsupervised or reinforcement learning) where the learner is trained on a bunch of expert demonstrations (in this case, move-strings), and learns to generate similar demonstrations itself. </p>
<p>A major problem with imitation learning is that it fails in the face of distributional shift. If the test data it faces (in this case, opponent move-strings) is much different from its training distribution, then it doesn&#8217;t &#8220;know&#8221; how to respond and may respond strangely. This pushes the game further out of its training distribution, and the errors compound. I suspect that this is what happened when Scott played an unexpected opening sequence:</p>
<blockquote><p>Gwern suggested I did better than I expected against it because I’m so bad that I accidentally made moves outside what it was trained for. </p></blockquote>
<p> -Scott (in a comment reply)</p>
<p>There are approaches to dealing with this issue (see: <a rel="nofollow"href="https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf" rel="nofollow ugc">DAgger</a>), but it still limits the contexts in which imitation learning is useful. Unless a GPT-2 descendant manages to somehow recover something like a goal or a desired end-state from its training data (and in that way become more like a reinforcement learner), I suspect that it will struggle to perform at human-level in contexts where it may encounter inputs that differ slightly from its training distribution. Unfortunately, human interaction is rife with these inputs.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
	<li class="comment byuser comment-author-closed-to-third-cause odd alt thread-even depth-1" id="li-comment-838968">
		<div id="comment-838968" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/98040bee9094d5997e0c34bc4c216e17?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/98040bee9094d5997e0c34bc4c216e17?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">closed to third cause</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-838968">
			January 8, 2020 at 9:39 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Has anyone read the Ted Chiang&#8217;s novella The Lifecycle of Software Objects? It&#8217;s included in his Exhalation collection, which I highly recommend (though not quite as good as his first book). Some broad spoilers follow, but they will not ruin your enjoyment of the story. The novella follows the education of artificial intelligences over years as they learn and grow similarly to the way people develop from babies. The point Chiang is making is that the best way to arrive at a general AI is the same way people become intelligent: by raising it from infanthood.</p>
<p>Which makes me wonder if anyone has tried doing this yet. You could do it in a virtual world, or, even better, in the real world. Let&#8217;s say you hook up some deep learning system to a camera and a microphone, and give a speaker, maybe some robotic manipulators, may be a form of crude locomotion. Then you treat is as a human baby. Would an attention mechanism be enough? Would you need some reinforcement learning based goals? Is this a potentially horrible idea with some serious ethical concerns?</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-vivi_iviv even depth-2" id="li-comment-839048">
		<div id="comment-839048" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f06fd304638718f05ee2d89d0235d70?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">viVI_IViv</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839048">
			January 8, 2020 at 11:29 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><blockquote><p>Which makes me wonder if anyone has tried doing this yet. You could do it in a virtual world, or, even better, in the real world. Let’s say you hook up some deep learning system to a camera and a microphone, and give a speaker, maybe some robotic manipulators, may be a form of crude locomotion. Then you treat is as a human baby.</p></blockquote>
<p>People have been trying things like this for decades, see <a rel="nofollow"href="https://en.wikipedia.org/wiki/Kismet_(robot)" rel="nofollow ugc">Kismet</a> and <a rel="nofollow"href="https://en.wikipedia.org/wiki/ICub" rel="nofollow ugc">iCub</a>, not necessarily with deep learning, but it doesn&#8217;t matter. It&#8217;s like building a bamboo tower and a dirt road on a remote island and expecting an airplane full of <a rel="nofollow"href="https://en.wikipedia.org/wiki/Cargo_cult" rel="nofollow ugc">cargo</a> to magically land on it.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-enyeword odd alt thread-odd thread-alt depth-1" id="li-comment-839308">
		<div id="comment-839308" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/98e5b49ca17e534ea542ee8cfa2ebbba?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/98e5b49ca17e534ea542ee8cfa2ebbba?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">enye-word</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839308">
			January 8, 2020 at 9:06 pm</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>Did GPT-2 have any advantage over, say, using a markov chain?</p>
<p>After looking at Doug S.&#8217;s link about using a Bayesian spam filter to play chess, looks like no.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	<ul class="children">
	<li class="comment byuser comment-author-rachel even depth-2" id="li-comment-839341">
		<div id="comment-839341" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/151d19d592de984666089518e151c523?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/151d19d592de984666089518e151c523?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">rachel</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-839341">
			January 9, 2020 at 2:42 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I don&#8217;t know about this specific context, but GPT-2 definitely has an advantage over using markov chains in standard text-generation. For example, given enough training it can <a rel="nofollow"href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow ugc">learn to summarize</a> when prompted with TL;DR:. A markov chain could only ever parrot-back the beginnings of summaries that it has already seen, whereas GPT-2 can learn to recombine the contents of a text in a vaguely summary-like pattern. The summaries themselves are <a rel="nofollow"href="https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/">apparently not great</a>, but they do demonstrate a capacity to generate new text be reorganizing the previous that markov chains lack.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
	<li class="comment byuser comment-author-deciusbrutus odd alt thread-even depth-1" id="li-comment-843421">
		<div id="comment-843421" class="commentholder">
		<div class="comment-author vcard">
			<img alt='' src='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=40&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/794ddc14d165c6ec425018d798ff5486?s=80&#038;d=identicon&#038;r=g 2x' class='avatar avatar-40 photo' height='40' width='40' />			<cite class="fn">deciusbrutus</cite> <span class="says">says:</span>		</div><!-- .comment-author .vcard -->
		
		<div class="comment-meta commentmetadata"><a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/#comment-843421">
			January 20, 2020 at 9:51 am</a>		</div><!-- .comment-meta .commentmetadata -->

		<div class="comment-body"><p>I think it&#8217;s a major error to consider that GPT-2 is writing poems, composing music, or playing chess. What it is doing is imitating descriptions of poems, imitating descriptions of music, and imitating descriptions of chess.</p>
<p>If we fed GPT-2 with peer-reviewed science publications, it would not generate peer-reviewed science publications, even when what it generated was indistinguishable from what grad students generate (although at that point we might well consider GPT-2 to be &#8216;as smart&#8217; as grad students, particularly if its studies &#8216;replicated&#8217; at equal or better frequency). If we fed GPT-2 with locations and descriptions of known exoplanets, it would not discover more exoplanets (although if we were consistently able to find exoplanets matching the location and conditions that GPT-2 generated, we would be correct to consider GPT-2 &#8216;as smart as&#8217; exoplanet researchers). </p>
<p>If GPT-2 can be given a bug report database (not necessarily its own) and produce new bug reports that are correct, then I will be impressed.</p>
</div>

		<div class="reply">
					</div><!-- .reply -->
	</div><!-- #comment-##  -->

	</li><!-- #comment-## -->
			</ol>


	</div><!-- #comments -->




			</div><!-- #pjgm-content -->
		</div><!-- #pjgm-box -->

<div id="primary" class="widget-area" role="complementary">
	<a class="sidebar-toggle" title="Expand Sidebar"><i class="fa fa-angle-double-left"></i><i class="fa fa-angle-double-right"></i></a>
	<ul class="xoxo">
		<li id="meta-2" class="widget-container widget_meta"><h3 class="widget-title">Meta</h3>			<ul>
			<li><a href="https://slatestarcodex.com/wp-login.php?action=register">Register</a></li>			<li><a href="https://slatestarcodex.com/wp-login.php">Log in</a></li>
			<li><a href="https://slatestarcodex.com/feed/">Entries feed</a></li>
			<li><a href="https://slatestarcodex.com/comments/feed/">Comments feed</a></li>
			<li><a href="https://wordpress.org/">WordPress.org</a></li>			</ul>
			</li><li id="blog_subscription-2" class="widget-container widget_blog_subscription jetpack_subscription_widget"><h3 class="widget-title">Subscribe via Email</h3>
            <form action="#" method="post" accept-charset="utf-8" id="subscribe-blog-blog_subscription-2">
				                    <p id="subscribe-email">
                        <label id="jetpack-subscribe-label"
                               class="screen-reader-text"
                               for="subscribe-field-blog_subscription-2">
							Email Address                        </label>
                        <input type="email" name="email" required="required" class="required"
                               value=""
                               id="subscribe-field-blog_subscription-2"
                               placeholder="Email Address"/>
                    </p>

                    <p id="subscribe-submit">
                        <input type="hidden" name="action" value="subscribe"/>
                        <input type="hidden" name="source" value="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/"/>
                        <input type="hidden" name="sub-type" value="widget"/>
                        <input type="hidden" name="redirect_fragment" value="blog_subscription-2"/>
						                        <button type="submit"
	                        		                    	                        name="jetpack_subscriptions_widget"
	                    >
	                        Subscribe                        </button>
                    </p>
				            </form>
		
</li><li id="text-4" class="widget-container widget_text"><h3 class="widget-title">Advertisements</h3>			<div class="textwidget"></div>
		</li><li id="arvins_ad_randomizer-2" class="widget-container widget_arvins_ad_randomizer"><div class="widget-text arvins_ad_randomizer_box"><div class="aar_div"><p><center><A HREF="http://LauraBaurMD.com"><IMG SRC="https://slatestarcodex.com/blog_images/vert_baur.jpg"></A></center></p>

<p>Dr. Laura Baur is a psychiatrist with interests in literature review, reproductive psychiatry, and relational psychotherapy; see <A HREF="http://LauraBaurMD.com">her website</A> for more.  Note that due to conflict of interest she doesn't treat people in the NYC rationalist social scene.</p></div><div class="aar_div"><center><p><a href="https://www.patreon.com/user?u=926060"><IMG SRC="https://slatestarcodex.com/blog_images/vert_patreon3.png" border="0"></A></p></center>

<p>Support Slate Star Codex on <A HREF="https://www.patreon.com/user?u=926060">Patreon</A>. I have a day job and SSC gets free hosting, so don't feel pressured to contribute. But extra cash helps pay for contest prizes, meetup expenses, and me spending extra time blogging instead of working.</p></div><div class="aar_div"><p><center><A HREF="https://www.chartercitiesinstitute.org"><IMG SRC="https://slatestarcodex.com/blog_images/vert_charter.png"></A></center></p>

<p>The <A HREF="https://www.chartercitiesinstitute.org/">Charter Cities Institute</A> is working on ways governments can set up special zones with unique legal institutions. <A HREF="https://www.chartercitiesinstitute.org/intro">Learn more</A> about how this could help tackle problems from global poverty to climate change.</p></div><div class="aar_div"><p><center><A HREF="http://effectivealtruism.org/?refer=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/eatowr.jpg"></A></center></p>

<p>The <A HREF="http://effectivealtruism.org/?refer=ssc">Effective Altruism newsletter</A> provides monthly updates on the highest-impact ways to do good and help others.</p></div><div class="aar_div"><p><center><A HREF="https://safetywing.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_safety.png"></A></center></p>

<p>Norwegian founders with an international team on a mission to offer the equivalent of a Norwegian social safety net globally available as a membership. Currently offering <A HREF="https://safetywing.com/nomad-insurance">travel medical insurance for nomads</A>, and <A HREF="https://safetywing.com/remote-health">global health insurance for remote teams</A>.</p></div><div class="aar_div"><p><center><A HREF="https://www.janestreet.com/join-jane-street/open-positions/?utm_source=ssc&utm_medium=banner&utm_campaign=trading&utm_term=trading&utm_content=sierpinski"><img src="https://slatestarcodex.com/blog_images/sierpinski-low_res.png" srcset="https://slatestarcodex.com/blog_images/sierpinski-low_res.png 1x, https://slatestarcodex.com/blog_images/sierpinski_med_res.png 2x"></A></center></p>

<p><A HREF="https://www.janestreet.com/join-jane-street/open-positions/?utm_source=ssc&utm_medium=banner&utm_campaign=trading&utm_term=trading&utm_content=sierpinski">Jane Street</A> is a quantitative trading firm with a focus on technology and collaborative problem solving. We're always hiring talented programmers, traders, and researchers and have internships and fulltime positions in New York, London, and Hong Kong. No background in finance required.</p></div><div class="aar_div"><p><center><A HREF="https://www.beeminder.com/"><IMG SRC="https://slatestarcodex.com/blog_images/beeminder_ad.png"></A></center></p>

<p>Beeminder's an evidence-based willpower augmention tool that collects quantifiable data about your life, then helps you organize it into commitment mechanisms so you can keep resolutions. They've also got a blog about what they're doing <A HREF="http://blog.beeminder.com/tag/rationality/">here</A></p></div><div class="aar_div"><p><center><A HREF="https://substack.com/?utm_source=ssc&utm_campaign=ssc1"><IMG SRC="https://slatestarcodex.com/blog_images/vert_substack.png"></A></center></p>

<p><A HREF="https://substack.com/?utm_source=ssc&utm_campaign=ssc1">Substack</A> is a blogging site that helps writers earn money and readers discover articles they'll like.</p></div><div class="aar_div"><p><center><A HREF="https://80000hours.org/key-ideas/?utm_source=ssc&utm_campaign=2017-04+Sidebar+Ad&utm_medium=blog"><IMG SRC="https://slatestarcodex.com/blog_images/80k_vertise.png"></A></center></p>

<p>80,000 Hours researches different problems and professions to help you figure out how to do as much good as possible. Their <A HREF="https://80000hours.org/career-guide/?utm_source=ssc&utm_campaign=2017-04+Sidebar+Ad&utm_medium=blog">free career guide</A> show you how to choose a career that's fulfilling and maximises your contribution to solving the world's most pressing problems.</p></div><div class="aar_div"><p><center><A HREF="http://www.mealsquares.com/"><IMG SRC="https://slatestarcodex.com/blog_images/mealsquares_ad.png"></A></center></p>

<p><A HREF="http://www.mealsquares.com/">MealSquares</A> is a "nutritionally complete" food that contains a balanced diet worth of nutrients in a few tasty easily measurable units. Think Soylent, except zero preparation, made with natural ingredients, and looks/tastes a lot like an ordinary scone. </p></div><div class="aar_div"><p><center><A HREF="http://epidemicforecasting.org/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_covid.png"></A></center></p>

<p>The <A HREF="http://epidemicforecasting.org/">COVID-19 Forecasting Project</A> at the University of Oxford is making advanced pandemic simulations of 150+ countries available to the public, and also offer pro-bono forecasting services to decision-makers.</p>
</div><div class="aar_div"><p><center><A HREF="https://aisafety.com/reading-group/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_aisafety.jpg"></A></center></p>

<p><A HREF="https://aisafety.com/reading-group/">AISafety.com</A> hosts a Skype reading group Wednesdays at 19:45 UTC, reading new and old articles on different aspects of AI Safety. We start with a presentation of a summary of the article, and then discuss in a friendly atmosphere.</A></p></div><div class="aar_div"><p><center><A HREF="http://seattleanxiety.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_seattle.png"></A></center></p>

<p><A HREF="https://seattleanxiety.com/">Seattle Anxiety Specialists</A> are a therapy practice helping people overcome anxiety and related mental health issues (eg GAD, OCD, PTSD) through evidence based interventions and self-exploration. Check out their free anti-anxiety guide <A HREF="https://seattleanxiety.com/#free-guide-section">here</A></p>.</div><div class="aar_div"><p><center><A HREF="https://altruisto.com/?ref=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/vertise_altruisto.png"></A></center></p>

<p><A HREF="https://altruisto.com/?ref=ssc">Altruisto</A> is a browser extension so that when you shop online, a portion of the money you pay goes to effective charities (no extra cost to you). Just install an extension and when you buy something, people in poverty will get medicines, bed nets, or financial aid.</p></div><div class="aar_div"><p><center><A HREF="https://b4x.com/"><IMG SRC="https://slatestarcodex.com/blog_images/vert_b4x.png"></A></center></p>

<p><A HREF="https://b4x.com/">B4X</A> is a free and open source developer tool that allows users to write apps for Android, iOS, and more.</p></div><div class="aar_div"><p><center><A HREF="https://www.givingwhatwecan.org/?refer=ssc"><IMG SRC="https://slatestarcodex.com/blog_images/eatowr2.jpg"></A></center></p>

<p><A HREF="https://www.givingwhatwecan.org/">Giving What We Can</A> is a charitable movement promoting giving some of your money to the developing world or other worthy causes. If you're interested in this, consider taking their Pledge as a formal and public declaration of intent.</p></div><div class="aar_div"><p><center><A HREF="https://www.metaculus.com/questions/?show-welcome=true"><IMG SRC="https://slatestarcodex.com/blog_images/metaculus_vert.jpg"></A></center></p>

<p>Metaculus is a platform for generating crowd-sourced predictions about the future, especially science and technology. If you're interested in testing yourself and contributing to their project, check out their <A HREF="https://www.metaculus.com/questions/">questions page</A></p>
</div></div></li>	</ul>
</div><!-- #primary .widget-area -->
			</div><!-- #pjgm-main -->
			<div id="pjgm-footer">
				<div id="pjgm-ender">
					<a href="http://www.hulozila.com/" title="Hulozila" rel="designer"> </a>
				</div><!-- #pjgm-ender -->
			</div><!-- #pjgm-footer -->
		</div><!-- #pjgm-wrap -->
		<script>
    jQuery(document).ready(function () {
		jQuery.post('https://slatestarcodex.com?ga_action=googleanalytics_get_script', {action: 'googleanalytics_get_script'}, function(response) {
			var s = document.createElement("script");
			s.type = "text/javascript";
			s.innerHTML = response;
			jQuery("head").append(s);
		});
    });
</script><script type='text/javascript'>
/* <![CDATA[ */
var ReportCommentsJs = {"ajaxurl":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php","confirm":"Are you sure you want to report this comment"};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/old.reportcomments/reportcomments.js?ver=1.2'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/comment-reply.min.js'></script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/page-links-to/dist/new-tab.js?ver=3.3.3'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var pmcc_ajax = {"ajaxurl":"https:\/\/slatestarcodex.com\/wp-admin\/admin-ajax.php","errors":{"thank_you_message":"Reported.","invalid_nonce_message":"It seems you already reported this comment.","invalid_values_message":"Cheating huh?","already_flagged_message":"It seems you already reported this comment.","already_flagged_note":"Comment has been flagged already."}};
/* ]]> */
</script>
<script type='text/javascript' src='https://slatestarcodex.com/wp-content/plugins/crowd-control/js/ajax.js?ver=20150929'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.4.1/wp-includes/js/wp-embed.min.js'></script>
<script type='text/javascript' src='https://stats.wp.com/e-202021.js' async='async' defer='defer'></script>
<script type='text/javascript'>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:8.5',blog:'46701818',post:'5840',tz:'-7',srv:'slatestarcodex.com'} ]);
	_stq.push([ 'clickTrackerInit', '46701818', '5840' ]);
</script>
		<script src="https://bakkot.github.io/SlateStarComments/ssc.js"></script>

		<script>
			jQuery(function() {

				/*  Sidebar collapse
				/* ------------------------------------ */

				jQuery('#primary .sidebar-toggle').click(function(){
					jQuery('body').toggleClass('s1-collapse').toggleClass('s1-expand');
					if (jQuery('body').is('.s2-expand')) {
						jQuery('body').toggleClass('s2-expand').toggleClass('s2-collapse');
					}
				});
				jQuery('#left-sidebar .sidebar-toggle').click(function(){
					jQuery('body').toggleClass('s2-collapse').toggleClass('s2-expand');
					if (jQuery('body').is('.s1-expand')) {
						jQuery('body').toggleClass('s1-expand').toggleClass('s1-collapse');
					}
				});
			});
		</script>
	</body>
</html>
