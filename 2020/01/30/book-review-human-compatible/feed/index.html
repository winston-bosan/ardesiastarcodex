<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: Book Review: Human Compatible	</title>
	<atom:link href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/feed/" rel="self" type="application/rss+xml" />
	<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/</link>
	<description>SELF-RECOMMENDING!</description>
	<lastBuildDate>Wed, 19 Feb 2020 08:38:44 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.1</generator>
	<item>
		<title>
		By: MostlyCredibleHulk		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-854587</link>

		<dc:creator><![CDATA[MostlyCredibleHulk]]></dc:creator>
		<pubDate>Wed, 19 Feb 2020 08:38:44 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-854587</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848050&quot;&gt;James Koppel&lt;/a&gt;.

Namely, for the same thing that forgeries have been used for literally thousands of years. I think that supports Scott&#039;s argument. There might be a brief period where deepfakes are novelty and so some people would be tricked, but then the same thing would happen that happened with faking money, signatures, documents, texts, audio and Rolex watches - people would develop ways to spot the fakes and healthy mistrust for plausibly looking Rolex watch being sold for $20... I mean, plausibly looking video evidence of something that is outside of the common experience.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848050">James Koppel</a>.</p>
<p>Namely, for the same thing that forgeries have been used for literally thousands of years. I think that supports Scott&#8217;s argument. There might be a brief period where deepfakes are novelty and so some people would be tricked, but then the same thing would happen that happened with faking money, signatures, documents, texts, audio and Rolex watches &#8211; people would develop ways to spot the fakes and healthy mistrust for plausibly looking Rolex watch being sold for $20&#8230; I mean, plausibly looking video evidence of something that is outside of the common experience.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: MostlyCredibleHulk		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-854586</link>

		<dc:creator><![CDATA[MostlyCredibleHulk]]></dc:creator>
		<pubDate>Wed, 19 Feb 2020 08:31:46 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-854586</guid>

					<description><![CDATA[Something I&#039;m missing in the whole thing here:
&lt;blockquote&gt;If it’s important to control AI, and easy solutions like “put it in a box” aren’t going to work, what do you do?&lt;/blockquote&gt;

If we ever succeed in creating human-level AI, what makes one think we have the right to &quot;control&quot; it at all? I mean, if we have superhuman or even human-level consciousness, and we &quot;control&quot; it to the point it can&#039;t but do our bidding, doesn&#039;t it look some kind of hyper-slavery (at least human slaves could act autonomously, even if they would be punished and maybe killed for it)? Aren&#039;t we by now supposed to have arrived at the point in our culture that we think it&#039;s a bad thing to do? 

On the other hand, humans are perfectly capable - and frequently willing - to destroy other humans. Some are more adept at this that others. Still, humanity seems to be on a pretty smooth ride to 8 billions (yes, I know about climate worries and such, but I think we&#039;ll manage to handle it one way or another). So having intelligences around that we don&#039;t entirely control and even having a lot of them that are smarter than us (well, at least smarter than me, Scott may replace &quot;a lot&quot; with &quot;a very small number&quot;) doesn&#039;t seem to be an extinction-level problem. I mean, it&#039;s possible that some very smart humans decide to destroy human race, and they certainly would have a lot of tools for their mission&#039;s success. And yes, we have people that take care of that risk, so I agree that it makes sense to have people take care of AI-based risk in the same way (maybe not exactly the same but you get the idea). But it&#039;s not something people spend a lot of day time worried about, do they?]]></description>
			<content:encoded><![CDATA[<p>Something I&#8217;m missing in the whole thing here:</p>
<blockquote><p>If it’s important to control AI, and easy solutions like “put it in a box” aren’t going to work, what do you do?</p></blockquote>
<p>If we ever succeed in creating human-level AI, what makes one think we have the right to &#8220;control&#8221; it at all? I mean, if we have superhuman or even human-level consciousness, and we &#8220;control&#8221; it to the point it can&#8217;t but do our bidding, doesn&#8217;t it look some kind of hyper-slavery (at least human slaves could act autonomously, even if they would be punished and maybe killed for it)? Aren&#8217;t we by now supposed to have arrived at the point in our culture that we think it&#8217;s a bad thing to do? </p>
<p>On the other hand, humans are perfectly capable &#8211; and frequently willing &#8211; to destroy other humans. Some are more adept at this that others. Still, humanity seems to be on a pretty smooth ride to 8 billions (yes, I know about climate worries and such, but I think we&#8217;ll manage to handle it one way or another). So having intelligences around that we don&#8217;t entirely control and even having a lot of them that are smarter than us (well, at least smarter than me, Scott may replace &#8220;a lot&#8221; with &#8220;a very small number&#8221;) doesn&#8217;t seem to be an extinction-level problem. I mean, it&#8217;s possible that some very smart humans decide to destroy human race, and they certainly would have a lot of tools for their mission&#8217;s success. And yes, we have people that take care of that risk, so I agree that it makes sense to have people take care of AI-based risk in the same way (maybe not exactly the same but you get the idea). But it&#8217;s not something people spend a lot of day time worried about, do they?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: StellaAthena		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-850239</link>

		<dc:creator><![CDATA[StellaAthena]]></dc:creator>
		<pubDate>Fri, 07 Feb 2020 23:22:41 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-850239</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849727&quot;&gt;DavidFriedman&lt;/a&gt;.

So does the book discuss him? It seems quite bizarre to me to forecast a complete failure of the farming industry if a massive revolution in farming &lt;i&gt;had just happened&lt;/i&gt;. How does the Green Revolution relate to his thought?]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849727">DavidFriedman</a>.</p>
<p>So does the book discuss him? It seems quite bizarre to me to forecast a complete failure of the farming industry if a massive revolution in farming <i>had just happened</i>. How does the Green Revolution relate to his thought?</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: John Schilling		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849957</link>

		<dc:creator><![CDATA[John Schilling]]></dc:creator>
		<pubDate>Fri, 07 Feb 2020 14:31:05 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849957</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889&quot;&gt;viVI_IViv&lt;/a&gt;.

&lt;blockquote&gt;My standard explanation of the argument is that the U.S. has two technologies for producing cars. &lt;/blockquote&gt;

Three.  We can sell title to Iowa farmland to Japanese carmakers and get Hondas in return.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889">viVI_IViv</a>.</p>
<blockquote><p>My standard explanation of the argument is that the U.S. has two technologies for producing cars. </p></blockquote>
<p>Three.  We can sell title to Iowa farmland to Japanese carmakers and get Hondas in return.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Aapje		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849892</link>

		<dc:creator><![CDATA[Aapje]]></dc:creator>
		<pubDate>Fri, 07 Feb 2020 10:23:01 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849892</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889&quot;&gt;viVI_IViv&lt;/a&gt;.

@DavidFriedman

&lt;blockquote&gt;The claim is that comparative advantage means that one gains from trade, however low one’s productivity is.&lt;/blockquote&gt;

...if transaction costs are zero, which they are not.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889">viVI_IViv</a>.</p>
<p>@DavidFriedman</p>
<blockquote><p>The claim is that comparative advantage means that one gains from trade, however low one’s productivity is.</p></blockquote>
<p>&#8230;if transaction costs are zero, which they are not.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Charlie__		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849865</link>

		<dc:creator><![CDATA[Charlie__]]></dc:creator>
		<pubDate>Fri, 07 Feb 2020 04:31:49 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849865</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-847259&quot;&gt;JungianTJ&lt;/a&gt;.

Sort of, but not exactly. The AI is &lt;i&gt;almost&lt;/i&gt; interpreting the human as taking actions based on how it expects the AI to interpret them (Gricean communication), but not &lt;i&gt;quite&lt;/i&gt;. Instead, the human is interpreted as taking good actions in a very specific sort of two-player game, which is capable of encompassing most types of communication but also contains plenty of &quot;obvious,&quot; non-communicative interpretation.

Of course, that&#039;s still really close, and perhaps I&#039;m just splitting hairs because it&#039;s a whole lot easier to say the words &quot;relevance theory&quot; than it is to program a computer to do it.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-847259">JungianTJ</a>.</p>
<p>Sort of, but not exactly. The AI is <i>almost</i> interpreting the human as taking actions based on how it expects the AI to interpret them (Gricean communication), but not <i>quite</i>. Instead, the human is interpreted as taking good actions in a very specific sort of two-player game, which is capable of encompassing most types of communication but also contains plenty of &#8220;obvious,&#8221; non-communicative interpretation.</p>
<p>Of course, that&#8217;s still really close, and perhaps I&#8217;m just splitting hairs because it&#8217;s a whole lot easier to say the words &#8220;relevance theory&#8221; than it is to program a computer to do it.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: JPNunez		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849794</link>

		<dc:creator><![CDATA[JPNunez]]></dc:creator>
		<pubDate>Thu, 06 Feb 2020 21:49:49 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849794</guid>

					<description><![CDATA[I do remember cancer researchers saying that there cannot be a cure for cancer after all, mostly cause cancer is not a single sickness but a huge variation of them so a single cure is impossible. So that ain&#039;t really a counterargument against strong AI but it tells me it&#039;s not unthinkable that AI researchers can come up clean that we can&#039;t really build HAL 9000.]]></description>
			<content:encoded><![CDATA[<p>I do remember cancer researchers saying that there cannot be a cure for cancer after all, mostly cause cancer is not a single sickness but a huge variation of them so a single cure is impossible. So that ain&#8217;t really a counterargument against strong AI but it tells me it&#8217;s not unthinkable that AI researchers can come up clean that we can&#8217;t really build HAL 9000.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: DavidFriedman		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849733</link>

		<dc:creator><![CDATA[DavidFriedman]]></dc:creator>
		<pubDate>Thu, 06 Feb 2020 19:13:31 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849733</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889&quot;&gt;viVI_IViv&lt;/a&gt;.

The claim is that comparative advantage means that one gains from trade, however low one&#039;s productivity is. That isn&#039;t inconsistent with the existence of some people who will starve to death if there is no trade, and will still starve to death if there is.

But a more precise statement would be that an individual gains from his being able to trade with others. It is still possible that A loses as a result of B being able to trade with C — because that reduces the amount A can gain by himself trading with B.

The argument that we always gain from trade is implicitly treating the country as a single individual. Moving to free trade results in net gains to Americans, but that doesn&#039;t mean that all Americans gain. 

My standard explanation of the argument is that the U.S. has two technologies for producing cars. We can build them  in Detroit or grow them in Iowa. The way you grow cars is by growing the raw material they are made out of, called &quot;wheat.&quot; You put the wheat on a ship, it sails out into the Pacific, and it comes back with Hondas on it. A tariff taxes that technology, protecting American auto workers from the competition of American farmers.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848889">viVI_IViv</a>.</p>
<p>The claim is that comparative advantage means that one gains from trade, however low one&#8217;s productivity is. That isn&#8217;t inconsistent with the existence of some people who will starve to death if there is no trade, and will still starve to death if there is.</p>
<p>But a more precise statement would be that an individual gains from his being able to trade with others. It is still possible that A loses as a result of B being able to trade with C — because that reduces the amount A can gain by himself trading with B.</p>
<p>The argument that we always gain from trade is implicitly treating the country as a single individual. Moving to free trade results in net gains to Americans, but that doesn&#8217;t mean that all Americans gain. </p>
<p>My standard explanation of the argument is that the U.S. has two technologies for producing cars. We can build them  in Detroit or grow them in Iowa. The way you grow cars is by growing the raw material they are made out of, called &#8220;wheat.&#8221; You put the wheat on a ship, it sails out into the Pacific, and it comes back with Hondas on it. A tariff taxes that technology, protecting American auto workers from the competition of American farmers.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: DavidFriedman		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849727</link>

		<dc:creator><![CDATA[DavidFriedman]]></dc:creator>
		<pubDate>Thu, 06 Feb 2020 19:05:24 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849727</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848762&quot;&gt;StellaAthena&lt;/a&gt;.

Googling for [Ehrlich Borlaug] I found the following:
&lt;blockquote&gt;
In fact, by the time that The Population Bomb saw it’s 1971 edition, Borlaug had already won the Nobel Peace Prize for his work revolutionizing agricultural productivity in the developing world. &lt;/blockquote&gt;
From the Wiki piece on Borlaug:
&lt;blockquote&gt;
During the mid-20th century, Borlaug led the introduction of these high-yielding varieties combined with modern agricultural production techniques to Mexico, Pakistan, and India. As a result, Mexico became a net exporter of wheat by 1963. Between 1965 and 1970, wheat yields nearly doubled in Pakistan and India&lt;/blockquote&gt;

&lt;i&gt;The Population Bomb&lt;/i&gt; was written in 1968.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848762">StellaAthena</a>.</p>
<p>Googling for [Ehrlich Borlaug] I found the following:</p>
<blockquote><p>
In fact, by the time that The Population Bomb saw it’s 1971 edition, Borlaug had already won the Nobel Peace Prize for his work revolutionizing agricultural productivity in the developing world. </p></blockquote>
<p>From the Wiki piece on Borlaug:</p>
<blockquote><p>
During the mid-20th century, Borlaug led the introduction of these high-yielding varieties combined with modern agricultural production techniques to Mexico, Pakistan, and India. As a result, Mexico became a net exporter of wheat by 1963. Between 1965 and 1970, wheat yields nearly doubled in Pakistan and India</p></blockquote>
<p><i>The Population Bomb</i> was written in 1968.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Scott H.		</title>
		<link>https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-849379</link>

		<dc:creator><![CDATA[Scott H.]]></dc:creator>
		<pubDate>Thu, 06 Feb 2020 03:05:52 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5859#comment-849379</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848011&quot;&gt;Hyman Rosen&lt;/a&gt;.

I think I&#039;m going to label myself a Hyman Rosenist.  My concerns also center on how &quot;safety&quot; manifests itself in the here and now, and I agree that the idea of an emergent non-lifeform motivation is a total mystery. 

Personally, I&#039;m more inclined to worry about the select group of humans that end up controlling the coming stupid but narrowly effective machines and programs.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2020/01/30/book-review-human-compatible/#comment-848011">Hyman Rosen</a>.</p>
<p>I think I&#8217;m going to label myself a Hyman Rosenist.  My concerns also center on how &#8220;safety&#8221; manifests itself in the here and now, and I agree that the idea of an emergent non-lifeform motivation is a total mystery. </p>
<p>Personally, I&#8217;m more inclined to worry about the select group of humans that end up controlling the coming stupid but narrowly effective machines and programs.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>
