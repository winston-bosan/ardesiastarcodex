<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: 2018 Predictions: Calibration Results	</title>
	<atom:link href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/feed/" rel="self" type="application/rss+xml" />
	<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/</link>
	<description>SELF-RECOMMENDING!</description>
	<lastBuildDate>Fri, 25 Jan 2019 15:38:12 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4.1</generator>
	<item>
		<title>
		By: Lambert		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713751</link>

		<dc:creator><![CDATA[Lambert]]></dc:creator>
		<pubDate>Fri, 25 Jan 2019 15:38:12 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713751</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713624&quot;&gt;David Wallace&lt;/a&gt;.

I think generally tracking which predictions are preferred is a good idea, not just for 50%.  
See whether there&#039;s a systematic bias going on.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713624">David Wallace</a>.</p>
<p>I think generally tracking which predictions are preferred is a good idea, not just for 50%.<br />
See whether there&#8217;s a systematic bias going on.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: David Wallace		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713624</link>

		<dc:creator><![CDATA[David Wallace]]></dc:creator>
		<pubDate>Fri, 25 Jan 2019 03:32:45 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713624</guid>

					<description><![CDATA[If you want to do something meaningful with the 50% results, find some non-random way to select which way you ask them, ideally one that tracks some concern about your decision-making you’d like to check.

E.G. if you want to check for irrational pessimism or optimism, always choose the option you’d prefer to happen as the ‘confirmed’ case.]]></description>
			<content:encoded><![CDATA[<p>If you want to do something meaningful with the 50% results, find some non-random way to select which way you ask them, ideally one that tracks some concern about your decision-making you’d like to check.</p>
<p>E.G. if you want to check for irrational pessimism or optimism, always choose the option you’d prefer to happen as the ‘confirmed’ case.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Douglas Knight		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713577</link>

		<dc:creator><![CDATA[Douglas Knight]]></dc:creator>
		<pubDate>Fri, 25 Jan 2019 01:51:01 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713577</guid>

					<description><![CDATA[&lt;blockquote&gt;Please don’t complain that 50% predictions don’t mean anything; I know this is true but there are some things I’m genuinely 50-50 unsure of.&lt;/blockquote&gt;

OK, I won&#039;t complain about your decisions if you present them as decisions. But that&#039;s not what you did. If you do make up bullshit excuses, I&#039;m not going to believe them. I&#039;m going to complain about them.

Maybe there are things that you&#039;re genuinely 50-50 unsure of, but there are other things that you&#039;re genuinely 65-35 unsure of, yet you&#039;re able to bucket them as either 70-30 or 60-40. So you could force items out of 50-50 just as well.]]></description>
			<content:encoded><![CDATA[<blockquote><p>Please don’t complain that 50% predictions don’t mean anything; I know this is true but there are some things I’m genuinely 50-50 unsure of.</p></blockquote>
<p>OK, I won&#8217;t complain about your decisions if you present them as decisions. But that&#8217;s not what you did. If you do make up bullshit excuses, I&#8217;m not going to believe them. I&#8217;m going to complain about them.</p>
<p>Maybe there are things that you&#8217;re genuinely 50-50 unsure of, but there are other things that you&#8217;re genuinely 65-35 unsure of, yet you&#8217;re able to bucket them as either 70-30 or 60-40. So you could force items out of 50-50 just as well.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: phreak		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713463</link>

		<dc:creator><![CDATA[phreak]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 21:27:28 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713463</guid>

					<description><![CDATA[The interesting Elon Musk - related predictions are:

Elon Musk will be reassigned from CEO in 2019: 40%
Tesla will file for Chapter 11 in 2019: 20%
Space X will file for Chapter 11 in 2019: 25%]]></description>
			<content:encoded><![CDATA[<p>The interesting Elon Musk &#8211; related predictions are:</p>
<p>Elon Musk will be reassigned from CEO in 2019: 40%<br />
Tesla will file for Chapter 11 in 2019: 20%<br />
Space X will file for Chapter 11 in 2019: 25%</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: LibertyRisk		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713433</link>

		<dc:creator><![CDATA[LibertyRisk]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 20:56:08 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713433</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713081&quot;&gt;Alexander Turok&lt;/a&gt;.

https://www.gjopen.com/

Not as user-definable as you would like, but a lot I think you&#039;d be interested in.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713081">Alexander Turok</a>.</p>
<p><a rel="nofollow"href="https://www.gjopen.com/" rel="nofollow ugc">https://www.gjopen.com/</a></p>
<p>Not as user-definable as you would like, but a lot I think you&#8217;d be interested in.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Lambert		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713423</link>

		<dc:creator><![CDATA[Lambert]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 20:43:38 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713423</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-712963&quot;&gt;Lambert&lt;/a&gt;.

Really what I&#039;m trying to say here is that the 50% problem is fundamentally invalid.  
  
&#039;Do you get any points for being calibrated at 50%?&#039; is part of the &#039;high score&#039; paradigm which people naively shoehorn this kind of calibration exercise into.  
But calibration does not really work according to that paradigm, so the answers people get out are hopelessly confused and inconsistent (in the mathematical sense of the word).  
  
Do 50% predictions matter? Mu]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-712963">Lambert</a>.</p>
<p>Really what I&#8217;m trying to say here is that the 50% problem is fundamentally invalid.  </p>
<p>&#8216;Do you get any points for being calibrated at 50%?&#8217; is part of the &#8216;high score&#8217; paradigm which people naively shoehorn this kind of calibration exercise into.<br />
But calibration does not really work according to that paradigm, so the answers people get out are hopelessly confused and inconsistent (in the mathematical sense of the word).  </p>
<p>Do 50% predictions matter? Mu</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: Nornagest		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713368</link>

		<dc:creator><![CDATA[Nornagest]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 19:25:11 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713368</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713139&quot;&gt;matthewravery&lt;/a&gt;.

&lt;blockquote&gt;I’m also struck by a sense of Déjà vu on the 50% question. Didn’t this get discussed last year?&lt;/blockquote&gt;

It gets discussed every year.  Seems to be one of those scissor things, if a relatively benign one.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713139">matthewravery</a>.</p>
<blockquote><p>I’m also struck by a sense of Déjà vu on the 50% question. Didn’t this get discussed last year?</p></blockquote>
<p>It gets discussed every year.  Seems to be one of those scissor things, if a relatively benign one.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: zqed		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713340</link>

		<dc:creator><![CDATA[zqed]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 18:47:38 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713340</guid>

					<description><![CDATA[&lt;blockquote&gt;50% predictions are technically meaningless since I could have written them either way – which makes it surprising I managed to get such an imbalance between right and wrong.&lt;/blockquote&gt;

For the last time, no! 50% predictions may be irrelevant for calculating calibration, but they are certainly not irrelevant for your decision-making strategy! Explaining this will take some math, but the narrative should make sense even if one skips the &quot;mathy bits&quot;

Imagine that we&#039;re given a list E of &lt;i&gt;events&lt;/i&gt;. A &lt;i&gt;probability assessment function&lt;/i&gt; (PAF) is a strategy for assigning subjective probability assessment values to each event in any given list of events. The strategy that Scott used to make his predictions is one such probabiliy assessment function, but it&#039;s a very complicated strategy that is implemented only in Scott&#039;s brain, and uses Scott&#039;s information about the current state of the world. One can think of other, much simpler probability assessment functions, such as the strategy of &quot;predict 50% if the event somehow involves Donald Trump, and predict 80% otherwise&quot;, or the even simpler strategy of &quot;always predict 100%&quot;.

Being &lt;i&gt;well-calibrated&lt;/i&gt; is a property that any given PAF may have or lack. Intuitively, we call a PAF well-calibrated if about 80% of the events to which the PAF assigns &quot;80%&quot; actually happen, and about 70% of the events to which the PAF assigns &quot;70%&quot; actually happen, and so on. Initiates of mathematics sometimes state this definition more formally: they say that given a PAF f and a list of independent events E, it should be difficult to statistically distinguish the actual outcomes of the events in the set {x &#124; x in E, f(x) = p} from a sample from a sequence of identically distributed random variables with distribution Bernoulli(p) (note to the highly mathematically literate: we skip a lot of assumptions here, including consistency and having independent events throughout. Kahneman did the same thing when he came up with this concept; you don&#039;t need much to deal with correlated or mutually exclusive events, but the details are best left to an MSc thesis).

Being well-calibrated is a desirable property for our PAFs: a well-calibrated PAF does not make over-confident predictions. But there are well-calibrated that are mostly useless. Believe it or not, the &quot;say 50% to everything&quot; strategy is a well-calibrated PAF! Simply speaking, stating &quot;I have no idea&quot; cannot make you less calibrated. Slightly more formally:  

&lt;i&gt;
The act of predicting &quot;P will happen&quot; (P) with 75% is the same as predicting &quot;It is not the case that P will happen&quot; (¬P) with 25%. The act of predicting P with 60% is the same as predicting ¬P with 40%. The act of predicting P with 50% is the same as predicting ¬P with 50%. Now imagine that you predict P with 50% and ¬P with 50%. There are two possible outcomes:

Case 1: P happens. Then your prediction of P with 50% was wrong, and your corresponding prediction of ¬P with 50% was right, so you got exactly half (50%) of your predictions right.

Case 2: P does not happen. Then your prediction of P with 50% was right, and your corresponding prediction of ¬P with 50% was wrong, so again you got exactly half (50%) of your predictions right.

Either way, you get 50% of your 50% predictions right, so your calibration is unaffected by 50% predictions.
&lt;/i&gt;


If you still think something&#039;s inherently wrong with assigning exactly 50% probability, notice that the  So calibration is good to have, but it&#039;s not the only property that measures the performance of a PAF. Imagine that you&#039;re trying to predict the weather. Which of the following PAFs would you prefer? X) A well-calibrated strategy that always predicts 50% rain and is correct 50% of the time; or Y) an ill-calibrated strategy that always predicts 100% rain or 100% sunshine, and is correct 90% of the time? While strategy X is better calibrated, strategy Y is &lt;i&gt;more informative&lt;/i&gt; - despite being overconfident! Being informative is another desirable property that a PAF may possess or lack, one very different from calibration.

Here, Scott makes predictions, and then uses the outcomes to compute the calibration of his probability assessment strategy. Strictly speaking, the 50% predictions don&#039;t affect the calibration calculations: nonetheless, &lt;b&gt;50% predictions do make sense&lt;/b&gt;, and we learn about the informativeness of the probability assessment from these predictions - and about some other important properties that I did not have time to mention in this comment. And that&#039;s why 50% predictions matter, even though they don&#039;t affect the calibration score.]]></description>
			<content:encoded><![CDATA[<blockquote><p>50% predictions are technically meaningless since I could have written them either way – which makes it surprising I managed to get such an imbalance between right and wrong.</p></blockquote>
<p>For the last time, no! 50% predictions may be irrelevant for calculating calibration, but they are certainly not irrelevant for your decision-making strategy! Explaining this will take some math, but the narrative should make sense even if one skips the &#8220;mathy bits&#8221;</p>
<p>Imagine that we&#8217;re given a list E of <i>events</i>. A <i>probability assessment function</i> (PAF) is a strategy for assigning subjective probability assessment values to each event in any given list of events. The strategy that Scott used to make his predictions is one such probabiliy assessment function, but it&#8217;s a very complicated strategy that is implemented only in Scott&#8217;s brain, and uses Scott&#8217;s information about the current state of the world. One can think of other, much simpler probability assessment functions, such as the strategy of &#8220;predict 50% if the event somehow involves Donald Trump, and predict 80% otherwise&#8221;, or the even simpler strategy of &#8220;always predict 100%&#8221;.</p>
<p>Being <i>well-calibrated</i> is a property that any given PAF may have or lack. Intuitively, we call a PAF well-calibrated if about 80% of the events to which the PAF assigns &#8220;80%&#8221; actually happen, and about 70% of the events to which the PAF assigns &#8220;70%&#8221; actually happen, and so on. Initiates of mathematics sometimes state this definition more formally: they say that given a PAF f and a list of independent events E, it should be difficult to statistically distinguish the actual outcomes of the events in the set {x | x in E, f(x) = p} from a sample from a sequence of identically distributed random variables with distribution Bernoulli(p) (note to the highly mathematically literate: we skip a lot of assumptions here, including consistency and having independent events throughout. Kahneman did the same thing when he came up with this concept; you don&#8217;t need much to deal with correlated or mutually exclusive events, but the details are best left to an MSc thesis).</p>
<p>Being well-calibrated is a desirable property for our PAFs: a well-calibrated PAF does not make over-confident predictions. But there are well-calibrated that are mostly useless. Believe it or not, the &#8220;say 50% to everything&#8221; strategy is a well-calibrated PAF! Simply speaking, stating &#8220;I have no idea&#8221; cannot make you less calibrated. Slightly more formally:  </p>
<p><i><br />
The act of predicting &#8220;P will happen&#8221; (P) with 75% is the same as predicting &#8220;It is not the case that P will happen&#8221; (¬P) with 25%. The act of predicting P with 60% is the same as predicting ¬P with 40%. The act of predicting P with 50% is the same as predicting ¬P with 50%. Now imagine that you predict P with 50% and ¬P with 50%. There are two possible outcomes:</p>
<p>Case 1: P happens. Then your prediction of P with 50% was wrong, and your corresponding prediction of ¬P with 50% was right, so you got exactly half (50%) of your predictions right.</p>
<p>Case 2: P does not happen. Then your prediction of P with 50% was right, and your corresponding prediction of ¬P with 50% was wrong, so again you got exactly half (50%) of your predictions right.</p>
<p>Either way, you get 50% of your 50% predictions right, so your calibration is unaffected by 50% predictions.<br />
</i></p>
<p>If you still think something&#8217;s inherently wrong with assigning exactly 50% probability, notice that the  So calibration is good to have, but it&#8217;s not the only property that measures the performance of a PAF. Imagine that you&#8217;re trying to predict the weather. Which of the following PAFs would you prefer? X) A well-calibrated strategy that always predicts 50% rain and is correct 50% of the time; or Y) an ill-calibrated strategy that always predicts 100% rain or 100% sunshine, and is correct 90% of the time? While strategy X is better calibrated, strategy Y is <i>more informative</i> &#8211; despite being overconfident! Being informative is another desirable property that a PAF may possess or lack, one very different from calibration.</p>
<p>Here, Scott makes predictions, and then uses the outcomes to compute the calibration of his probability assessment strategy. Strictly speaking, the 50% predictions don&#8217;t affect the calibration calculations: nonetheless, <b>50% predictions do make sense</b>, and we learn about the informativeness of the probability assessment from these predictions &#8211; and about some other important properties that I did not have time to mention in this comment. And that&#8217;s why 50% predictions matter, even though they don&#8217;t affect the calibration score.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: philosophistry		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713326</link>

		<dc:creator><![CDATA[philosophistry]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 18:19:07 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713326</guid>

					<description><![CDATA[I noticed you had trouble controlling Internet time-wasters. One strategy that worked for me is to take a microscope to how I personalize my tech interfaces. Doing so led me to delete all my bookmarks, so that I&#039;m required to type in &quot;reddit.com&quot; to visit it, thus slowing me down enough to consider not going there. Furthermore, I unsubscribed from all subbreddits, so that I have to take the extra step of navigating to a specific subreddit. I do, however, have bookmarks to Gmail and Facebook, but my link to Facebook is a direct link to Messenger.]]></description>
			<content:encoded><![CDATA[<p>I noticed you had trouble controlling Internet time-wasters. One strategy that worked for me is to take a microscope to how I personalize my tech interfaces. Doing so led me to delete all my bookmarks, so that I&#8217;m required to type in &#8220;reddit.com&#8221; to visit it, thus slowing me down enough to consider not going there. Furthermore, I unsubscribed from all subbreddits, so that I have to take the extra step of navigating to a specific subreddit. I do, however, have bookmarks to Gmail and Facebook, but my link to Facebook is a direct link to Messenger.</p>
]]></content:encoded>
		
			</item>
		<item>
		<title>
		By: 10240		</title>
		<link>https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-713278</link>

		<dc:creator><![CDATA[10240]]></dc:creator>
		<pubDate>Thu, 24 Jan 2019 16:17:30 +0000</pubDate>
		<guid isPermaLink="false">https://slatestarcodex.com/?p=5367#comment-713278</guid>

					<description><![CDATA[In reply to &lt;a href=&quot;https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-712962&quot;&gt;SaiNushi&lt;/a&gt;.

Sooner or later bubbles burst whether or not the news predict it. Once there are no more people willing to take the gamble, the price stops growing. After it&#039;s flat for a while, speculators who bought it to profit from the rising price start to cash out. Then others panic and cash out too, and the price crashes.]]></description>
			<content:encoded><![CDATA[<p>In reply to <a rel="nofollow"href="https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/#comment-712962">SaiNushi</a>.</p>
<p>Sooner or later bubbles burst whether or not the news predict it. Once there are no more people willing to take the gamble, the price stops growing. After it&#8217;s flat for a while, speculators who bought it to profit from the rising price start to cash out. Then others panic and cash out too, and the price crashes.</p>
]]></content:encoded>
		
			</item>
	</channel>
</rss>
